{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","mount_file_id":"1igIMLK7SGSqKyWzutdt2oVBw5-LQ_TFg","authorship_tag":"ABX9TyPlYnywJN4OWdyFTeQ2ujvq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2B8vZeDjXU2N"},"outputs":[],"source":["!pip install -q datasets transformers sentencepiece torch tqdm numpy\n","# ============================================================\n","# CELL 1: Setup & Dependencies\n","# ============================================================\n","!git clone https://github.com/auralmn/aura-hybrid-pre-model.git\n","\n","# Uninstall existing torch and torchvision to prevent conflicts\n","# !pip uninstall -y torch torchvision torchaudio\n","\n","# Explicitly install specific compatible versions first to prevent conflicts\n","# !pip install torchvision\n","\n","# Install project dependencies, which should now recognize the already installed compatible torch/torchvision\n","!cd aura-hybrid-pre-model && git checkout master && git pull\n","import sys\n","sys.path.insert(0, '/content/aura-hybrid-pre-model')\n","\n","# Import modules\n","from src.core.hippocampal import HippocampalFormation\n","from src.core.language_zone.hippocampal_transformer import HippocampalTransformer\n","from src.training.hippocampal_trainer import HippocampalTransformerTrainer\n","\n","# Explicitly reload hippocampal_trainer to ensure latest changes are picked up\n","import importlib\n","importlib.reload(sys.modules['src.training.hippocampal_trainer'])"]},{"cell_type":"code","source":["import os\n","import gc\n","import math\n","import time\n","import traceback\n","from dataclasses import dataclass\n","from typing import Optional\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.amp import autocast\n","from tqdm import tqdm\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","CHECKPOINT_DIR = '/content/drive/MyDrive/aura_checkpoints'\n","os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n","\n","device = torch.device('cuda')\n","print(f\"‚úÖ Device: {device}\")\n","print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n","print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n","print(f\"   Checkpoint dir: {CHECKPOINT_DIR}\")\n"],"metadata":{"id":"xC43UdLaX9Jf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from dataclasses import dataclass\n","\n","\n","@dataclass\n","class Config:\n","    # === MODEL (L4 Optimized) ===\n","    vocab_size: int = 32000\n","    embedding_dim: int = 768\n","    num_layers: int = 12\n","    num_heads: int = 16\n","    head_dim: int = 64\n","    dropout: float = 0.15\n","    max_seq_len: int = 512\n","    intermediate_size: int = 4096\n","\n","    # === HIPPOCAMPAL ===\n","    theta_frequency: float = 8.0\n","    gamma_frequency: float = 40.0\n","    n_place_cells: int = 2000\n","    n_time_cells: int = 100\n","    n_grid_cells: int = 200\n","\n","    # === TRAINING ===\n","    batch_size: int = 16\n","    gradient_accumulation: int = 1\n","    lr: float = 3e-4\n","    warmup_steps: int = 1500\n","    max_steps: int = 50000\n","    weight_decay: float = 0.1\n","\n","    # === CONSOLIDATION ===\n","    sleep_interval: int = 2000\n","    sleep_steps: int = 25\n","    eval_interval: int = 100\n","    ewc_lambda: float = 0.4\n","    use_ewc: bool = True\n","\n","    # === MEMORY ===\n","    replay_buffer_size: int = 1000000\n","    memory_creation_interval: int = 5\n","    memory_decay_rate: float = 0.03\n","\n","    # === TRAINING STABILITY ===\n","    label_smoothing: float = 0.2\n","    use_mixed_precision: bool = True\n","    compile_model: bool = False\n","\n","\n","config = Config()\n","\n","print(\"=\"*60)\n","print(\"L4 CONFIG (22.5GB VRAM)\")\n","print(\"=\"*60)\n","print(f\"Model: {config.embedding_dim}D √ó {config.num_layers}L √ó {config.num_heads}H\")\n","print(f\"Batch: {config.batch_size} √ó {config.gradient_accumulation} = {config.batch_size * config.gradient_accumulation} effective\")\n","print(f\"LR: {config.lr} | Label smoothing: {config.label_smoothing}\")\n","print(f\"EWC: enabled (Œª={config.ewc_lambda})\")\n","print(f\"Max steps: {config.max_steps}\")\n","print(\"=\"*60)\n"],"metadata":{"id":"F8BETVrSZH7-"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b02695ea"},"source":["from datasets import load_dataset\n","from transformers import T5Tokenizer\n","\n","import gc\n","import torch\n","from torch.amp import autocast\n","\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","\n","print(\"=\"*60)\n","print(\"LOADING DATASET & TOKENIZER\")\n","print(\"=\"*60)\n","\n","print(\"\\nüìö Loading Nemotron-CC-v2 High-Quality...\")\n","try:\n","    dataset = load_dataset(\n","        \"nvidia/Nemotron-CC-v2\",\n","        \"High-Quality\",\n","        split=\"train\",\n","        streaming=True\n","    )\n","    print(\"‚úÖ Nemotron-CC-v2 loaded (streaming)\")\n","\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Nemotron failed: {e}\")\n","    print(\"Falling back to WikiText-103...\")\n","    dataset = load_dataset('wikitext', 'wikitext-103-raw-v1', split='train')\n","    print(\"‚úÖ WikiText-103 loaded\")\n","\n","# Load T5 Tokenizer\n","print(\"\\nüî§ Loading T5 Tokenizer...\")\n","tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n","sp = tokenizer.sp_model\n","\n","print(f\"‚úÖ T5 Tokenizer loaded\")\n","print(f\"   Vocab size: {tokenizer.vocab_size}\")\n","print(f\"   Pad token: {tokenizer.pad_token_id}\")\n","\n","# Test\n","test_text = \"The quick brown fox\"\n","test_ids = sp.encode(test_text, out_type=int)\n","print(f\"\\n   Test: '{test_text}'\")\n","print(f\"   Tokens: {test_ids}\")\n","print(f\"   Decoded: '{sp.decode(test_ids)}'\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1a08033"},"source":["import torch\n","\n","def create_batches_sentencepiece_streaming(dataset, sp, config, max_batches=None):\n","    \"\"\"Create batches from streaming dataset\"\"\"\n","    batch_count = 0\n","    epoch = 0\n","    pad_id = sp.pad_id() if hasattr(sp, 'pad_id') else 0\n","\n","    while True:\n","        epoch += 1\n","        if epoch > 1:\n","            print(f\"\\nüìö Epoch {epoch}\")\n","\n","        batch_texts = []\n","\n","        try:\n","            for sample in dataset:\n","                # Auto-detect text field\n","                text = None\n","                for field in ['text', 'content', 'document', 'body', 'article']:\n","                    if field in sample:\n","                        text = sample[field]\n","                        break\n","\n","                if not text or len(str(text).strip()) < 20:\n","                    continue\n","\n","                batch_texts.append(str(text))\n","\n","                if len(batch_texts) >= config.batch_size:\n","                    encoded_batch = []\n","                    for t in batch_texts:\n","                        try:\n","                            token_ids = sp.encode(t, out_type=int)\n","                            if len(token_ids) > config.max_seq_len:\n","                                token_ids = token_ids[:config.max_seq_len]\n","                            pad_len = config.max_seq_len - len(token_ids)\n","                            token_ids = token_ids + [pad_id] * pad_len\n","                            encoded_batch.append(token_ids)\n","                        except:\n","                            continue\n","\n","                    if len(encoded_batch) >= config.batch_size:\n","                        encoded_batch = encoded_batch[:config.batch_size]\n","\n","                        input_ids = torch.tensor(encoded_batch, dtype=torch.long)\n","                        labels = input_ids.clone()\n","                        prosody = torch.rand(config.batch_size, config.max_seq_len, 4)\n","                        attention_mask = (input_ids != pad_id).long()\n","                        labels[attention_mask == 0] = -100\n","\n","                        batch_count += 1\n","                        yield input_ids, labels, prosody, attention_mask\n","\n","                        if max_batches and batch_count >= max_batches:\n","                            return\n","\n","                        if batch_count % 100 == 0:\n","                            print(f\"  Batches: {batch_count}\")\n","\n","                    batch_texts = []\n","\n","        except Exception as e:\n","            print(f\"  Dataset iteration ended: {e}\")\n","            if epoch > 50:\n","                return\n","\n","\n","print(\"‚úÖ Data loader function defined\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch.serialization\n","\n","# Allow numpy dtype for checkpoint loading\n","torch.serialization.add_safe_globals([np.dtype])\n","\n","def save_checkpoint(model, optimizer, scheduler, hippocampus, trainer,\n","                   global_step, losses, perplexities, steps, config):\n","    \"\"\"Save checkpoint to Drive\"\"\"\n","    checkpoint_path = os.path.join(CHECKPOINT_DIR, f'checkpoint_step_{global_step}.pt')\n","\n","    try:\n","        checkpoint = {\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'scheduler_state_dict': scheduler.state_dict(),\n","            'global_step': global_step,\n","            'losses': losses,\n","            'perplexities': perplexities,\n","            'steps': steps,\n","            'hippocampus_memories': len(hippocampus.episodic_memories),\n","            'replay_buffer_size': len(trainer.replay_buffer),\n","            'config': config.__dict__,\n","        }\n","\n","        torch.save(checkpoint, checkpoint_path)\n","        print(f\"‚úÖ Checkpoint saved: step_{global_step}\")\n","\n","        latest_path = os.path.join(CHECKPOINT_DIR, 'checkpoint_latest.pt')\n","        torch.save(checkpoint, latest_path)\n","\n","        return True\n","    except Exception as e:\n","        print(f\"‚ùå Checkpoint save failed: {e}\")\n","        return False\n","\n","\n","def load_checkpoint(checkpoint_path, model, optimizer, scheduler):\n","    \"\"\"Load checkpoint from Drive (PyTorch 2.6+ compatible)\"\"\"\n","    try:\n","        # Allow numpy types for checkpoint loading\n","        with torch.serialization.safe_globals([np.dtype]):\n","            checkpoint = torch.load(checkpoint_path, weights_only=False)\n","\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","\n","        global_step = checkpoint['global_step']\n","        losses = checkpoint['losses']\n","        perplexities = checkpoint['perplexities']\n","        steps = checkpoint['steps']\n","\n","        print(f\"‚úÖ Checkpoint loaded from step {global_step}\")\n","        if perplexities:\n","            print(f\"   Latest PPL: {perplexities[-1]:.2f}\")\n","\n","        return global_step, losses, perplexities, steps\n","\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Checkpoint load failed: {e}\")\n","        print(f\"   Trying alternative loading method...\")\n","        try:\n","            # Fallback: load with weights_only=False (less secure but works)\n","            checkpoint = torch.load(checkpoint_path, weights_only=False)\n","\n","            model.load_state_dict(checkpoint['model_state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","\n","            global_step = checkpoint['global_step']\n","            losses = checkpoint['losses']\n","            perplexities = checkpoint['perplexities']\n","            steps = checkpoint['steps']\n","\n","            print(f\"‚úÖ Checkpoint loaded (fallback method) from step {global_step}\")\n","            if perplexities:\n","                print(f\"   Latest PPL: {perplexities[-1]:.2f}\")\n","\n","            return global_step, losses, perplexities, steps\n","        except Exception as e2:\n","            print(f\"‚ùå All checkpoint loading failed: {e2}\")\n","            return 0, [], [], []\n","\n","\n","print(\"‚úÖ Checkpoint functions updated (PyTorch 2.6+ compatible)\")\n"],"metadata":{"id":"r3ONioqJan8q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\n\" + \"=\"*70)\n","print(\"Importing AURA modules...\")\n","print(\"=\"*70)\n","\n","try:\n","    from src.core.hippocampal import HippocampalFormation\n","    from src.core.language_zone.hippocampal_transformer import HippocampalTransformer\n","    from src.training.hippocampal_trainer import HippocampalTransformerTrainer\n","    print(\"‚úÖ Imported AURA modules\")\n","except ImportError as e:\n","    print(f\"‚ùå Import failed: {e}\")\n","    print(\"Make sure AURA source code is in /content or installed\")\n","    raise\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"Initializing model...\")\n","print(\"=\"*70)\n","\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","# Create hippocampus\n","hippocampus = HippocampalFormation(\n","    config.embedding_dim,\n","    config.n_place_cells,\n","    config.n_time_cells,\n","    config.n_grid_cells\n",")\n","print(f\"‚úÖ Hippocampus initialized\")\n","print(f\"   Place cells: {config.n_place_cells}\")\n","print(f\"   Time cells: {config.n_time_cells}\")\n","print(f\"   Grid cells: {config.n_grid_cells}\")\n","\n","# Create transformer\n","model = HippocampalTransformer(config, hippocampus)\n","model = model.to(device=device, dtype=torch.bfloat16)\n","print(f\"‚úÖ HippocampalTransformer initialized\")\n","\n","# Create trainer\n","trainer = HippocampalTransformerTrainer(model, config, hippocampus)\n","print(f\"‚úÖ Trainer initialized\")\n","\n","# Create optimizer\n","optimizer = torch.optim.AdamW(\n","    model.parameters(),\n","    lr=config.lr,\n","    weight_decay=config.weight_decay,\n","    betas=(0.9, 0.95)\n",")\n","print(f\"‚úÖ Optimizer created\")\n","\n","# Create scheduler\n","def warmup_cosine(step):\n","    if step < config.warmup_steps:\n","        return (step + 1) / config.warmup_steps\n","    progress = (step - config.warmup_steps) / max(1, config.max_steps - config.warmup_steps)\n","    return 0.5 * (1 + np.cos(np.pi * progress))\n","\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, warmup_cosine)\n","print(f\"‚úÖ Scheduler created\")\n","\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"\\nüìä Model Statistics:\")\n","print(f\"   Parameters: {total_params / 1e6:.0f}M\")\n","print(f\"   GPU Memory: {torch.cuda.memory_allocated()/1e9:.2f}GB / {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\n"],"metadata":{"id":"crnDjKa6bKQH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"49d9104b"},"source":["After running the cell above, you will have updated the `hippocampal_trainer.py` file. To ensure these changes are loaded, please **re-run the following cells in your notebook**:\n","\n","1.  **Cell `2B8vZeDjXU2N`**: To re-import the updated modules.\n","2.  **Cell `crnDjKa6bKQH`**: To re-initialize the `model`, `trainer`, `optimizer`, and `scheduler` with the corrected `EWCConsolidator` instantiation.\n","3.  **Cell `ZmGnMFqonGBj`**: To resume your training with the applied fix."]},{"cell_type":"code","source":["#\n","# Recreate optimizer with new batch size\n","optimizer = torch.optim.AdamW(\n","    model.parameters(),\n","    lr=config.lr,\n","    weight_decay=config.weight_decay,\n","    betas=(0.9, 0.95)\n",")\n","print(\"‚úÖ Optimizer recreated\")\n"],"metadata":{"id":"O46GqDhRls5H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gc.collect()\n","torch.cuda.empty_cache()\n","\n","print(\"Testing new batch size...\")\n","\n","test_input = torch.randint(0, config.vocab_size, (config.batch_size, config.max_seq_len)).to(device)\n","test_prosody = torch.zeros(config.batch_size, config.max_seq_len, 4, dtype=torch.bfloat16, device=device)\n","\n","with autocast('cuda', dtype=torch.bfloat16):\n","    logits, _ = model(test_input, prosody=test_prosody, use_memory=True)\n","    loss = nn.CrossEntropyLoss()(logits.view(-1, config.vocab_size), test_input.view(-1))\n","\n","loss.backward()\n","\n","mem_used = torch.cuda.memory_allocated() / 1e9\n","mem_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n","mem_pct = (mem_used / mem_total) * 100\n","\n","print(f\"‚úÖ Test passed!\")\n","print(f\"   VRAM used: {mem_used:.2f}GB / {mem_total:.1f}GB ({mem_pct:.0f}%)\")\n","print(f\"   Headroom: {mem_total - mem_used:.2f}GB\")\n","\n","if mem_pct > 90:\n","    print(\"‚ö†Ô∏è Too high! Reduce batch_size\")\n","elif mem_pct < 50:\n","    print(\"üí° Can increase batch_size more!\")\n","else:\n","    print(\"‚úÖ Optimal utilization!\")\n","\n","del test_input, test_prosody, logits, loss\n","optimizer.zero_grad()\n","gc.collect()\n","torch.cuda.empty_cache()\n"],"metadata":{"id":"IY3kkZKHlu-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"589dbcdd"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Assuming these are defined elsewhere or imported\n","# from src.core.language_zone.hippocampal_transformer import HippocampalTransformer\n","# from src.core.hippocampal import HippocampalFormation\n","\n","class ReplayBuffer:\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.buffer = []\n","\n","    def add(self, input_ids, labels, loss):\n","        if len(self.buffer) >= self.capacity:\n","            self.buffer.pop(0)\n","        self.buffer.append((input_ids, labels, loss))\n","\n","    def sample(self, batch_size):\n","        if len(self.buffer) < batch_size:\n","            return []\n","        indices = torch.randint(len(self.buffer), (batch_size,)).tolist()\n","        return [self.buffer[i] for i in indices]\n","\n","    def __len__(self):\n","        return len(self.buffer)\n","\n","\n","class EWCConsolidator:\n","    def __init__(self, model):\n","        self.model = model\n","        self.fisher = {}\n","        self.optpar = {}\n","\n","    def compute_fisher(self, dataloader, device):\n","        original_dtype = next(self.model.parameters()).dtype\n","        # Temporarily convert model to float32 for Fisher calculation if not already\n","        if original_dtype != torch.float32:\n","            self.model.float()\n","\n","        self.model.eval() # Set model to evaluation mode\n","        fisher_accumulator = {}\n","        for n, p in self.model.named_parameters():\n","            if p.requires_grad:\n","                fisher_accumulator[n] = torch.zeros_like(p.data, dtype=torch.float32)\n","                self.optpar[n] = p.data.clone().float()\n","\n","        config = self.model.config\n","\n","        for input_ids, labels in dataloader:\n","            input_ids = input_ids.to(device)\n","            labels = labels.to(device)\n","\n","            # Create prosody. Input to model needs to be float32 for EWC pass.\n","            prosody = torch.rand(input_ids.size(0), config.max_seq_len, 4, dtype=torch.float32, device=device)\n","            # The HippocampalTransformer.forward() does not accept 'attention_mask'\n","            # attention_mask = (input_ids != 0).long().to(device) # Assuming 0 is pad_token_id\n","\n","            self.model.zero_grad()\n","            with torch.enable_grad(): # Ensure gradients are enabled for Fisher calculation\n","                # FIX: Removed 'attention_mask' argument\n","                logits, _ = self.model(input_ids, prosody=prosody, use_memory=False)\n","\n","                loss = nn.CrossEntropyLoss(reduction='mean')(\n","                    logits.view(-1, config.vocab_size),\n","                    labels.view(-1)\n","                )\n","            loss.backward()\n","\n","            for n, p in self.model.named_parameters():\n","                if p.grad is not None:\n","                    fisher_accumulator[n] += p.grad.data.pow(2)\n","\n","        # Average fisher over the dataloader size\n","        for n, f in fisher_accumulator.items():\n","            self.fisher[n] = f / len(dataloader)\n","\n","        # Restore model to original dtype if it was changed\n","        if original_dtype != torch.float32:\n","            self.model.to(dtype=original_dtype)\n","        self.model.train() # Set model back to training mode\n","\n","\n","class HippocampalTransformerTrainer:\n","    def __init__(self, model, config, hippocampus):\n","        self.model = model\n","        self.config = config\n","        self.hippocampus = hippocampus\n","        self.optimizer = None # This will be passed from the training script\n","        self.scheduler = None # This will be passed from the training script\n","\n","        self.global_step = 0\n","        self.losses = []\n","        self.perplexities = []\n","        self.steps = []\n","\n","        self.replay_buffer = ReplayBuffer(capacity=getattr(config, 'replay_buffer_size', 50000))\n","        # FIX: Removed lambda_ewc argument from EWCConsolidator instantiation\n","        self.ewc = EWCConsolidator(model)\n","\n","        self.phase = \"wake\"\n","        self.sleep_counter = 0\n","\n","    def step_counter(self):\n","        self.global_step += 1\n","        if self.global_step % self.config.sleep_interval == 0:\n","            self.phase = \"sleep\"\n","\n","    def train_step(self, input_ids, labels, prosody, attention_mask):\n","        # This method is typically called within the main training loop\n","        # and uses autocast, which is fine.\n","        pass # Actual training logic is in the main script for flexibility\n","\n","    def consolidate(self, device):\n","        # This method is called during the sleep phase\n","        # EWC is used here, ewc_lambda comes from config\n","        if self.config.use_ewc and len(self.ewc.fisher) > 0:\n","            ewc_loss = 0\n","            for n, p in self.model.named_parameters():\n","                if n in self.ewc.fisher:\n","                    ewc_loss += (self.ewc.fisher[n] * (p - self.ewc.optpar[n])**2).sum()\n","            return ewc_loss * self.config.ewc_lambda # Use config.ewc_lambda here\n","        return 0.0\n","\n","\n","# Helper for plotting - assuming it's used elsewhere for visualizations\n","def plot_metrics(losses, perplexities, steps):\n","    # This is a placeholder, actual plotting would depend on matplotlib/seaborn etc.\n","    print(\"Plotting functionality not implemented in trainer.py\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9603c07c"},"source":["After running the cell above, you will have updated the `hippocampal_trainer.py` file. To ensure these changes are loaded, please **re-run the following cells in your notebook**:\n","\n","1.  **Cell `2B8vZeDjXU2N`**: To re-import the updated modules.\n","2.  **Cell `crnDjKa6bKQH`**: To re-initialize the `model`, `trainer`, `optimizer`, and `scheduler` with the corrected `EWCConsolidator` instantiation.\n","3.  **Cell `ZmGnMFqonGBj`**: To resume your training with the applied fix."]},{"cell_type":"code","source":["import threading\n","import time\n","from datetime import datetime\n","\n","# Stop any existing monitor\n","monitor_running = False\n","global_step = 0\n","\n","def background_monitor():\n","    \"\"\"Run monitoring in background thread\"\"\"\n","    global monitor_running\n","    monitor_running = True\n","\n","    while monitor_running and global_step < config.max_steps:\n","        try:\n","            # Get current state\n","            step = global_step\n","            loss = losses[-1] if losses else 0\n","            ppl = perplexities[-1] if perplexities else 0\n","            best_ppl = min(perplexities) if perplexities else 0\n","            mem_count = len(hippocampus.episodic_memories)\n","            buf_size = len(trainer.replay_buffer)\n","            phase = trainer.phase\n","\n","            # Calculate ETA\n","            if step > 0:\n","                eta_hours = (config.max_steps - step) / 66 / 60\n","            else:\n","                eta_hours = 0\n","\n","            # Print status\n","            timestamp = datetime.now().strftime(\"%H:%M:%S\")\n","            print(f\"\\n[{timestamp}] Step: {step:,}/50k | Loss: {loss:.3f} | PPL: {ppl:.2f} | Best: {best_ppl:.2f}\")\n","            print(f\"           Mem: {mem_count} | Buf: {buf_size:,} | Phase: {phase} | ETA: {eta_hours:.1f}h\")\n","\n","            time.sleep(60)  # Check every 60 seconds\n","\n","        except Exception as e:\n","            print(f\"Monitor error: {e}\")\n","            time.sleep(60)\n","\n","    print(\"\\n‚úÖ Monitor finished\")\n","\n","# Start background thread\n","monitor_thread = threading.Thread(target=background_monitor, daemon=True)\n","monitor_thread.start()\n","\n","print(\"‚úÖ Background monitor started (checks every 60 seconds)\")\n","print(\"   Training will continue in parallel\")\n"],"metadata":{"id":"-VneWfj8w1O1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CELL D1: Diagnose the issue\n","print(\"=\"*70)\n","print(\"DIAGNOSING REPETITION ISSUE\")\n","print(\"=\"*70)\n","\n","# Check what the model is actually outputting\n","model.eval()\n","test_prompt = \"The history of\"\n","test_ids = sp.encode(test_prompt, out_type=int)\n","input_ids = torch.tensor([test_ids], dtype=torch.long).to(device)\n","\n","with torch.no_grad():\n","    with autocast('cuda', dtype=torch.bfloat16):\n","        prosody = torch.randn(1, len(test_ids), 4, dtype=torch.bfloat16, device=device)\n","        logits, _ = model(input_ids, prosody=prosody, use_memory=True)\n","\n","        # Check the probability distribution\n","        probs = torch.softmax(logits[0, -1, :], dim=-1)\n","        top_k_probs, top_k_indices = torch.topk(probs, 10)\n","\n","        print(\"\\nTop 10 predictions for next token:\")\n","        for prob, idx in zip(top_k_probs, top_k_indices):\n","            token_str = sp.id_to_piece(idx.item())\n","            print(f\"  {token_str:20} : {prob.item():.4f}\")\n","\n","        # Check entropy\n","        entropy = -torch.sum(probs * torch.log(probs + 1e-10))\n","        print(f\"\\nEntropy: {entropy.item():.2f} (should be 2-5)\")\n","        print(f\"Max prob: {probs.max().item():.4f} (should be < 0.5)\")\n","\n","        if probs.max().item() > 0.8:\n","            print(\"\\n‚ö†Ô∏è WARNING: Model is outputting one token with >80% probability!\")\n","            print(\"   This causes repetition. The model may be underfitting or\")\n","            print(\"   the learning rate might be too high causing instability.\")\n","\n","model.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1o2ip_wGSU5B","executionInfo":{"status":"ok","timestamp":1764255632273,"user_tz":300,"elapsed":65,"user":{"displayName":"Nicolas Cloutier","userId":"10242568199473316524"}},"outputId":"1cc76ac3-82a1-454c-c259-b63f3710a52d"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","DIAGNOSING REPETITION ISSUE\n","======================================================================\n","\n","Top 10 predictions for next token:\n","  ‚ñÅof                  : 0.8787\n","  ‚ñÅthe                 : 0.0006\n","  ‚ñÅ                    : 0.0004\n","  s                    : 0.0004\n","  ‚ñÅis                  : 0.0003\n","  ‚ñÅfor                 : 0.0003\n","  ‚ñÅto                  : 0.0002\n","  ,                    : 0.0002\n","  ‚ñÅare                 : 0.0002\n","  ‚ñÅit                  : 0.0002\n","\n","Entropy: 1.60 (should be 2-5)\n","Max prob: 0.8787 (should be < 0.5)\n","\n","‚ö†Ô∏è WARNING: Model is outputting one token with >80% probability!\n","   This causes repetition. The model may be underfitting or\n","   the learning rate might be too high causing instability.\n"]},{"output_type":"execute_result","data":{"text/plain":["HippocampalTransformer(\n","  (pos_encoder): ThetaGammaPositionalEncoding(embedding_dim=768, theta_freq=8.0Hz, gamma_freq=40.0Hz, freq_ratio=5.0)\n","  (semantic_encoder): PlaceCellSemanticEncoder(\n","    vocab_size=32000, embedding_dim=768, n_place_cells=2000, sparsity=3.0% (k=60)\n","    (token_embedding): Embedding(32000, 768)\n","    (semantic_projection): Linear(in_features=768, out_features=2000, bias=True)\n","    (place_to_semantic): Linear(in_features=2000, out_features=768, bias=True)\n","  )\n","  (dropout): Dropout(p=0.15, inplace=False)\n","  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  (layers): ModuleList(\n","    (0-11): 12 x HippocampalTransformerLayer(\n","      (attention_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (attention): HippocampalProsodyAttention(\n","        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (o_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (prosody_gate): Linear(in_features=4, out_features=16, bias=True)\n","        (memory_gate): Linear(in_features=768, out_features=1, bias=True)\n","        (dropout): Dropout(p=0.15, inplace=False)\n","      )\n","      (ffn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (ffn): Sequential(\n","        (0): Linear(in_features=768, out_features=4096, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Linear(in_features=4096, out_features=768, bias=True)\n","        (3): Dropout(p=0.15, inplace=False)\n","      )\n","      (dropout): Dropout(p=0.15, inplace=False)\n","    )\n","  )\n","  (output_head): Linear(in_features=768, out_features=32000, bias=False)\n",")"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# The problem: softmax is collapsing to near-zero for all but one token\n","# Solution: Better numerical stability + prevent degenerate distributions\n","\n","print(\"=\"*70)\n","print(\"FIXING NUMERICAL STABILITY\")\n","print(\"=\"*70)\n","\n","# Check if this is a training data issue\n","print(f\"\\nCurrent training stats:\")\n","print(f\"  Step: {global_step}\")\n","print(f\"  Loss: {losses[-1]:.3f}\")\n","print(f\"  PPL: {math.exp(min(losses[-1], 20)):.2f}\")\n","print(f\"  Eval PPL: {perplexities[-1] if perplexities else 'N/A'}\")\n","\n","# The model learned that \"The history of\" ‚Üí \"of\" is common\n","# This is actually partially correct! But the issue is:\n","# 1. Softmax is numerically unstable (other tokens are exactly 0.0000)\n","# 2. Need to add eps to prevent this\n","\n","print(\"\\n‚ö†Ô∏è DIAGNOSIS:\")\n","print(\"  ‚Ä¢ Model learned that after 'The history of' ‚Üí next word is 'of'\")\n","print(\"  ‚Ä¢ This is in the training data ('The history of history')\")\n","print(\"  ‚Ä¢ But softmax collapsed all other tokens to exactly 0\")\n","print(\"  ‚Ä¢ This causes generation to repeat the same token\")\n","\n","print(\"\\nüí° SOLUTION:\")\n","print(\"  ‚Ä¢ Reduce model size (12 layers might be overcapacity for 2200 steps)\")\n","print(\"  ‚Ä¢ Or continue training - by step 10000+, model will learn better\")\n","print(\"  ‚Ä¢ Or lower learning rate to prevent oscillation\")\n","\n","# For now, add numerical stability to generation\n","print(\"\\n\" + \"=\"*70)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jtcOfIeS6hB","executionInfo":{"status":"ok","timestamp":1764255618141,"user_tz":300,"elapsed":12,"user":{"displayName":"Nicolas Cloutier","userId":"10242568199473316524"}},"outputId":"5393e003-3fd3-4765-aadb-4579105c0175"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","FIXING NUMERICAL STABILITY\n","======================================================================\n","\n","Current training stats:\n","  Step: 11678\n","  Loss: 1.448\n","  PPL: 4.25\n","  Eval PPL: 1.1504640644594604\n","\n","‚ö†Ô∏è DIAGNOSIS:\n","  ‚Ä¢ Model learned that after 'The history of' ‚Üí next word is 'of'\n","  ‚Ä¢ This is in the training data ('The history of history')\n","  ‚Ä¢ But softmax collapsed all other tokens to exactly 0\n","  ‚Ä¢ This causes generation to repeat the same token\n","\n","üí° SOLUTION:\n","  ‚Ä¢ Reduce model size (12 layers might be overcapacity for 2200 steps)\n","  ‚Ä¢ Or continue training - by step 10000+, model will learn better\n","  ‚Ä¢ Or lower learning rate to prevent oscillation\n","\n","======================================================================\n"]}]},{"cell_type":"code","source":["import threading\n","import time\n","from datetime import datetime\n","\n","generation_running = False\n","\n","def generate_text_stable(prompt, max_tokens=50, temperature=1.0):\n","    \"\"\"Generate with numerical stability\"\"\"\n","    try:\n","        model.eval()\n","\n","        token_ids = sp.encode(prompt, out_type=int)\n","        input_ids = torch.tensor([token_ids], dtype=torch.long).to(device)\n","        generated_tokens = list(token_ids)\n","\n","        with torch.no_grad():\n","            with autocast('cuda', dtype=torch.bfloat16):\n","                for step in range(max_tokens):\n","                    if input_ids.shape[1] > config.max_seq_len:\n","                        input_ids = input_ids[:, -config.max_seq_len:]\n","\n","                    prosody = torch.randn(1, input_ids.shape[1], 4, dtype=torch.bfloat16, device=device)\n","                    logits, _ = model(input_ids, prosody=prosody, use_memory=True)\n","                    logits = logits[0, -1, :].float()\n","\n","                    # ===== NUMERICAL STABILITY FIX =====\n","                    # Subtract max to prevent overflow\n","                    logits = logits - logits.max()\n","\n","                    # Apply temperature\n","                    logits = logits / temperature\n","\n","                    # Convert to probabilities with numerical stability\n","                    # Use log_softmax to prevent underflow\n","                    log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n","                    probs = torch.exp(log_probs)\n","\n","                    # Add small epsilon to prevent exact zeros\n","                    probs = probs + 1e-10\n","                    probs = probs / probs.sum()\n","\n","                    # ===== BLOCK LAST 5 TOKENS =====\n","                    for token in generated_tokens[-5:]:\n","                        probs[token] = 1e-10\n","                    probs = probs / probs.sum()\n","\n","                    # Sample\n","                    next_token = torch.multinomial(probs, 1)[0]\n","\n","                    if next_token.item() == sp.eos_id():\n","                        break\n","\n","                    generated_tokens.append(next_token.item())\n","                    input_ids = torch.cat([input_ids, next_token.unsqueeze(0).unsqueeze(0)], dim=1)\n","\n","        result = sp.decode(generated_tokens)\n","        model.train()\n","        return result\n","    except Exception as e:\n","        return f\"[Error]\"\n","\n","\n","def background_generation_monitor():\n","    \"\"\"Monitor generation\"\"\"\n","    global generation_running\n","    generation_running = True\n","\n","prompts = [\n","        \"The history of\",\n","        \"In the future\",\n","        \"Neural networks\",\n","        \"Machine learning\",\n","        \"Deep learning\"\n","]\n","\n","\n","for p in prompts:\n","                gen = generate_text_stable(p, max_tokens=25, temperature=0.8)\n","                print(f\"  '{p}' ‚Üí '{gen[:70]}...'\")\n","\n","print(\"‚úÖ Numerically Stable Generation Monitor\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fukhoRcOTFzV","executionInfo":{"status":"ok","timestamp":1764255709439,"user_tz":300,"elapsed":2032,"user":{"displayName":"Nicolas Cloutier","userId":"10242568199473316524"}},"outputId":"b4017d1a-5a30-4af1-c827-ebf1ee61cbe0"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["  'The history of' ‚Üí 'The history of Ingredient W stage Evolution blondeberry Ele Effectplea...'\n","  'In the future' ‚Üí 'In the future st√§ndig rug Shot frustrating resurse qualitiesblin Flexi...'\n","  'Neural networks' ‚Üí 'Neural networks comparison aggregate Tab stalk Cash digestion Perhaps ...'\n","  'Machine learning' ‚Üí 'Machine learning Bangladesh Joshua Numbershi diverizer son Practicalas...'\n","  'Deep learning' ‚Üí 'Deep learning pipesProf density entsteht TopicBR needlecriticalinscrit...'\n","‚úÖ Numerically Stable Generation Monitor\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# ADVANCED OPTIMIZATION METHODS\n","# ============================================================================\n","\n","print(\"=\"*70)\n","print(\"ADDING OPTIMIZATION METHODS\")\n","print(\"=\"*70)\n","\n","# 1. Update config with regularization\n","config.weight_decay = 0.1        # L2 regularization (already in AdamW)\n","config.label_smoothing = 0.1     # Reduce from 0.2 (was too aggressive)\n","config.dropout = 0.1             # Reduce dropout (was 0.15)\n","config.gradient_clip = 1.0       # Gradient clipping\n","\n","# 2. Add new optimization flags\n","config.use_cosine_annealing = True\n","config.use_gradient_checkpointing = False  # Enable if OOM\n","config.warmup_ratio = 0.06       # 6% warmup\n","\n","print(f\"‚úÖ Config updated:\")\n","print(f\"   Weight decay (L2): {config.weight_decay}\")\n","print(f\"   Label smoothing: {config.label_smoothing}\")\n","print(f\"   Dropout: {config.dropout}\")\n","print(f\"   Gradient clip: {config.gradient_clip}\")\n","\n","\n","# 3. Create optimized optimizer with weight decay groups\n","def create_optimizer_with_weight_decay(model, lr, weight_decay):\n","    \"\"\"\n","    Separate parameters into groups:\n","    - With weight decay: Linear layers (L2 regularization)\n","    - Without weight decay: LayerNorm, biases, embeddings\n","    \"\"\"\n","    decay_params = []\n","    no_decay_params = []\n","\n","    for name, param in model.named_parameters():\n","        if not param.requires_grad:\n","            continue\n","\n","        # No weight decay on: biases, LayerNorm, embeddings\n","        if 'bias' in name or 'norm' in name or 'embedding' in name:\n","            no_decay_params.append(param)\n","        else:\n","            decay_params.append(param)\n","\n","    optimizer_groups = [\n","        {'params': decay_params, 'weight_decay': weight_decay},\n","        {'params': no_decay_params, 'weight_decay': 0.0}\n","    ]\n","\n","    optimizer = torch.optim.AdamW(\n","        optimizer_groups,\n","        lr=lr,\n","        betas=(0.9, 0.95),\n","        eps=1e-8\n","    )\n","\n","    print(f\"   Decay params: {len(decay_params)} tensors\")\n","    print(f\"   No-decay params: {len(no_decay_params)} tensors\")\n","\n","    return optimizer\n","\n","\n","# 4. Create new optimizer\n","print(f\"\\nüîß Creating optimized AdamW with L2 regularization...\")\n","optimizer = create_optimizer_with_weight_decay(model, config.lr, config.weight_decay)\n","print(f\"‚úÖ Optimizer created\")\n","\n","\n","# 5. Warmup + Cosine Annealing with Restarts\n","def warmup_cosine_with_min_lr(step, warmup_steps, max_steps, min_lr_ratio=0.1):\n","    \"\"\"\n","    Warmup + Cosine decay with minimum LR floor\n","    \"\"\"\n","    if step < warmup_steps:\n","        return (step + 1) / warmup_steps\n","\n","    progress = (step - warmup_steps) / max(1, max_steps - warmup_steps)\n","    cosine_decay = 0.5 * (1 + math.cos(math.pi * progress))\n","\n","    # Floor at min_lr_ratio (10% of peak)\n","    return min_lr_ratio + (1 - min_lr_ratio) * cosine_decay\n","\n","\n","scheduler = torch.optim.lr_scheduler.LambdaLR(\n","    optimizer,\n","    lambda step: warmup_cosine_with_min_lr(step, config.warmup_steps, config.max_steps, min_lr_ratio=0.1)\n",")\n","\n","# Step to current position\n","for _ in range(global_step):\n","    scheduler.step()\n","\n","print(f\"‚úÖ Scheduler created with LR floor at 10%\")\n","print(f\"   Current LR: {scheduler.get_last_lr()[0]:.2e}\")\n","\n","print(\"=\"*70)\n"],"metadata":{"id":"mLCdfRd1kqeX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optional: Stochastic Weight Averaging for better generalization\n","from torch.optim.swa_utils import AveragedModel, SWALR\n","\n","# Enable SWA after 20% of training\n","swa_start_step = int(config.max_steps * 0.2)\n","use_swa = True\n","\n","if use_swa:\n","    swa_model = AveragedModel(model)\n","    swa_scheduler = SWALR(optimizer, swa_lr=1e-5)\n","    print(f\"‚úÖ SWA enabled (starts at step {swa_start_step})\")\n","else:\n","    swa_model = None\n","    print(\"‚ö†Ô∏è SWA disabled\")\n"],"metadata":{"id":"-Z5Cg3-Okx6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","print(\"=\"*70)\n","print(\"üöÄ OPTIMIZED L4 CONFIG\")\n","print(\"=\"*70)\n","print(f\"Batch size: {config.batch_size} (4x increase)\")\n","print(f\"Gradient accumulation: {config.gradient_accumulation}\")\n","print(f\"Effective batch: {config.batch_size * config.gradient_accumulation}\")\n","print(f\"Replay buffer: {config.replay_buffer_size}\")\n","print(f\"Expected VRAM: ~16-18GB\")\n","print(\"=\"*70 + \"\\n\")\n","\n","optimizer.zero_grad()\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","\n","\n","latest_checkpoint = os.path.join(CHECKPOINT_DIR, 'checkpoint_step_2000.pt')\n","\n","\n","# Reload checkpoint with new optimizer\n","global_step, losses, perplexities, steps = load_checkpoint(\n","    latest_checkpoint, model, optimizer, scheduler\n",")\n","\n","print(f\"‚úÖ Resumed from step {global_step}\")\n","print(f\"   Batch: {config.batch_size} √ó {config.gradient_accumulation}\")\n","\n","# ===== START OPTIMIZED TRAINING =====\n","print(\"\\n\" + \"=\"*70)\n","print(\"üöÄ RESUMING TRAINING (OPTIMIZED)\")\n","print(\"=\"*70)\n","\n","accumulation_step = 0\n","train_gen = create_batches_sentencepiece_streaming(\n","    dataset, sp, config,\n","    max_batches=(config.max_steps - global_step) * config.gradient_accumulation\n",")\n","\n","pbar = tqdm(total=config.max_steps - global_step, desc=\"Training (Optimized)\")\n","model.train()\n","start_time = time.time()\n","\n","try:\n","    for input_ids, labels, prosody, attention_mask in train_gen:\n","        accumulation_step += 1\n","\n","        input_ids = input_ids.to(device, non_blocking=True)\n","        labels = labels.to(device, non_blocking=True)\n","        prosody = prosody.to(device, dtype=torch.bfloat16, non_blocking=True)\n","\n","        # ===== WAKE PHASE =====\n","        if trainer.phase == \"wake\":\n","            try:\n","                with autocast('cuda', dtype=torch.bfloat16):\n","                    logits, place_cell_activity = model(input_ids, prosody=prosody, use_memory=True)\n","                    loss = nn.CrossEntropyLoss(label_smoothing=config.label_smoothing)(\n","                        logits.view(-1, config.vocab_size),\n","                        labels.view(-1)\n","                    )\n","\n","               # Gradient accumulation\n","                scaled_loss = loss / config.gradient_accumulation\n","                scaled_loss.backward()\n","\n","                if accumulation_step % config.gradient_accumulation == 0:\n","                    global_step += 1\n","                    trainer.step_counter()\n","\n","                    # ===== GRADIENT CLIPPING =====\n","                    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)\n","\n","                    optimizer.step()\n","\n","                    # ===== SWA UPDATE (if enabled) =====\n","                    if use_swa and global_step >= swa_start_step:\n","                        swa_model.update_parameters(model)\n","                        swa_scheduler.step()\n","                    else:\n","                        scheduler.step()\n","\n","                    optimizer.zero_grad(set_to_none=True)\n","\n","                    # Track gradient norm for debugging\n","                    if global_step % 100 == 0:\n","                        print(f\"   Grad norm: {grad_norm:.2f}\")\n","                    losses.append(loss.item())\n","\n","                    # Store in replay buffer\n","                    if global_step % 2 == 0:\n","                        trainer.replay_buffer.add(\n","                            input_ids.detach().cpu(),\n","                            labels.detach().cpu(),\n","                            loss.item()\n","                        )\n","\n","                    elapsed = time.time() - start_time\n","                    speed = global_step / elapsed if elapsed > 0 else 0\n","                    current_lr = scheduler.get_last_lr()[0]\n","                    mem_used = torch.cuda.memory_allocated() / 1e9\n","\n","                    pbar.set_postfix({\n","                        'loss': f\"{loss.item():.3f}\",\n","                        'lr': f\"{current_lr:.2e}\",\n","                        'it/s': f\"{speed:.2f}\",\n","                        'mem': f\"{mem_used:.1f}GB\",\n","                        'mem_count': len(hippocampus.episodic_memories)\n","                    })\n","\n","                    # ===== EPISODIC MEMORY CREATION =====\n","                    if global_step % config.memory_creation_interval == 0:\n","                        with torch.no_grad():\n","                            feats = place_cell_activity.float().mean(dim=0).cpu().numpy()\n","\n","                        hippocampus.create_episodic_memory(\n","                            memory_id=f\"step_{global_step}\",\n","                            event_id=f\"train_{global_step}\",\n","                            features=feats,\n","                            associated_experts=None\n","                        )\n","\n","                    # ===== EVALUATION =====\n","                    if global_step % config.eval_interval == 0:\n","                        model.eval()\n","                        eval_loss = 0\n","                        eval_count = 0\n","\n","                        with torch.no_grad():\n","                            for sample in dataset:\n","                                if eval_count >= 20:\n","                                    break\n","\n","                                text = None\n","                                for field in ['text', 'content', 'document', 'body']:\n","                                    if field in sample:\n","                                        text = sample[field]\n","                                        break\n","\n","                                if not text or len(str(text).strip()) < 50:\n","                                    continue\n","\n","                                try:\n","                                    token_ids = sp.encode(str(text), out_type=int)\n","                                    if len(token_ids) < 10:\n","                                        continue\n","                                    if len(token_ids) > config.max_seq_len:\n","                                        token_ids = token_ids[:config.max_seq_len]\n","                                    pad_len = config.max_seq_len - len(token_ids)\n","                                    token_ids = token_ids + [sp.pad_id()] * pad_len\n","\n","                                    eval_input = torch.tensor([token_ids], dtype=torch.long).to(device)\n","                                    eval_labels = eval_input.clone()\n","                                    eval_labels[eval_input == sp.pad_id()] = -100\n","                                    eval_prosody = torch.zeros(1, config.max_seq_len, 4, dtype=torch.bfloat16, device=device)\n","\n","                                    with autocast('cuda', dtype=torch.bfloat16):\n","                                        eval_logits, _ = model(eval_input, prosody=eval_prosody, use_memory=True)\n","                                        batch_loss = nn.CrossEntropyLoss()(\n","                                            eval_logits.view(-1, config.vocab_size),\n","                                            eval_labels.view(-1)\n","                                        )\n","\n","                                    if not torch.isnan(batch_loss):\n","                                        eval_loss += batch_loss.item()\n","                                        eval_count += 1\n","                                except:\n","                                    continue\n","\n","                        ppl = math.exp(min(eval_loss / max(eval_count, 1), 20))\n","                        perplexities.append(ppl)\n","                        steps.append(global_step)\n","\n","                        train_ppl = math.exp(min(sum(losses[-50:])/min(len(losses),50), 20))\n","                        print(f\"\\nüìä Step {global_step}: Train PPL={train_ppl:.2f} | Eval PPL={ppl:.2f} | LR={current_lr:.2e}\")\n","                        print(f\"   VRAM: {mem_used:.1f}GB | Memories: {len(hippocampus.episodic_memories)} | Buffer: {len(trainer.replay_buffer)}\")\n","\n","                        model.train()\n","\n","                    # ===== CHECKPOINTING =====\n","                    if global_step % 500 == 0:\n","                        save_checkpoint(model, optimizer, scheduler, hippocampus, trainer,\n","                                      global_step, losses, perplexities, steps, config)\n","\n","                    if perplexities and perplexities[-1] == min(perplexities):\n","                        best_path = os.path.join(CHECKPOINT_DIR, 'checkpoint_best.pt')\n","                        torch.save({\n","                            'model_state_dict': model.state_dict(),\n","                            'global_step': global_step,\n","                            'ppl': perplexities[-1]\n","                        }, best_path)\n","                        print(f\"üèÜ Best: PPL={perplexities[-1]:.2f}\")\n","\n","                    pbar.update(1)\n","\n","                    if global_step >= config.max_steps:\n","                        break\n","\n","            except RuntimeError as e:\n","                if \"out of memory\" in str(e):\n","                    print(f\"\\n‚ö†Ô∏è OOM at step {global_step}\")\n","                    print(\"Reduce batch_size in config\")\n","                    optimizer.zero_grad(set_to_none=True)\n","                    gc.collect()\n","                    torch.cuda.empty_cache()\n","                    break\n","                else:\n","                    raise\n","            except Exception as e:\n","                print(f\"\\n‚ùå Error: {e}\")\n","                traceback.print_exc()\n","                break\n","\n","        # ===== SLEEP PHASE =====\n","        elif trainer.phase == \"sleep\":\n","            print(f\"\\nüåô Sleep Phase at step {global_step} - Memory Consolidation\")\n","            try:\n","                gc.collect()\n","                torch.cuda.empty_cache()\n","\n","                # ===== FISHER INFORMATION COMPUTATION =====\n","                if not trainer.ewc.fisher and len(trainer.replay_buffer) > 0 and config.use_ewc:\n","                    print(\"  üìç Computing Fisher Information (Elastic Weight Consolidation)...\")\n","                    try:\n","                        samples = trainer.replay_buffer.sample(min(20, len(trainer.replay_buffer)))\n","                        mock_loader = [(s[0].unsqueeze(0).to(device), s[1].unsqueeze(0).to(device)) for s in samples]\n","\n","                        # ===== FIX: Convert to float32 for Fisher computation =====\n","                        model.float()  # Temporary conversion\n","                        trainer.ewc.compute_fisher(mock_loader, device=device)\n","                        model.to(dtype=torch.bfloat16)  # Convert back to bfloat16\n","\n","                        print(\"  ‚úÖ Fisher Information computed\")\n","                    except Exception as e:\n","                        print(f\"  ‚ö†Ô∏è Fisher computation skipped: {e}\")\n","                        model.to(dtype=torch.bfloat16)  # Ensure model is back to bfloat16\n","\n","                # ===== EXPERIENCE REPLAY WITH BACKWARD REPLAYS =====\n","                print(f\"  üîÑ Replaying {config.sleep_steps} batches from memory...\")\n","                replay_count = 0\n","\n","                for i in range(config.sleep_steps):\n","                    try:\n","                        samples = trainer.replay_buffer.sample(config.batch_size)\n","                        if not samples or len(samples) < 2:\n","                            continue\n","\n","                        replay_in = torch.stack([s[0] for s in samples]).to(device)\n","                        replay_lab = torch.stack([s[1] for s in samples]).to(device)\n","\n","                        # Backward replay: temporal reversal for memory consolidation\n","                        if i % 5 >= 3:\n","                            replay_in = torch.flip(replay_in, [0])\n","\n","                        optimizer.zero_grad(set_to_none=True)\n","\n","                        with autocast('cuda', dtype=torch.bfloat16):\n","                            out, _ = model(replay_in, use_memory=True)\n","                            r_loss = nn.CrossEntropyLoss(label_smoothing=config.label_smoothing)(\n","                                out.view(-1, config.vocab_size),\n","                                replay_lab.view(-1)\n","                            )\n","\n","                        # Reduced learning for replay (0.1x)\n","                        (r_loss * 0.1).backward()\n","                        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","                        optimizer.step()\n","                        replay_count += 1\n","                    except:\n","                        continue\n","\n","                print(f\"  ‚úÖ Replay complete: {replay_count}/{config.sleep_steps} batches\")\n","                        # Memory Decay\n","                try:\n","                    hippocampus.decay_memories(decay_rate=config.memory_decay_rate)\n","                    print(f\"  üìâ Memory decay | Memories: {len(hippocampus.episodic_memories)}\")\n","                except Exception as e:\n","                    print(f\"  ‚ö†Ô∏è Decay failed: {e}\")\n","\n","                trainer.phase = \"wake\"\n","                gc.collect()\n","                torch.cuda.empty_cache()\n","\n","            except Exception as e:\n","                print(f\"\\n‚ùå Sleep error: {e}\")\n","                traceback.print_exc()\n","                trainer.phase = \"wake\"\n","\n","except KeyboardInterrupt:\n","    print(\"\\n‚èπÔ∏è Interrupted\")\n","    save_checkpoint(model, optimizer, scheduler, hippocampus, trainer,\n","                  global_step, losses, perplexities, steps, config)\n","    print(\"‚úÖ Checkpoint saved\")\n","\n","except Exception as e:\n","    print(f\"\\n‚ùå Fatal: {e}\")\n","    traceback.print_exc()\n","    save_checkpoint(model, optimizer, scheduler, hippocampus, trainer,\n","                  global_step, losses, perplexities, steps, config)\n","\n","finally:\n","    pbar.close()\n","    elapsed_time = time.time() - start_time\n","\n","    save_checkpoint(model, optimizer, scheduler, hippocampus, trainer,\n","                   global_step, losses, perplexities, steps, config)\n","\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"‚úÖ TRAINING COMPLETE (OPTIMIZED)\")\n","    print(\"=\"*70)\n","    print(f\"‚è±Ô∏è  Total Time: {elapsed_time/3600:.2f} hours\")\n","    print(f\"üìä Steps: {global_step}/{config.max_steps}\")\n","    print(f\"üöÄ Speed: {global_step / elapsed_time:.2f} it/s\")\n","    print(f\"üß† Memories: {len(hippocampus.episodic_memories)}\")\n","\n","    if perplexities:\n","        train_ppl = math.exp(min(sum(losses[-50:])/min(len(losses),50), 20))\n","        print(f\"üìà Final Train PPL: {train_ppl:.2f}\")\n","        print(f\"üìà Final Eval PPL: {perplexities[-1]:.2f}\")\n","        print(f\"üìà Best PPL: {min(perplexities):.2f}\")\n","\n","    print(f\"üíæ Checkpoints: {CHECKPOINT_DIR}\")\n","    print(\"=\"*70)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZmGnMFqonGBj","executionInfo":{"status":"ok","timestamp":1764255387086,"user_tz":300,"elapsed":27195223,"user":{"displayName":"Nicolas Cloutier","userId":"10242568199473316524"}},"outputId":"64afd5e5-5f6c-4e8e-b7b7-3bd48f960be2"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["Training (Optimized):  12%|‚ñà‚ñè        | 6059/50000 [2:44:34<18:04:51,  1.48s/it, loss=1.421, lr=2.94e-04, it/s=0.61, mem=3.7GB, mem_count=1211]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:23:38] Step: 6,060/50k | Loss: 1.421 | PPL: 1.17 | Best: 1.14\n","           Mem: 1212 | Buf: 48,480 | Phase: wake | ETA: 11.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  12%|‚ñà‚ñè        | 6084/50000 [2:45:36<17:51:37,  1.46s/it, loss=1.450, lr=2.94e-04, it/s=0.61, mem=3.7GB, mem_count=1216]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:24:38] Step: 6,085/50k | Loss: 1.450 | PPL: 1.17 | Best: 1.14\n","           Mem: 1217 | Buf: 48,672 | Phase: wake | ETA: 11.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  12%|‚ñà‚ñè        | 6097/50000 [2:46:11<27:59:31,  2.30s/it, loss=1.431, lr=2.94e-04, it/s=0.61, mem=3.7GB, mem_count=1219]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 6100\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  12%|‚ñà‚ñè        | 6099/50000 [2:46:13<18:08:02,  1.49s/it, loss=1.471, lr=2.94e-04, it/s=0.61, mem=3.7GB, mem_count=1219]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.68\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  12%|‚ñà‚ñè        | 6100/50000 [2:46:32<85:01:52,  6.97s/it, loss=1.471, lr=2.94e-04, it/s=0.61, mem=3.7GB, mem_count=1219]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 6100: Train PPL=4.24 | Eval PPL=1.15 | LR=2.94e-04\n","   VRAM: 3.7GB | Memories: 1220 | Buffer: 48800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  12%|‚ñà‚ñè        | 6104/50000 [2:46:36<27:14:29,  2.23s/it, loss=1.459, lr=2.94e-04, it/s=0.61, mem=3.7GB, mem_count=1220]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:25:38] Step: 6,105/50k | Loss: 1.459 | PPL: 1.15 | Best: 1.14\n","           Mem: 1221 | Buf: 48,832 | Phase: wake | ETA: 11.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  12%|‚ñà‚ñè        | 6129/50000 [2:47:38<17:58:44,  1.48s/it, loss=1.445, lr=2.94e-04, it/s=0.61, mem=3.7GB, mem_count=1225]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:26:38] Step: 6,129/50k | Loss: 1.445 | PPL: 1.15 | Best: 1.14\n","           Mem: 1225 | Buf: 49,024 | Phase: wake | ETA: 11.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  12%|‚ñà‚ñè        | 6149/50000 [2:48:29<18:03:34,  1.48s/it, loss=1.449, lr=2.94e-04, it/s=0.61, mem=3.7GB, mem_count=1229]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:27:38] Step: 6,150/50k | Loss: 1.449 | PPL: 1.15 | Best: 1.14\n","           Mem: 1230 | Buf: 49,200 | Phase: wake | ETA: 11.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  12%|‚ñà‚ñè        | 6174/50000 [2:49:32<18:12:33,  1.50s/it, loss=1.443, lr=2.94e-04, it/s=0.61, mem=3.7GB, mem_count=1234]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:28:38] Step: 6,175/50k | Loss: 1.443 | PPL: 1.15 | Best: 1.14\n","           Mem: 1235 | Buf: 49,392 | Phase: wake | ETA: 11.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  12%|‚ñà‚ñè        | 6197/50000 [2:50:33<28:13:55,  2.32s/it, loss=1.452, lr=2.94e-04, it/s=0.61, mem=3.7GB, mem_count=1239]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 6200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  12%|‚ñà‚ñè        | 6199/50000 [2:50:36<18:12:36,  1.50s/it, loss=1.450, lr=2.94e-04, it/s=0.61, mem=3.7GB, mem_count=1239]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.49\n","\n","[07:29:38] Step: 6,200/50k | Loss: 1.450 | PPL: 1.15 | Best: 1.14\n","           Mem: 1240 | Buf: 49,600 | Phase: wake | ETA: 11.1h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  12%|‚ñà‚ñè        | 6200/50000 [2:50:59<99:15:58,  8.16s/it, loss=1.450, lr=2.94e-04, it/s=0.61, mem=3.7GB, mem_count=1239]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 6200: Train PPL=4.27 | Eval PPL=1.16 | LR=2.94e-04\n","   VRAM: 3.7GB | Memories: 1240 | Buffer: 49600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  12%|‚ñà‚ñè        | 6215/50000 [2:51:37<50:12:56,  4.13s/it, loss=1.446, lr=2.94e-04, it/s=0.60, mem=3.7GB, mem_count=1242]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:30:38] Step: 6,215/50k | Loss: 1.446 | PPL: 1.16 | Best: 1.14\n","           Mem: 1243 | Buf: 49,712 | Phase: wake | ETA: 11.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  12%|‚ñà‚ñè        | 6239/50000 [2:52:32<18:10:10,  1.49s/it, loss=1.438, lr=2.94e-04, it/s=0.60, mem=3.7GB, mem_count=1247]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:31:38] Step: 6,240/50k | Loss: 1.438 | PPL: 1.16 | Best: 1.14\n","           Mem: 1248 | Buf: 49,920 | Phase: wake | ETA: 11.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6264/50000 [2:53:37<18:18:38,  1.51s/it, loss=1.437, lr=2.94e-04, it/s=0.60, mem=3.7GB, mem_count=1252]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:32:38] Step: 6,265/50k | Loss: 1.437 | PPL: 1.16 | Best: 1.14\n","           Mem: 1253 | Buf: 50,112 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6284/50000 [2:54:30<18:43:40,  1.54s/it, loss=1.446, lr=2.94e-04, it/s=0.60, mem=3.7GB, mem_count=1256]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:33:38] Step: 6,285/50k | Loss: 1.446 | PPL: 1.16 | Best: 1.14\n","           Mem: 1257 | Buf: 50,272 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6297/50000 [2:55:07<28:50:46,  2.38s/it, loss=1.444, lr=2.94e-04, it/s=0.60, mem=3.7GB, mem_count=1259]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 6300\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6299/50000 [2:55:09<18:29:34,  1.52s/it, loss=1.451, lr=2.94e-04, it/s=0.60, mem=3.7GB, mem_count=1259]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.56\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  13%|‚ñà‚ñé        | 6300/50000 [2:55:28<86:01:00,  7.09s/it, loss=1.451, lr=2.94e-04, it/s=0.60, mem=3.7GB, mem_count=1259]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 6300: Train PPL=4.24 | Eval PPL=1.16 | LR=2.94e-04\n","   VRAM: 3.7GB | Memories: 1260 | Buffer: 50400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6304/50000 [2:55:32<27:56:05,  2.30s/it, loss=1.454, lr=2.94e-04, it/s=0.60, mem=3.7GB, mem_count=1260]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:34:38] Step: 6,305/50k | Loss: 1.454 | PPL: 1.16 | Best: 1.14\n","           Mem: 1261 | Buf: 50,432 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6328/50000 [2:56:37<23:07:20,  1.91s/it, loss=1.463, lr=2.93e-04, it/s=0.60, mem=3.7GB, mem_count=1265]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:35:38] Step: 6,329/50k | Loss: 1.463 | PPL: 1.16 | Best: 1.14\n","           Mem: 1265 | Buf: 50,624 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6349/50000 [2:57:32<18:38:12,  1.54s/it, loss=1.472, lr=2.93e-04, it/s=0.60, mem=3.7GB, mem_count=1269]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:36:38] Step: 6,350/50k | Loss: 1.472 | PPL: 1.16 | Best: 1.14\n","           Mem: 1270 | Buf: 50,800 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6373/50000 [2:58:38<23:35:40,  1.95s/it, loss=1.447, lr=2.93e-04, it/s=0.59, mem=3.7GB, mem_count=1274]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:37:38] Step: 6,373/50k | Loss: 1.444 | PPL: 1.16 | Best: 1.14\n","           Mem: 1274 | Buf: 50,976 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6394/50000 [2:59:33<18:50:14,  1.56s/it, loss=1.441, lr=2.93e-04, it/s=0.59, mem=3.7GB, mem_count=1278]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:38:38] Step: 6,395/50k | Loss: 1.441 | PPL: 1.16 | Best: 1.14\n","           Mem: 1279 | Buf: 51,152 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6397/50000 [2:59:44<29:27:55,  2.43s/it, loss=1.456, lr=2.93e-04, it/s=0.59, mem=3.7GB, mem_count=1279]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 6400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6399/50000 [2:59:46<18:47:47,  1.55s/it, loss=1.459, lr=2.93e-04, it/s=0.59, mem=3.7GB, mem_count=1279]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.51\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  13%|‚ñà‚ñé        | 6400/50000 [3:00:06<87:53:14,  7.26s/it, loss=1.459, lr=2.93e-04, it/s=0.59, mem=3.7GB, mem_count=1279]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 6400: Train PPL=4.26 | Eval PPL=1.16 | LR=2.93e-04\n","   VRAM: 3.7GB | Memories: 1280 | Buffer: 51200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6414/50000 [3:00:37<19:17:36,  1.59s/it, loss=1.433, lr=2.93e-04, it/s=0.59, mem=3.7GB, mem_count=1282]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:39:38] Step: 6,415/50k | Loss: 1.433 | PPL: 1.16 | Best: 1.14\n","           Mem: 1283 | Buf: 51,312 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6434/50000 [3:01:31<19:00:33,  1.57s/it, loss=1.435, lr=2.93e-04, it/s=0.59, mem=3.7GB, mem_count=1286]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:40:38] Step: 6,435/50k | Loss: 1.435 | PPL: 1.16 | Best: 1.14\n","           Mem: 1287 | Buf: 51,472 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6458/50000 [3:02:37<23:27:46,  1.94s/it, loss=1.448, lr=2.93e-04, it/s=0.59, mem=3.7GB, mem_count=1291]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:41:38] Step: 6,459/50k | Loss: 1.448 | PPL: 1.16 | Best: 1.14\n","           Mem: 1291 | Buf: 51,664 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6479/50000 [3:03:33<19:03:59,  1.58s/it, loss=1.462, lr=2.93e-04, it/s=0.59, mem=3.7GB, mem_count=1295]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:42:38] Step: 6,480/50k | Loss: 1.462 | PPL: 1.16 | Best: 1.14\n","           Mem: 1296 | Buf: 51,840 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6497/50000 [3:04:26<30:18:56,  2.51s/it, loss=1.443, lr=2.93e-04, it/s=0.59, mem=3.7GB, mem_count=1299]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 6500\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6499/50000 [3:04:28<19:09:02,  1.58s/it, loss=1.467, lr=2.93e-04, it/s=0.59, mem=3.7GB, mem_count=1299]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 1.03\n","\n","[07:43:38] Step: 6,500/50k | Loss: 1.467 | PPL: 1.16 | Best: 1.14\n","           Mem: 1300 | Buf: 52,000 | Phase: wake | ETA: 11.0h\n","\n","üìä Step 6500: Train PPL=4.28 | Eval PPL=1.16 | LR=2.93e-04\n","   VRAM: 3.7GB | Memories: 1300 | Buffer: 52000\n","‚úÖ Checkpoint saved: step_6500\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6518/50000 [3:05:38<24:06:36,  2.00s/it, loss=1.454, lr=2.93e-04, it/s=0.59, mem=3.7GB, mem_count=1303]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:44:38] Step: 6,518/50k | Loss: 1.446 | PPL: 1.16 | Best: 1.14\n","           Mem: 1303 | Buf: 52,128 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6539/50000 [3:06:36<19:22:30,  1.60s/it, loss=1.440, lr=2.93e-04, it/s=0.58, mem=3.7GB, mem_count=1307]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:45:38] Step: 6,540/50k | Loss: 1.440 | PPL: 1.16 | Best: 1.14\n","           Mem: 1308 | Buf: 52,320 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6559/50000 [3:07:31<19:24:59,  1.61s/it, loss=1.451, lr=2.93e-04, it/s=0.58, mem=3.7GB, mem_count=1311]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:46:38] Step: 6,560/50k | Loss: 1.451 | PPL: 1.16 | Best: 1.14\n","           Mem: 1312 | Buf: 52,480 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6579/50000 [3:08:27<19:30:35,  1.62s/it, loss=1.458, lr=2.93e-04, it/s=0.58, mem=3.7GB, mem_count=1315]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:47:38] Step: 6,580/50k | Loss: 1.458 | PPL: 1.16 | Best: 1.14\n","           Mem: 1316 | Buf: 52,640 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6597/50000 [3:09:22<31:09:04,  2.58s/it, loss=1.440, lr=2.93e-04, it/s=0.58, mem=3.7GB, mem_count=1319]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 6600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6599/50000 [3:09:24<19:38:21,  1.63s/it, loss=1.451, lr=2.93e-04, it/s=0.58, mem=3.7GB, mem_count=1319]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.57\n","\n","[07:48:38] Step: 6,600/50k | Loss: 1.451 | PPL: 1.16 | Best: 1.14\n","           Mem: 1320 | Buf: 52,800 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  13%|‚ñà‚ñé        | 6600/50000 [3:09:44<91:14:12,  7.57s/it, loss=1.451, lr=2.93e-04, it/s=0.58, mem=3.7GB, mem_count=1319]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 6600: Train PPL=4.27 | Eval PPL=1.19 | LR=2.93e-04\n","   VRAM: 3.7GB | Memories: 1320 | Buffer: 52800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6619/50000 [3:10:31<19:28:14,  1.62s/it, loss=1.460, lr=2.93e-04, it/s=0.58, mem=3.7GB, mem_count=1323]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:49:38] Step: 6,620/50k | Loss: 1.460 | PPL: 1.19 | Best: 1.14\n","           Mem: 1324 | Buf: 52,960 | Phase: wake | ETA: 11.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6639/50000 [3:11:27<19:38:03,  1.63s/it, loss=1.453, lr=2.93e-04, it/s=0.58, mem=3.7GB, mem_count=1327]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:50:38] Step: 6,640/50k | Loss: 1.453 | PPL: 1.19 | Best: 1.14\n","           Mem: 1328 | Buf: 53,120 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6663/50000 [3:12:37<24:46:27,  2.06s/it, loss=1.461, lr=2.93e-04, it/s=0.58, mem=3.7GB, mem_count=1332]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:51:38] Step: 6,663/50k | Loss: 1.461 | PPL: 1.19 | Best: 1.14\n","           Mem: 1332 | Buf: 53,296 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6684/50000 [3:13:36<19:51:17,  1.65s/it, loss=1.456, lr=2.92e-04, it/s=0.58, mem=3.7GB, mem_count=1336]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:52:38] Step: 6,685/50k | Loss: 1.456 | PPL: 1.19 | Best: 1.14\n","           Mem: 1337 | Buf: 53,472 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6697/50000 [3:14:17<31:53:33,  2.65s/it, loss=1.483, lr=2.92e-04, it/s=0.57, mem=3.7GB, mem_count=1339]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 6700\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6699/50000 [3:14:19<20:03:51,  1.67s/it, loss=1.439, lr=2.92e-04, it/s=0.57, mem=3.7GB, mem_count=1339]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.43\n","\n","[07:53:38] Step: 6,700/50k | Loss: 1.439 | PPL: 1.19 | Best: 1.14\n","           Mem: 1340 | Buf: 53,600 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  13%|‚ñà‚ñé        | 6700/50000 [3:14:41<95:33:20,  7.94s/it, loss=1.439, lr=2.92e-04, it/s=0.57, mem=3.7GB, mem_count=1339]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 6700: Train PPL=4.25 | Eval PPL=1.20 | LR=2.92e-04\n","   VRAM: 3.7GB | Memories: 1340 | Buffer: 53600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6719/50000 [3:15:28<19:46:00,  1.64s/it, loss=1.451, lr=2.92e-04, it/s=0.57, mem=3.7GB, mem_count=1343]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:54:38] Step: 6,720/50k | Loss: 1.451 | PPL: 1.20 | Best: 1.14\n","           Mem: 1344 | Buf: 53,760 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  13%|‚ñà‚ñé        | 6741/50000 [3:16:38<42:19:18,  3.52s/it, loss=1.458, lr=2.92e-04, it/s=0.57, mem=3.7GB, mem_count=1348]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:55:38] Step: 6,741/50k | Loss: 1.447 | PPL: 1.20 | Best: 1.14\n","           Mem: 1348 | Buf: 53,920 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñé        | 6762/50000 [3:17:38<32:15:25,  2.69s/it, loss=1.495, lr=2.92e-04, it/s=0.57, mem=3.7GB, mem_count=1352]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:56:38] Step: 6,762/50k | Loss: 1.495 | PPL: 1.20 | Best: 1.14\n","           Mem: 1352 | Buf: 54,096 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñé        | 6784/50000 [3:18:38<19:52:37,  1.66s/it, loss=1.484, lr=2.92e-04, it/s=0.57, mem=3.7GB, mem_count=1356]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:57:38] Step: 6,784/50k | Loss: 1.484 | PPL: 1.20 | Best: 1.14\n","           Mem: 1356 | Buf: 54,272 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñé        | 6797/50000 [3:19:20<32:07:45,  2.68s/it, loss=1.458, lr=2.92e-04, it/s=0.57, mem=3.7GB, mem_count=1359]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 6800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñé        | 6799/50000 [3:19:22<20:05:05,  1.67s/it, loss=1.439, lr=2.92e-04, it/s=0.57, mem=3.7GB, mem_count=1359]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.49\n","\n","[07:58:38] Step: 6,800/50k | Loss: 1.439 | PPL: 1.20 | Best: 1.14\n","           Mem: 1360 | Buf: 54,400 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  14%|‚ñà‚ñé        | 6800/50000 [3:19:44<94:35:29,  7.88s/it, loss=1.439, lr=2.92e-04, it/s=0.57, mem=3.7GB, mem_count=1359]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 6800: Train PPL=4.29 | Eval PPL=1.21 | LR=2.92e-04\n","   VRAM: 3.7GB | Memories: 1360 | Buffer: 54400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñé        | 6819/50000 [3:20:32<20:02:05,  1.67s/it, loss=1.447, lr=2.92e-04, it/s=0.57, mem=3.7GB, mem_count=1363]"]},{"output_type":"stream","name":"stdout","text":["\n","[07:59:38] Step: 6,820/50k | Loss: 1.447 | PPL: 1.21 | Best: 1.14\n","           Mem: 1364 | Buf: 54,560 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñé        | 6839/50000 [3:21:31<20:04:11,  1.67s/it, loss=1.456, lr=2.92e-04, it/s=0.57, mem=3.7GB, mem_count=1367]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:00:38] Step: 6,840/50k | Loss: 1.456 | PPL: 1.21 | Best: 1.14\n","           Mem: 1368 | Buf: 54,720 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñé        | 6859/50000 [3:22:31<20:27:23,  1.71s/it, loss=1.463, lr=2.92e-04, it/s=0.56, mem=3.7GB, mem_count=1371]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:01:38] Step: 6,860/50k | Loss: 1.463 | PPL: 1.21 | Best: 1.14\n","           Mem: 1372 | Buf: 54,880 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 6879/50000 [3:23:31<20:29:17,  1.71s/it, loss=1.453, lr=2.92e-04, it/s=0.56, mem=3.7GB, mem_count=1375]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:02:38] Step: 6,880/50k | Loss: 1.453 | PPL: 1.21 | Best: 1.14\n","           Mem: 1376 | Buf: 55,040 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 6897/50000 [3:24:30<33:22:46,  2.79s/it, loss=1.457, lr=2.92e-04, it/s=0.56, mem=3.7GB, mem_count=1379]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 6900\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 6899/50000 [3:24:32<20:46:44,  1.74s/it, loss=1.448, lr=2.92e-04, it/s=0.56, mem=3.7GB, mem_count=1379]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.66\n","\n","[08:03:38] Step: 6,900/50k | Loss: 1.448 | PPL: 1.21 | Best: 1.14\n","           Mem: 1380 | Buf: 55,200 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  14%|‚ñà‚ñç        | 6900/50000 [3:24:53<93:46:14,  7.83s/it, loss=1.448, lr=2.92e-04, it/s=0.56, mem=3.7GB, mem_count=1379]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 6900: Train PPL=4.26 | Eval PPL=1.18 | LR=2.92e-04\n","   VRAM: 3.7GB | Memories: 1380 | Buffer: 55200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 6914/50000 [3:25:28<20:52:49,  1.74s/it, loss=1.446, lr=2.92e-04, it/s=0.56, mem=3.7GB, mem_count=1382]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:04:38] Step: 6,915/50k | Loss: 1.446 | PPL: 1.18 | Best: 1.14\n","           Mem: 1383 | Buf: 55,312 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 6934/50000 [3:26:29<20:38:38,  1.73s/it, loss=1.428, lr=2.92e-04, it/s=0.56, mem=3.7GB, mem_count=1386]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:05:38] Step: 6,935/50k | Loss: 1.428 | PPL: 1.18 | Best: 1.14\n","           Mem: 1387 | Buf: 55,472 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 6954/50000 [3:27:29<20:30:34,  1.72s/it, loss=1.447, lr=2.92e-04, it/s=0.56, mem=3.7GB, mem_count=1390]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:06:38] Step: 6,955/50k | Loss: 1.447 | PPL: 1.18 | Best: 1.14\n","           Mem: 1391 | Buf: 55,632 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 6974/50000 [3:28:30<20:40:30,  1.73s/it, loss=1.485, lr=2.92e-04, it/s=0.56, mem=3.7GB, mem_count=1394]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:07:38] Step: 6,975/50k | Loss: 1.485 | PPL: 1.18 | Best: 1.14\n","           Mem: 1395 | Buf: 55,792 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 6994/50000 [3:29:32<20:52:48,  1.75s/it, loss=1.439, lr=2.92e-04, it/s=0.56, mem=3.7GB, mem_count=1398]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:08:38] Step: 6,995/50k | Loss: 1.439 | PPL: 1.18 | Best: 1.14\n","           Mem: 1399 | Buf: 55,952 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 6997/50000 [3:29:46<33:44:30,  2.82s/it, loss=1.447, lr=2.92e-04, it/s=0.56, mem=3.7GB, mem_count=1399]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 7000\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 6999/50000 [3:29:48<20:50:40,  1.75s/it, loss=1.445, lr=2.92e-04, it/s=0.56, mem=3.7GB, mem_count=1399]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.44\n","\n","üìä Step 7000: Train PPL=4.28 | Eval PPL=1.21 | LR=2.92e-04\n","   VRAM: 3.7GB | Memories: 1400 | Buffer: 56000\n","‚úÖ Checkpoint saved: step_7000\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7009/50000 [3:30:33<22:51:58,  1.91s/it, loss=1.474, lr=2.91e-04, it/s=0.55, mem=3.7GB, mem_count=1401]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:09:38] Step: 7,010/50k | Loss: 1.474 | PPL: 1.21 | Best: 1.14\n","           Mem: 1402 | Buf: 56,080 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7029/50000 [3:31:37<21:06:00,  1.77s/it, loss=1.445, lr=2.91e-04, it/s=0.55, mem=3.7GB, mem_count=1405]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:10:38] Step: 7,030/50k | Loss: 1.445 | PPL: 1.21 | Best: 1.14\n","           Mem: 1406 | Buf: 56,240 | Phase: wake | ETA: 10.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7048/50000 [3:32:38<26:24:42,  2.21s/it, loss=1.421, lr=2.91e-04, it/s=0.55, mem=3.7GB, mem_count=1409]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:11:38] Step: 7,048/50k | Loss: 1.454 | PPL: 1.21 | Best: 1.14\n","           Mem: 1409 | Buf: 56,368 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7064/50000 [3:33:27<21:07:25,  1.77s/it, loss=1.435, lr=2.91e-04, it/s=0.55, mem=3.7GB, mem_count=1412]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:12:38] Step: 7,065/50k | Loss: 1.435 | PPL: 1.21 | Best: 1.14\n","           Mem: 1413 | Buf: 56,512 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7084/50000 [3:34:30<21:11:29,  1.78s/it, loss=1.448, lr=2.91e-04, it/s=0.55, mem=3.7GB, mem_count=1416]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:13:38] Step: 7,085/50k | Loss: 1.448 | PPL: 1.21 | Best: 1.14\n","           Mem: 1417 | Buf: 56,672 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7097/50000 [3:35:15<34:35:54,  2.90s/it, loss=1.445, lr=2.91e-04, it/s=0.55, mem=3.7GB, mem_count=1419]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 7100\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7099/50000 [3:35:17<21:19:47,  1.79s/it, loss=1.499, lr=2.91e-04, it/s=0.55, mem=3.7GB, mem_count=1419]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.96\n","\n","[08:14:38] Step: 7,100/50k | Loss: 1.499 | PPL: 1.21 | Best: 1.14\n","           Mem: 1420 | Buf: 56,800 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  14%|‚ñà‚ñç        | 7100/50000 [3:35:43<108:30:19,  9.11s/it, loss=1.499, lr=2.91e-04, it/s=0.55, mem=3.7GB, mem_count=1419]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 7100: Train PPL=4.27 | Eval PPL=1.19 | LR=2.91e-04\n","   VRAM: 3.7GB | Memories: 1420 | Buffer: 56800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7119/50000 [3:36:34<21:01:20,  1.76s/it, loss=1.441, lr=2.91e-04, it/s=0.55, mem=3.7GB, mem_count=1423]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:15:38] Step: 7,120/50k | Loss: 1.441 | PPL: 1.19 | Best: 1.14\n","           Mem: 1424 | Buf: 56,960 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7139/50000 [3:37:37<21:02:37,  1.77s/it, loss=1.437, lr=2.91e-04, it/s=0.55, mem=3.7GB, mem_count=1427]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:16:38] Step: 7,140/50k | Loss: 1.437 | PPL: 1.19 | Best: 1.14\n","           Mem: 1428 | Buf: 57,120 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7155/50000 [3:38:37<61:07:44,  5.14s/it, loss=1.436, lr=2.91e-04, it/s=0.55, mem=3.7GB, mem_count=1430]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:17:38] Step: 7,156/50k | Loss: 1.436 | PPL: 1.19 | Best: 1.14\n","           Mem: 1431 | Buf: 57,232 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7174/50000 [3:39:29<21:08:15,  1.78s/it, loss=1.433, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1434]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:18:38] Step: 7,175/50k | Loss: 1.433 | PPL: 1.19 | Best: 1.14\n","           Mem: 1435 | Buf: 57,392 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7194/50000 [3:40:33<21:25:37,  1.80s/it, loss=1.457, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1438]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:19:38] Step: 7,195/50k | Loss: 1.457 | PPL: 1.19 | Best: 1.14\n","           Mem: 1439 | Buf: 57,552 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7197/50000 [3:40:47<35:10:59,  2.96s/it, loss=1.458, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1439]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 7200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7199/50000 [3:40:49<21:30:30,  1.81s/it, loss=1.460, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1439]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.79\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  14%|‚ñà‚ñç        | 7200/50000 [3:41:13<100:25:35,  8.45s/it, loss=1.460, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1439]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 7200: Train PPL=4.28 | Eval PPL=1.19 | LR=2.91e-04\n","   VRAM: 3.7GB | Memories: 1440 | Buffer: 57600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7209/50000 [3:41:32<22:51:00,  1.92s/it, loss=1.461, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1441]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:20:38] Step: 7,210/50k | Loss: 1.461 | PPL: 1.19 | Best: 1.14\n","           Mem: 1442 | Buf: 57,680 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7229/50000 [3:42:37<21:22:58,  1.80s/it, loss=1.464, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1445]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:21:38] Step: 7,230/50k | Loss: 1.464 | PPL: 1.19 | Best: 1.14\n","           Mem: 1446 | Buf: 57,840 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  14%|‚ñà‚ñç        | 7244/50000 [3:43:26<21:34:14,  1.82s/it, loss=1.447, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1448]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:22:38] Step: 7,245/50k | Loss: 1.447 | PPL: 1.19 | Best: 1.14\n","           Mem: 1449 | Buf: 57,952 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7264/50000 [3:44:32<21:51:46,  1.84s/it, loss=1.452, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1452]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:23:38] Step: 7,265/50k | Loss: 1.452 | PPL: 1.19 | Best: 1.14\n","           Mem: 1453 | Buf: 58,112 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7284/50000 [3:45:37<21:51:46,  1.84s/it, loss=1.443, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1456]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:24:38] Step: 7,285/50k | Loss: 1.443 | PPL: 1.19 | Best: 1.14\n","           Mem: 1456 | Buf: 58,272 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7297/50000 [3:46:26<36:13:20,  3.05s/it, loss=1.474, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1459]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 7300\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7299/50000 [3:46:28<22:06:17,  1.86s/it, loss=1.436, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1459]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.52\n","\n","[08:25:38] Step: 7,300/50k | Loss: 1.436 | PPL: 1.19 | Best: 1.14\n","           Mem: 1460 | Buf: 58,400 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  15%|‚ñà‚ñç        | 7300/50000 [3:46:52<101:02:55,  8.52s/it, loss=1.436, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1459]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 7300: Train PPL=4.27 | Eval PPL=1.20 | LR=2.91e-04\n","   VRAM: 3.7GB | Memories: 1460 | Buffer: 58400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7314/50000 [3:47:29<22:05:46,  1.86s/it, loss=1.463, lr=2.91e-04, it/s=0.54, mem=3.7GB, mem_count=1462]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:26:38] Step: 7,315/50k | Loss: 1.463 | PPL: 1.20 | Best: 1.14\n","           Mem: 1463 | Buf: 58,512 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7334/50000 [3:48:36<21:54:12,  1.85s/it, loss=1.483, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1466]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:27:38] Step: 7,335/50k | Loss: 1.483 | PPL: 1.20 | Best: 1.14\n","           Mem: 1467 | Buf: 58,672 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7349/50000 [3:49:26<21:53:56,  1.85s/it, loss=1.451, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1469]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:28:38] Step: 7,350/50k | Loss: 1.451 | PPL: 1.20 | Best: 1.14\n","           Mem: 1470 | Buf: 58,800 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7369/50000 [3:50:33<21:45:01,  1.84s/it, loss=1.500, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1473]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:29:38] Step: 7,370/50k | Loss: 1.500 | PPL: 1.20 | Best: 1.14\n","           Mem: 1474 | Buf: 58,960 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7387/50000 [3:51:38<35:45:30,  3.02s/it, loss=1.444, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1477]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:30:38] Step: 7,387/50k | Loss: 1.444 | PPL: 1.20 | Best: 1.14\n","           Mem: 1477 | Buf: 59,088 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7397/50000 [3:52:11<36:21:24,  3.07s/it, loss=1.444, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1479]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 7400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7399/50000 [3:52:14<22:04:30,  1.87s/it, loss=1.454, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1479]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.64\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  15%|‚ñà‚ñç        | 7400/50000 [3:52:37<102:20:32,  8.65s/it, loss=1.454, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1479]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 7400: Train PPL=4.30 | Eval PPL=1.23 | LR=2.90e-04\n","   VRAM: 3.7GB | Memories: 1480 | Buffer: 59200\n","\n","[08:31:38] Step: 7,401/50k | Loss: 1.454 | PPL: 1.23 | Best: 1.14\n","           Mem: 1480 | Buf: 59,200 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7419/50000 [3:53:31<21:53:55,  1.85s/it, loss=1.438, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1483]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:32:38] Step: 7,420/50k | Loss: 1.438 | PPL: 1.23 | Best: 1.14\n","           Mem: 1484 | Buf: 59,360 | Phase: wake | ETA: 10.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7438/50000 [3:54:38<28:01:58,  2.37s/it, loss=1.469, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1487]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:33:38] Step: 7,438/50k | Loss: 1.457 | PPL: 1.23 | Best: 1.14\n","           Mem: 1487 | Buf: 59,488 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7454/50000 [3:55:30<22:14:05,  1.88s/it, loss=1.450, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1490]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:34:38] Step: 7,455/50k | Loss: 1.450 | PPL: 1.23 | Best: 1.14\n","           Mem: 1491 | Buf: 59,632 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7473/50000 [3:56:37<28:08:28,  2.38s/it, loss=1.466, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1494]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:35:38] Step: 7,474/50k | Loss: 1.466 | PPL: 1.23 | Best: 1.14\n","           Mem: 1494 | Buf: 59,776 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7489/50000 [3:57:30<22:22:09,  1.89s/it, loss=1.474, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1497]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:36:38] Step: 7,490/50k | Loss: 1.474 | PPL: 1.23 | Best: 1.14\n","           Mem: 1498 | Buf: 59,920 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7497/50000 [3:58:03<37:11:32,  3.15s/it, loss=1.450, lr=2.90e-04, it/s=0.52, mem=3.7GB, mem_count=1499]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 7500\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñç        | 7499/50000 [3:58:05<22:29:11,  1.90s/it, loss=1.453, lr=2.90e-04, it/s=0.53, mem=3.7GB, mem_count=1499]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.64\n","\n","üìä Step 7500: Train PPL=4.29 | Eval PPL=1.20 | LR=2.90e-04\n","   VRAM: 3.7GB | Memories: 1500 | Buffer: 60000\n","‚úÖ Checkpoint saved: step_7500\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7504/50000 [3:58:38<36:21:49,  3.08s/it, loss=1.445, lr=2.90e-04, it/s=0.52, mem=3.7GB, mem_count=1500]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:37:38] Step: 7,504/50k | Loss: 1.444 | PPL: 1.20 | Best: 1.14\n","           Mem: 1500 | Buf: 60,016 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7519/50000 [3:59:30<22:25:20,  1.90s/it, loss=1.452, lr=2.90e-04, it/s=0.52, mem=3.7GB, mem_count=1503]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:38:38] Step: 7,520/50k | Loss: 1.452 | PPL: 1.20 | Best: 1.14\n","           Mem: 1504 | Buf: 60,160 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7536/50000 [4:00:38<49:28:29,  4.19s/it, loss=1.455, lr=2.90e-04, it/s=0.52, mem=3.7GB, mem_count=1507]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:39:38] Step: 7,536/50k | Loss: 1.468 | PPL: 1.20 | Best: 1.14\n","           Mem: 1507 | Buf: 60,272 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7554/50000 [4:01:33<22:39:17,  1.92s/it, loss=1.444, lr=2.90e-04, it/s=0.52, mem=3.7GB, mem_count=1510]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:40:38] Step: 7,555/50k | Loss: 1.444 | PPL: 1.20 | Best: 1.14\n","           Mem: 1511 | Buf: 60,432 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7569/50000 [4:02:26<22:35:09,  1.92s/it, loss=1.451, lr=2.90e-04, it/s=0.52, mem=3.7GB, mem_count=1513]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:41:38] Step: 7,570/50k | Loss: 1.451 | PPL: 1.20 | Best: 1.14\n","           Mem: 1514 | Buf: 60,560 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7589/50000 [4:03:35<22:24:44,  1.90s/it, loss=1.445, lr=2.90e-04, it/s=0.52, mem=3.7GB, mem_count=1517]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:42:38] Step: 7,590/50k | Loss: 1.445 | PPL: 1.20 | Best: 1.14\n","           Mem: 1518 | Buf: 60,720 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7597/50000 [4:04:09<37:57:35,  3.22s/it, loss=1.455, lr=2.90e-04, it/s=0.52, mem=3.7GB, mem_count=1519]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 7600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7599/50000 [4:04:11<22:50:11,  1.94s/it, loss=1.450, lr=2.90e-04, it/s=0.52, mem=3.7GB, mem_count=1519]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.55\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  15%|‚ñà‚ñå        | 7600/50000 [4:04:35<103:04:01,  8.75s/it, loss=1.450, lr=2.90e-04, it/s=0.52, mem=3.7GB, mem_count=1519]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 7600: Train PPL=4.28 | Eval PPL=1.18 | LR=2.90e-04\n","   VRAM: 3.7GB | Memories: 1520 | Buffer: 60800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7604/50000 [4:04:38<31:00:39,  2.63s/it, loss=1.433, lr=2.90e-04, it/s=0.52, mem=3.7GB, mem_count=1520]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:43:38] Step: 7,604/50k | Loss: 1.452 | PPL: 1.18 | Best: 1.14\n","           Mem: 1520 | Buf: 60,816 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7619/50000 [4:05:31<22:44:41,  1.93s/it, loss=1.469, lr=2.90e-04, it/s=0.52, mem=3.7GB, mem_count=1523]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:44:38] Step: 7,620/50k | Loss: 1.469 | PPL: 1.18 | Best: 1.14\n","           Mem: 1524 | Buf: 60,960 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7634/50000 [4:06:24<22:40:32,  1.93s/it, loss=1.470, lr=2.89e-04, it/s=0.52, mem=3.7GB, mem_count=1526]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:45:38] Step: 7,635/50k | Loss: 1.470 | PPL: 1.18 | Best: 1.14\n","           Mem: 1527 | Buf: 61,072 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7654/50000 [4:07:35<22:50:39,  1.94s/it, loss=1.454, lr=2.89e-04, it/s=0.52, mem=3.7GB, mem_count=1530]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:46:38] Step: 7,655/50k | Loss: 1.454 | PPL: 1.18 | Best: 1.14\n","           Mem: 1531 | Buf: 61,232 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7669/50000 [4:08:30<23:22:14,  1.99s/it, loss=1.454, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1533]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:47:38] Step: 7,670/50k | Loss: 1.454 | PPL: 1.18 | Best: 1.14\n","           Mem: 1534 | Buf: 61,360 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7684/50000 [4:09:24<22:59:06,  1.96s/it, loss=1.451, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1536]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:48:38] Step: 7,685/50k | Loss: 1.451 | PPL: 1.18 | Best: 1.14\n","           Mem: 1537 | Buf: 61,472 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7697/50000 [4:10:16<38:26:51,  3.27s/it, loss=1.468, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1539]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 7700\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7699/50000 [4:10:18<23:05:06,  1.96s/it, loss=1.487, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1539]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 1.05\n","\n","[08:49:38] Step: 7,700/50k | Loss: 1.487 | PPL: 1.18 | Best: 1.14\n","           Mem: 1540 | Buf: 61,600 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  15%|‚ñà‚ñå        | 7700/50000 [4:10:42<104:23:31,  8.88s/it, loss=1.487, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1539]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 7700: Train PPL=4.31 | Eval PPL=1.22 | LR=2.89e-04\n","   VRAM: 3.7GB | Memories: 1540 | Buffer: 61600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7717/50000 [4:11:38<38:29:55,  3.28s/it, loss=1.452, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1543]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:50:38] Step: 7,717/50k | Loss: 1.464 | PPL: 1.22 | Best: 1.14\n","           Mem: 1543 | Buf: 61,728 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7734/50000 [4:12:34<23:06:50,  1.97s/it, loss=1.457, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1546]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:51:38] Step: 7,735/50k | Loss: 1.457 | PPL: 1.22 | Best: 1.14\n","           Mem: 1547 | Buf: 61,872 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  15%|‚ñà‚ñå        | 7749/50000 [4:13:28<22:55:11,  1.95s/it, loss=1.458, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1549]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:52:38] Step: 7,750/50k | Loss: 1.458 | PPL: 1.22 | Best: 1.14\n","           Mem: 1550 | Buf: 62,000 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7766/50000 [4:14:38<51:45:45,  4.41s/it, loss=1.467, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1553]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:53:38] Step: 7,766/50k | Loss: 1.467 | PPL: 1.22 | Best: 1.14\n","           Mem: 1553 | Buf: 62,128 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7784/50000 [4:15:35<22:57:19,  1.96s/it, loss=1.480, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1556]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:54:38] Step: 7,785/50k | Loss: 1.480 | PPL: 1.22 | Best: 1.14\n","           Mem: 1557 | Buf: 62,272 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7797/50000 [4:16:28<39:13:30,  3.35s/it, loss=1.459, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1559]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 7800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7799/50000 [4:16:30<23:30:17,  2.01s/it, loss=1.441, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1559]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.62\n","\n","[08:55:38] Step: 7,800/50k | Loss: 1.441 | PPL: 1.22 | Best: 1.14\n","           Mem: 1560 | Buf: 62,400 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  16%|‚ñà‚ñå        | 7800/50000 [4:16:55<105:28:50,  9.00s/it, loss=1.441, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1559]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 7800: Train PPL=4.29 | Eval PPL=1.18 | LR=2.89e-04\n","   VRAM: 3.7GB | Memories: 1560 | Buffer: 62400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7814/50000 [4:17:36<23:39:34,  2.02s/it, loss=1.447, lr=2.89e-04, it/s=0.51, mem=3.7GB, mem_count=1562]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:56:38] Step: 7,815/50k | Loss: 1.447 | PPL: 1.18 | Best: 1.14\n","           Mem: 1563 | Buf: 62,512 | Phase: wake | ETA: 10.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7829/50000 [4:18:31<23:13:37,  1.98s/it, loss=1.458, lr=2.89e-04, it/s=0.50, mem=3.7GB, mem_count=1565]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:57:38] Step: 7,830/50k | Loss: 1.458 | PPL: 1.18 | Best: 1.14\n","           Mem: 1566 | Buf: 62,640 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7844/50000 [4:19:26<23:13:36,  1.98s/it, loss=1.455, lr=2.89e-04, it/s=0.50, mem=3.7GB, mem_count=1568]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:58:38] Step: 7,845/50k | Loss: 1.455 | PPL: 1.18 | Best: 1.14\n","           Mem: 1569 | Buf: 62,752 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7861/50000 [4:20:38<52:01:14,  4.44s/it, loss=1.452, lr=2.89e-04, it/s=0.50, mem=3.7GB, mem_count=1572]"]},{"output_type":"stream","name":"stdout","text":["\n","[08:59:38] Step: 7,861/50k | Loss: 1.452 | PPL: 1.18 | Best: 1.14\n","           Mem: 1572 | Buf: 62,880 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7879/50000 [4:21:36<23:32:22,  2.01s/it, loss=1.453, lr=2.89e-04, it/s=0.50, mem=3.7GB, mem_count=1575]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:00:38] Step: 7,880/50k | Loss: 1.453 | PPL: 1.18 | Best: 1.14\n","           Mem: 1576 | Buf: 63,040 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7894/50000 [4:22:32<23:44:25,  2.03s/it, loss=1.483, lr=2.89e-04, it/s=0.50, mem=3.7GB, mem_count=1578]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:01:38] Step: 7,895/50k | Loss: 1.483 | PPL: 1.18 | Best: 1.14\n","           Mem: 1579 | Buf: 63,152 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7897/50000 [4:22:48<39:26:27,  3.37s/it, loss=1.437, lr=2.89e-04, it/s=0.50, mem=3.7GB, mem_count=1579]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 7900\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7899/50000 [4:22:50<23:32:22,  2.01s/it, loss=1.459, lr=2.89e-04, it/s=0.50, mem=3.7GB, mem_count=1579]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.71\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  16%|‚ñà‚ñå        | 7900/50000 [4:23:16<108:18:18,  9.26s/it, loss=1.459, lr=2.89e-04, it/s=0.50, mem=3.7GB, mem_count=1579]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 7900: Train PPL=4.28 | Eval PPL=1.18 | LR=2.89e-04\n","   VRAM: 3.7GB | Memories: 1580 | Buffer: 63200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7909/50000 [4:23:38<24:54:52,  2.13s/it, loss=1.445, lr=2.89e-04, it/s=0.50, mem=3.7GB, mem_count=1581]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:02:38] Step: 7,910/50k | Loss: 1.445 | PPL: 1.18 | Best: 1.14\n","           Mem: 1581 | Buf: 63,264 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7924/50000 [4:24:34<23:31:50,  2.01s/it, loss=1.468, lr=2.88e-04, it/s=0.50, mem=3.7GB, mem_count=1584]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:03:38] Step: 7,925/50k | Loss: 1.468 | PPL: 1.18 | Best: 1.14\n","           Mem: 1585 | Buf: 63,392 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7939/50000 [4:25:30<23:31:42,  2.01s/it, loss=1.460, lr=2.88e-04, it/s=0.50, mem=3.7GB, mem_count=1587]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:04:38] Step: 7,940/50k | Loss: 1.460 | PPL: 1.18 | Best: 1.14\n","           Mem: 1588 | Buf: 63,520 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7954/50000 [4:26:27<23:35:34,  2.02s/it, loss=1.449, lr=2.88e-04, it/s=0.50, mem=3.7GB, mem_count=1590]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:05:38] Step: 7,955/50k | Loss: 1.449 | PPL: 1.18 | Best: 1.14\n","           Mem: 1591 | Buf: 63,632 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7969/50000 [4:27:23<23:41:35,  2.03s/it, loss=1.436, lr=2.88e-04, it/s=0.50, mem=3.7GB, mem_count=1593]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:06:38] Step: 7,970/50k | Loss: 1.436 | PPL: 1.18 | Best: 1.14\n","           Mem: 1594 | Buf: 63,760 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7987/50000 [4:28:38<40:45:29,  3.49s/it, loss=1.480, lr=2.88e-04, it/s=0.50, mem=3.7GB, mem_count=1597]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:07:38] Step: 7,987/50k | Loss: 1.467 | PPL: 1.18 | Best: 1.14\n","           Mem: 1597 | Buf: 63,888 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7997/50000 [4:29:16<40:30:36,  3.47s/it, loss=1.429, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1599]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 8000\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 7999/50000 [4:29:17<24:01:32,  2.06s/it, loss=1.438, lr=2.88e-04, it/s=0.50, mem=3.7GB, mem_count=1599]"]},{"output_type":"stream","name":"stdout","text":["üåô Entering SLEEP phase at step 8000\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  16%|‚ñà‚ñå        | 7999/50000 [4:29:18<24:01:32,  2.06s/it, loss=1.459, lr=2.88e-04, it/s=0.50, mem=3.7GB, mem_count=1599]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.62\n","\n","[09:08:38] Step: 8,000/50k | Loss: 1.459 | PPL: 1.18 | Best: 1.14\n","           Mem: 1600 | Buf: 64,000 | Phase: sleep | ETA: 10.6h\n","\n","üìä Step 8000: Train PPL=4.29 | Eval PPL=1.19 | LR=2.88e-04\n","   VRAM: 3.7GB | Memories: 1600 | Buffer: 64000\n","‚úÖ Checkpoint saved: step_8000\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  16%|‚ñà‚ñå        | 8000/50000 [4:29:50<132:08:24, 11.33s/it, loss=1.459, lr=2.88e-04, it/s=0.50, mem=3.7GB, mem_count=1599]"]},{"output_type":"stream","name":"stdout","text":["\n","üåô Sleep Phase at step 8000 - Memory Consolidation\n","  üîÑ Replaying 25 batches from memory...\n","  ‚úÖ Replay complete: 25/25 batches\n","  üìâ Memory decay | Memories: 1600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 8009/50000 [4:30:31<30:18:29,  2.60s/it, loss=1.511, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1601]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:09:38] Step: 8,010/50k | Loss: 1.511 | PPL: 1.19 | Best: 1.14\n","           Mem: 1602 | Buf: 64,080 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 8024/50000 [4:31:29<24:03:41,  2.06s/it, loss=1.449, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1604]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:10:38] Step: 8,025/50k | Loss: 1.449 | PPL: 1.19 | Best: 1.14\n","           Mem: 1605 | Buf: 64,192 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 8039/50000 [4:32:28<24:21:18,  2.09s/it, loss=1.441, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1607]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:11:38] Step: 8,040/50k | Loss: 1.441 | PPL: 1.19 | Best: 1.14\n","           Mem: 1608 | Buf: 64,320 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 8054/50000 [4:33:26<24:25:04,  2.10s/it, loss=1.445, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1610]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:12:38] Step: 8,055/50k | Loss: 1.445 | PPL: 1.19 | Best: 1.14\n","           Mem: 1611 | Buf: 64,432 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 8069/50000 [4:34:24<24:28:40,  2.10s/it, loss=1.467, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1613]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:13:38] Step: 8,070/50k | Loss: 1.467 | PPL: 1.19 | Best: 1.14\n","           Mem: 1614 | Buf: 64,560 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 8084/50000 [4:35:23<24:23:14,  2.09s/it, loss=1.473, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1616]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:14:38] Step: 8,085/50k | Loss: 1.473 | PPL: 1.19 | Best: 1.14\n","           Mem: 1617 | Buf: 64,672 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 8096/50000 [4:36:18<54:41:31,  4.70s/it, loss=1.446, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1619]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 8100\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 8099/50000 [4:36:21<24:08:10,  2.07s/it, loss=1.450, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1619]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.80\n","\n","[09:15:38] Step: 8,100/50k | Loss: 1.450 | PPL: 1.19 | Best: 1.14\n","           Mem: 1620 | Buf: 64,800 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  16%|‚ñà‚ñå        | 8100/50000 [4:36:47<110:53:54,  9.53s/it, loss=1.450, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1619]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 8100: Train PPL=4.31 | Eval PPL=1.20 | LR=2.88e-04\n","   VRAM: 3.7GB | Memories: 1620 | Buffer: 64800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñå        | 8114/50000 [4:37:30<24:48:07,  2.13s/it, loss=1.465, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1622]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:16:38] Step: 8,115/50k | Loss: 1.465 | PPL: 1.20 | Best: 1.14\n","           Mem: 1623 | Buf: 64,912 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñã        | 8129/50000 [4:38:30<24:30:56,  2.11s/it, loss=1.460, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1625]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:17:38] Step: 8,130/50k | Loss: 1.460 | PPL: 1.20 | Best: 1.14\n","           Mem: 1626 | Buf: 65,040 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñã        | 8144/50000 [4:39:29<24:30:22,  2.11s/it, loss=1.439, lr=2.88e-04, it/s=0.49, mem=3.7GB, mem_count=1628]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:18:38] Step: 8,145/50k | Loss: 1.439 | PPL: 1.20 | Best: 1.14\n","           Mem: 1629 | Buf: 65,152 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñã        | 8159/50000 [4:40:29<24:22:51,  2.10s/it, loss=1.448, lr=2.88e-04, it/s=0.48, mem=3.7GB, mem_count=1631]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:19:38] Step: 8,160/50k | Loss: 1.448 | PPL: 1.20 | Best: 1.14\n","           Mem: 1632 | Buf: 65,280 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñã        | 8174/50000 [4:41:28<24:26:17,  2.10s/it, loss=1.444, lr=2.88e-04, it/s=0.48, mem=3.7GB, mem_count=1634]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:20:38] Step: 8,175/50k | Loss: 1.444 | PPL: 1.20 | Best: 1.14\n","           Mem: 1635 | Buf: 65,392 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñã        | 8189/50000 [4:42:28<24:31:12,  2.11s/it, loss=1.447, lr=2.88e-04, it/s=0.48, mem=3.7GB, mem_count=1637]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:21:38] Step: 8,190/50k | Loss: 1.447 | PPL: 1.20 | Best: 1.14\n","           Mem: 1638 | Buf: 65,520 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñã        | 8196/50000 [4:43:04<55:34:03,  4.79s/it, loss=1.464, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1639]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 8200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñã        | 8199/50000 [4:43:07<24:24:19,  2.10s/it, loss=1.486, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1639]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.95\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  16%|‚ñà‚ñã        | 8200/50000 [4:43:33<109:36:45,  9.44s/it, loss=1.486, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1639]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 8200: Train PPL=4.28 | Eval PPL=1.19 | LR=2.87e-04\n","   VRAM: 3.7GB | Memories: 1640 | Buffer: 65600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñã        | 8204/50000 [4:43:37<33:10:57,  2.86s/it, loss=1.468, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1640]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:22:38] Step: 8,205/50k | Loss: 1.468 | PPL: 1.19 | Best: 1.14\n","           Mem: 1641 | Buf: 65,632 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñã        | 8219/50000 [4:44:37<24:46:11,  2.13s/it, loss=1.463, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1643]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:23:38] Step: 8,220/50k | Loss: 1.463 | PPL: 1.19 | Best: 1.14\n","           Mem: 1644 | Buf: 65,760 | Phase: wake | ETA: 10.6h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñã        | 8234/50000 [4:45:38<25:02:43,  2.16s/it, loss=1.462, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1646]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:24:38] Step: 8,235/50k | Loss: 1.440 | PPL: 1.19 | Best: 1.14\n","           Mem: 1646 | Buf: 65,872 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  16%|‚ñà‚ñã        | 8248/50000 [4:46:38<32:31:20,  2.80s/it, loss=1.448, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1649]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:25:38] Step: 8,248/50k | Loss: 1.456 | PPL: 1.19 | Best: 1.14\n","           Mem: 1649 | Buf: 65,968 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8262/50000 [4:47:38<42:29:17,  3.66s/it, loss=1.455, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1652]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:26:38] Step: 8,262/50k | Loss: 1.516 | PPL: 1.19 | Best: 1.14\n","           Mem: 1652 | Buf: 66,080 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8275/50000 [4:48:38<78:48:49,  6.80s/it, loss=1.514, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1654]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:27:38] Step: 8,275/50k | Loss: 1.514 | PPL: 1.19 | Best: 1.14\n","           Mem: 1655 | Buf: 66,192 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8289/50000 [4:49:22<25:00:32,  2.16s/it, loss=1.445, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1657]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:28:38] Step: 8,290/50k | Loss: 1.445 | PPL: 1.19 | Best: 1.14\n","           Mem: 1658 | Buf: 66,320 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8296/50000 [4:50:00<58:04:13,  5.01s/it, loss=1.434, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1659]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 8300\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8299/50000 [4:50:03<25:14:24,  2.18s/it, loss=1.454, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1659]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.65\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  17%|‚ñà‚ñã        | 8300/50000 [4:50:30<113:16:01,  9.78s/it, loss=1.454, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1659]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 8300: Train PPL=4.30 | Eval PPL=1.20 | LR=2.87e-04\n","   VRAM: 3.7GB | Memories: 1660 | Buffer: 66400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8304/50000 [4:50:34<34:13:29,  2.95s/it, loss=1.448, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1660]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:29:38] Step: 8,305/50k | Loss: 1.448 | PPL: 1.20 | Best: 1.14\n","           Mem: 1661 | Buf: 66,432 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8319/50000 [4:51:35<25:15:52,  2.18s/it, loss=1.471, lr=2.87e-04, it/s=0.48, mem=3.7GB, mem_count=1663]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:30:38] Step: 8,320/50k | Loss: 1.471 | PPL: 1.20 | Best: 1.14\n","           Mem: 1664 | Buf: 66,560 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8334/50000 [4:52:37<25:23:27,  2.19s/it, loss=1.466, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1666]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:31:38] Step: 8,335/50k | Loss: 1.466 | PPL: 1.20 | Best: 1.14\n","           Mem: 1667 | Buf: 66,672 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8349/50000 [4:53:38<25:05:50,  2.17s/it, loss=1.470, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1669]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:32:38] Step: 8,349/50k | Loss: 1.470 | PPL: 1.20 | Best: 1.14\n","           Mem: 1669 | Buf: 66,784 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8361/50000 [4:54:38<58:35:38,  5.07s/it, loss=1.453, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1672]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:33:38] Step: 8,361/50k | Loss: 1.453 | PPL: 1.20 | Best: 1.14\n","           Mem: 1672 | Buf: 66,880 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8374/50000 [4:55:22<25:22:46,  2.19s/it, loss=1.442, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1674]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:34:38] Step: 8,375/50k | Loss: 1.442 | PPL: 1.20 | Best: 1.14\n","           Mem: 1675 | Buf: 66,992 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8389/50000 [4:56:25<25:37:14,  2.22s/it, loss=1.474, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1677]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:35:38] Step: 8,390/50k | Loss: 1.474 | PPL: 1.20 | Best: 1.14\n","           Mem: 1678 | Buf: 67,120 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8396/50000 [4:57:04<58:54:49,  5.10s/it, loss=1.437, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1679]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 8400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8399/50000 [4:57:07<25:31:48,  2.21s/it, loss=1.447, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1679]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.62\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  17%|‚ñà‚ñã        | 8400/50000 [4:57:34<114:14:18,  9.89s/it, loss=1.447, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1679]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 8400: Train PPL=4.31 | Eval PPL=1.23 | LR=2.87e-04\n","   VRAM: 3.7GB | Memories: 1680 | Buffer: 67200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8404/50000 [4:57:38<34:09:19,  2.96s/it, loss=1.453, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1680]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:36:38] Step: 8,405/50k | Loss: 1.455 | PPL: 1.23 | Best: 1.14\n","           Mem: 1680 | Buf: 67,232 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8416/50000 [4:58:38<57:58:34,  5.02s/it, loss=1.447, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1683]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:37:38] Step: 8,416/50k | Loss: 1.447 | PPL: 1.23 | Best: 1.14\n","           Mem: 1683 | Buf: 67,328 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8429/50000 [4:59:23<25:38:47,  2.22s/it, loss=1.462, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1685]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:38:38] Step: 8,430/50k | Loss: 1.462 | PPL: 1.23 | Best: 1.14\n","           Mem: 1686 | Buf: 67,440 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8444/50000 [5:00:25<25:21:34,  2.20s/it, loss=1.442, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1688]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:39:38] Step: 8,445/50k | Loss: 1.442 | PPL: 1.23 | Best: 1.14\n","           Mem: 1689 | Buf: 67,552 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8459/50000 [5:01:28<25:32:10,  2.21s/it, loss=1.465, lr=2.87e-04, it/s=0.47, mem=3.7GB, mem_count=1691]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:40:38] Step: 8,460/50k | Loss: 1.465 | PPL: 1.23 | Best: 1.14\n","           Mem: 1692 | Buf: 67,680 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8474/50000 [5:02:31<25:35:37,  2.22s/it, loss=1.465, lr=2.86e-04, it/s=0.47, mem=3.7GB, mem_count=1694]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:41:38] Step: 8,475/50k | Loss: 1.465 | PPL: 1.23 | Best: 1.14\n","           Mem: 1695 | Buf: 67,792 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8489/50000 [5:03:34<25:55:55,  2.25s/it, loss=1.478, lr=2.86e-04, it/s=0.47, mem=3.7GB, mem_count=1697]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:42:38] Step: 8,490/50k | Loss: 1.478 | PPL: 1.23 | Best: 1.14\n","           Mem: 1698 | Buf: 67,920 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8496/50000 [5:04:14<60:28:56,  5.25s/it, loss=1.455, lr=2.86e-04, it/s=0.47, mem=3.7GB, mem_count=1699]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 8500\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8499/50000 [5:04:17<26:06:12,  2.26s/it, loss=1.471, lr=2.86e-04, it/s=0.47, mem=3.7GB, mem_count=1699]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.65\n","\n","[09:43:38] Step: 8,500/50k | Loss: 1.471 | PPL: 1.23 | Best: 1.14\n","           Mem: 1700 | Buf: 68,000 | Phase: wake | ETA: 10.5h\n","\n","üìä Step 8500: Train PPL=4.29 | Eval PPL=1.21 | LR=2.86e-04\n","   VRAM: 3.7GB | Memories: 1700 | Buffer: 68000\n","‚úÖ Checkpoint saved: step_8500\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8514/50000 [5:05:37<26:36:15,  2.31s/it, loss=1.467, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1702]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:44:38] Step: 8,515/50k | Loss: 1.467 | PPL: 1.21 | Best: 1.14\n","           Mem: 1702 | Buf: 68,112 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8524/50000 [5:06:22<26:24:07,  2.29s/it, loss=1.474, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1704]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:45:38] Step: 8,525/50k | Loss: 1.474 | PPL: 1.21 | Best: 1.14\n","           Mem: 1705 | Buf: 68,192 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8539/50000 [5:07:26<25:47:00,  2.24s/it, loss=1.464, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1707]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:46:38] Step: 8,540/50k | Loss: 1.464 | PPL: 1.21 | Best: 1.14\n","           Mem: 1708 | Buf: 68,320 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8554/50000 [5:08:30<26:11:32,  2.28s/it, loss=1.461, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1710]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:47:38] Step: 8,555/50k | Loss: 1.461 | PPL: 1.21 | Best: 1.14\n","           Mem: 1711 | Buf: 68,432 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8569/50000 [5:09:35<26:18:47,  2.29s/it, loss=1.449, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1713]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:48:38] Step: 8,570/50k | Loss: 1.449 | PPL: 1.21 | Best: 1.14\n","           Mem: 1714 | Buf: 68,560 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8582/50000 [5:10:38<45:10:38,  3.93s/it, loss=1.486, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1716]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:49:38] Step: 8,582/50k | Loss: 1.486 | PPL: 1.21 | Best: 1.14\n","           Mem: 1716 | Buf: 68,656 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8594/50000 [5:11:23<25:56:32,  2.26s/it, loss=1.451, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1718]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:50:38] Step: 8,595/50k | Loss: 1.451 | PPL: 1.21 | Best: 1.14\n","           Mem: 1719 | Buf: 68,752 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8596/50000 [5:11:42<59:55:56,  5.21s/it, loss=1.442, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1719]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 8600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8599/50000 [5:11:44<25:52:42,  2.25s/it, loss=1.468, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1719]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.84\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  17%|‚ñà‚ñã        | 8600/50000 [5:12:13<118:49:17, 10.33s/it, loss=1.468, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1719]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 8600: Train PPL=4.31 | Eval PPL=1.20 | LR=2.86e-04\n","   VRAM: 3.7GB | Memories: 1720 | Buffer: 68800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8609/50000 [5:12:38<27:45:18,  2.41s/it, loss=1.470, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1721]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:51:38] Step: 8,609/50k | Loss: 1.485 | PPL: 1.20 | Best: 1.14\n","           Mem: 1721 | Buf: 68,864 | Phase: wake | ETA: 10.5h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8619/50000 [5:13:22<26:07:14,  2.27s/it, loss=1.472, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1723]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:52:38] Step: 8,620/50k | Loss: 1.472 | PPL: 1.20 | Best: 1.14\n","           Mem: 1724 | Buf: 68,960 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8634/50000 [5:14:28<26:38:40,  2.32s/it, loss=1.453, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1726]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:53:38] Step: 8,635/50k | Loss: 1.453 | PPL: 1.20 | Best: 1.14\n","           Mem: 1727 | Buf: 69,072 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8649/50000 [5:15:33<25:59:25,  2.26s/it, loss=1.461, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1729]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:54:38] Step: 8,650/50k | Loss: 1.461 | PPL: 1.20 | Best: 1.14\n","           Mem: 1730 | Buf: 69,200 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8664/50000 [5:16:38<26:03:10,  2.27s/it, loss=1.463, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1732]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:55:38] Step: 8,665/50k | Loss: 1.463 | PPL: 1.20 | Best: 1.14\n","           Mem: 1733 | Buf: 69,312 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8674/50000 [5:17:22<26:37:24,  2.32s/it, loss=1.447, lr=2.86e-04, it/s=0.46, mem=3.7GB, mem_count=1734]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:56:38] Step: 8,675/50k | Loss: 1.447 | PPL: 1.20 | Best: 1.14\n","           Mem: 1735 | Buf: 69,392 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8689/50000 [5:18:27<26:38:52,  2.32s/it, loss=1.452, lr=2.86e-04, it/s=0.45, mem=3.7GB, mem_count=1737]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:57:38] Step: 8,690/50k | Loss: 1.452 | PPL: 1.20 | Best: 1.14\n","           Mem: 1738 | Buf: 69,520 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8696/50000 [5:19:08<61:23:55,  5.35s/it, loss=1.478, lr=2.86e-04, it/s=0.45, mem=3.7GB, mem_count=1739]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 8700\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8699/50000 [5:19:11<26:22:50,  2.30s/it, loss=1.457, lr=2.86e-04, it/s=0.45, mem=3.7GB, mem_count=1739]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.59\n","\n","[09:58:38] Step: 8,700/50k | Loss: 1.457 | PPL: 1.20 | Best: 1.14\n","           Mem: 1740 | Buf: 69,600 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  17%|‚ñà‚ñã        | 8700/50000 [5:19:40<120:33:25, 10.51s/it, loss=1.457, lr=2.86e-04, it/s=0.45, mem=3.7GB, mem_count=1739]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 8700: Train PPL=4.33 | Eval PPL=1.20 | LR=2.86e-04\n","   VRAM: 3.7GB | Memories: 1740 | Buffer: 69600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8714/50000 [5:20:28<26:36:36,  2.32s/it, loss=1.462, lr=2.86e-04, it/s=0.45, mem=3.7GB, mem_count=1742]"]},{"output_type":"stream","name":"stdout","text":["\n","[09:59:38] Step: 8,715/50k | Loss: 1.462 | PPL: 1.20 | Best: 1.14\n","           Mem: 1743 | Buf: 69,712 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8729/50000 [5:21:35<26:41:51,  2.33s/it, loss=1.439, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1745]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:00:38] Step: 8,730/50k | Loss: 1.439 | PPL: 1.20 | Best: 1.14\n","           Mem: 1746 | Buf: 69,840 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  17%|‚ñà‚ñã        | 8739/50000 [5:22:19<26:50:46,  2.34s/it, loss=1.462, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1747]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:01:38] Step: 8,740/50k | Loss: 1.462 | PPL: 1.20 | Best: 1.14\n","           Mem: 1748 | Buf: 69,920 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8754/50000 [5:23:26<26:50:42,  2.34s/it, loss=1.471, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1750]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:02:38] Step: 8,755/50k | Loss: 1.471 | PPL: 1.20 | Best: 1.14\n","           Mem: 1751 | Buf: 70,032 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8769/50000 [5:24:33<26:45:40,  2.34s/it, loss=1.457, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1753]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:03:38] Step: 8,770/50k | Loss: 1.457 | PPL: 1.20 | Best: 1.14\n","           Mem: 1754 | Buf: 70,160 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8780/50000 [5:25:37<87:10:04,  7.61s/it, loss=1.446, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1755]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:04:38] Step: 8,781/50k | Loss: 1.446 | PPL: 1.20 | Best: 1.14\n","           Mem: 1756 | Buf: 70,240 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8794/50000 [5:26:26<26:30:56,  2.32s/it, loss=1.444, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1758]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:05:38] Step: 8,795/50k | Loss: 1.444 | PPL: 1.20 | Best: 1.14\n","           Mem: 1759 | Buf: 70,352 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8796/50000 [5:26:46<63:18:56,  5.53s/it, loss=1.440, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1759]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 8800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8799/50000 [5:26:48<27:04:00,  2.37s/it, loss=1.465, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1759]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.81\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  18%|‚ñà‚ñä        | 8800/50000 [5:27:18<121:44:58, 10.64s/it, loss=1.465, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1759]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 8800: Train PPL=4.33 | Eval PPL=1.18 | LR=2.85e-04\n","   VRAM: 3.7GB | Memories: 1760 | Buffer: 70400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8804/50000 [5:27:21<35:34:53,  3.11s/it, loss=1.462, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1760]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:06:38] Step: 8,805/50k | Loss: 1.462 | PPL: 1.18 | Best: 1.14\n","           Mem: 1761 | Buf: 70,432 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8819/50000 [5:28:30<27:21:12,  2.39s/it, loss=1.476, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1763]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:07:38] Step: 8,820/50k | Loss: 1.476 | PPL: 1.18 | Best: 1.14\n","           Mem: 1764 | Buf: 70,560 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8834/50000 [5:29:37<27:10:17,  2.38s/it, loss=1.459, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1766]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:08:38] Step: 8,835/50k | Loss: 1.459 | PPL: 1.18 | Best: 1.14\n","           Mem: 1766 | Buf: 70,672 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8844/50000 [5:30:23<26:55:44,  2.36s/it, loss=1.484, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1768]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:09:38] Step: 8,845/50k | Loss: 1.484 | PPL: 1.18 | Best: 1.14\n","           Mem: 1769 | Buf: 70,752 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8859/50000 [5:31:31<26:52:54,  2.35s/it, loss=1.460, lr=2.85e-04, it/s=0.45, mem=3.7GB, mem_count=1771]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:10:38] Step: 8,860/50k | Loss: 1.460 | PPL: 1.18 | Best: 1.14\n","           Mem: 1772 | Buf: 70,880 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8872/50000 [5:32:38<47:25:43,  4.15s/it, loss=1.526, lr=2.85e-04, it/s=0.44, mem=3.7GB, mem_count=1774]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:11:38] Step: 8,872/50k | Loss: 1.487 | PPL: 1.18 | Best: 1.14\n","           Mem: 1774 | Buf: 70,960 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8884/50000 [5:33:25<26:52:48,  2.35s/it, loss=1.443, lr=2.85e-04, it/s=0.44, mem=3.7GB, mem_count=1776]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:12:38] Step: 8,885/50k | Loss: 1.443 | PPL: 1.18 | Best: 1.14\n","           Mem: 1777 | Buf: 71,072 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8896/50000 [5:34:31<65:00:26,  5.69s/it, loss=1.450, lr=2.85e-04, it/s=0.44, mem=3.7GB, mem_count=1779]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 8900\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8899/50000 [5:34:34<27:36:25,  2.42s/it, loss=1.441, lr=2.85e-04, it/s=0.44, mem=3.7GB, mem_count=1779]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.58\n","\n","[10:13:38] Step: 8,900/50k | Loss: 1.441 | PPL: 1.18 | Best: 1.14\n","           Mem: 1780 | Buf: 71,200 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  18%|‚ñà‚ñä        | 8900/50000 [5:35:03<121:35:50, 10.65s/it, loss=1.441, lr=2.85e-04, it/s=0.44, mem=3.7GB, mem_count=1779]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 8900: Train PPL=4.31 | Eval PPL=1.19 | LR=2.85e-04\n","   VRAM: 3.7GB | Memories: 1780 | Buffer: 71200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8909/50000 [5:35:30<28:39:42,  2.51s/it, loss=1.458, lr=2.85e-04, it/s=0.44, mem=3.7GB, mem_count=1781]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:14:38] Step: 8,910/50k | Loss: 1.458 | PPL: 1.19 | Best: 1.14\n","           Mem: 1782 | Buf: 71,280 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8924/50000 [5:36:37<27:01:05,  2.37s/it, loss=1.450, lr=2.85e-04, it/s=0.44, mem=3.7GB, mem_count=1784]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:15:38] Step: 8,925/50k | Loss: 1.450 | PPL: 1.19 | Best: 1.14\n","           Mem: 1784 | Buf: 71,392 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8934/50000 [5:37:25<27:32:49,  2.41s/it, loss=1.478, lr=2.85e-04, it/s=0.44, mem=3.7GB, mem_count=1786]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:16:38] Step: 8,935/50k | Loss: 1.478 | PPL: 1.19 | Best: 1.14\n","           Mem: 1787 | Buf: 71,472 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8949/50000 [5:38:34<27:34:48,  2.42s/it, loss=1.463, lr=2.85e-04, it/s=0.44, mem=3.7GB, mem_count=1789]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:17:38] Step: 8,950/50k | Loss: 1.463 | PPL: 1.19 | Best: 1.14\n","           Mem: 1790 | Buf: 71,600 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8959/50000 [5:39:21<27:16:31,  2.39s/it, loss=1.457, lr=2.85e-04, it/s=0.44, mem=3.7GB, mem_count=1791]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:18:38] Step: 8,960/50k | Loss: 1.457 | PPL: 1.19 | Best: 1.14\n","           Mem: 1792 | Buf: 71,680 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8974/50000 [5:40:30<27:48:03,  2.44s/it, loss=1.460, lr=2.84e-04, it/s=0.44, mem=3.7GB, mem_count=1794]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:19:38] Step: 8,975/50k | Loss: 1.460 | PPL: 1.19 | Best: 1.14\n","           Mem: 1795 | Buf: 71,792 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8985/50000 [5:41:37<90:18:55,  7.93s/it, loss=1.447, lr=2.84e-04, it/s=0.44, mem=3.7GB, mem_count=1796]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:20:38] Step: 8,986/50k | Loss: 1.447 | PPL: 1.19 | Best: 1.14\n","           Mem: 1797 | Buf: 71,872 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8996/50000 [5:42:24<64:21:35,  5.65s/it, loss=1.483, lr=2.84e-04, it/s=0.44, mem=3.7GB, mem_count=1799]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 9000\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 8999/50000 [5:42:27<27:19:25,  2.40s/it, loss=1.436, lr=2.84e-04, it/s=0.44, mem=3.7GB, mem_count=1799]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.60\n","\n","[10:21:38] Step: 9,000/50k | Loss: 1.436 | PPL: 1.19 | Best: 1.14\n","           Mem: 1800 | Buf: 72,000 | Phase: wake | ETA: 10.4h\n","\n","üìä Step 9000: Train PPL=4.30 | Eval PPL=1.21 | LR=2.84e-04\n","   VRAM: 3.7GB | Memories: 1800 | Buffer: 72000\n","‚úÖ Checkpoint saved: step_9000\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9009/50000 [5:43:33<30:41:39,  2.70s/it, loss=1.449, lr=2.84e-04, it/s=0.44, mem=3.7GB, mem_count=1801]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:22:38] Step: 9,010/50k | Loss: 1.449 | PPL: 1.21 | Best: 1.14\n","           Mem: 1802 | Buf: 72,080 | Phase: wake | ETA: 10.4h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9019/50000 [5:44:21<28:21:34,  2.49s/it, loss=1.478, lr=2.84e-04, it/s=0.44, mem=3.7GB, mem_count=1803]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:23:38] Step: 9,020/50k | Loss: 1.478 | PPL: 1.21 | Best: 1.14\n","           Mem: 1804 | Buf: 72,160 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9034/50000 [5:45:33<27:54:22,  2.45s/it, loss=1.461, lr=2.84e-04, it/s=0.44, mem=3.7GB, mem_count=1806]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:24:38] Step: 9,035/50k | Loss: 1.461 | PPL: 1.21 | Best: 1.14\n","           Mem: 1807 | Buf: 72,272 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9044/50000 [5:46:20<27:56:18,  2.46s/it, loss=1.458, lr=2.84e-04, it/s=0.44, mem=3.7GB, mem_count=1808]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:25:38] Step: 9,045/50k | Loss: 1.458 | PPL: 1.21 | Best: 1.14\n","           Mem: 1809 | Buf: 72,352 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9059/50000 [5:47:31<27:49:30,  2.45s/it, loss=1.462, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1811]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:26:38] Step: 9,060/50k | Loss: 1.462 | PPL: 1.21 | Best: 1.14\n","           Mem: 1812 | Buf: 72,480 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9069/50000 [5:48:19<28:04:37,  2.47s/it, loss=1.465, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1813]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:27:38] Step: 9,070/50k | Loss: 1.465 | PPL: 1.21 | Best: 1.14\n","           Mem: 1814 | Buf: 72,560 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9084/50000 [5:49:30<27:41:37,  2.44s/it, loss=1.477, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1816]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:28:38] Step: 9,085/50k | Loss: 1.477 | PPL: 1.21 | Best: 1.14\n","           Mem: 1817 | Buf: 72,672 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9095/50000 [5:50:37<90:15:53,  7.94s/it, loss=1.451, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1818]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:29:38] Step: 9,096/50k | Loss: 1.451 | PPL: 1.21 | Best: 1.14\n","           Mem: 1819 | Buf: 72,752 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9096/50000 [5:50:38<65:34:37,  5.77s/it, loss=1.465, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1819]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 9100\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9099/50000 [5:50:41<27:44:44,  2.44s/it, loss=1.483, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1819]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.86\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  18%|‚ñà‚ñä        | 9100/50000 [5:51:11<125:44:45, 11.07s/it, loss=1.483, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1819]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 9100: Train PPL=4.32 | Eval PPL=1.21 | LR=2.84e-04\n","   VRAM: 3.7GB | Memories: 1820 | Buffer: 72800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9109/50000 [5:51:38<29:20:00,  2.58s/it, loss=1.452, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1821]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:30:38] Step: 9,109/50k | Loss: 1.438 | PPL: 1.21 | Best: 1.14\n","           Mem: 1821 | Buf: 72,864 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9119/50000 [5:52:27<28:26:47,  2.51s/it, loss=1.450, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1823]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:31:38] Step: 9,120/50k | Loss: 1.450 | PPL: 1.21 | Best: 1.14\n","           Mem: 1824 | Buf: 72,960 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9133/50000 [5:53:38<36:40:08,  3.23s/it, loss=1.465, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1826]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:32:38] Step: 9,134/50k | Loss: 1.465 | PPL: 1.21 | Best: 1.14\n","           Mem: 1826 | Buf: 73,056 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9144/50000 [5:54:27<28:15:29,  2.49s/it, loss=1.451, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1828]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:33:38] Step: 9,145/50k | Loss: 1.451 | PPL: 1.21 | Best: 1.14\n","           Mem: 1829 | Buf: 73,152 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9157/50000 [5:55:38<50:03:32,  4.41s/it, loss=1.454, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1831]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:34:38] Step: 9,157/50k | Loss: 1.443 | PPL: 1.21 | Best: 1.14\n","           Mem: 1831 | Buf: 73,248 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9169/50000 [5:56:28<28:08:31,  2.48s/it, loss=1.462, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1833]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:35:38] Step: 9,170/50k | Loss: 1.462 | PPL: 1.21 | Best: 1.14\n","           Mem: 1834 | Buf: 73,360 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9181/50000 [5:57:38<67:33:41,  5.96s/it, loss=1.462, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1836]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:36:38] Step: 9,181/50k | Loss: 1.478 | PPL: 1.21 | Best: 1.14\n","           Mem: 1836 | Buf: 73,440 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9194/50000 [5:58:29<28:10:24,  2.49s/it, loss=1.451, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1838]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:37:38] Step: 9,195/50k | Loss: 1.451 | PPL: 1.21 | Best: 1.14\n","           Mem: 1839 | Buf: 73,552 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9196/50000 [5:58:51<67:43:21,  5.97s/it, loss=1.461, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1839]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 9200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9199/50000 [5:58:54<28:27:44,  2.51s/it, loss=1.455, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1839]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.57\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  18%|‚ñà‚ñä        | 9200/50000 [5:59:24<125:54:57, 11.11s/it, loss=1.455, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1839]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 9200: Train PPL=4.31 | Eval PPL=1.20 | LR=2.84e-04\n","   VRAM: 3.7GB | Memories: 1840 | Buffer: 73600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9204/50000 [5:59:28<37:00:02,  3.27s/it, loss=1.456, lr=2.84e-04, it/s=0.43, mem=3.7GB, mem_count=1840]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:38:38] Step: 9,205/50k | Loss: 1.456 | PPL: 1.20 | Best: 1.14\n","           Mem: 1841 | Buf: 73,632 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9214/50000 [6:00:18<29:10:32,  2.58s/it, loss=1.452, lr=2.83e-04, it/s=0.43, mem=3.7GB, mem_count=1842]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:39:38] Step: 9,215/50k | Loss: 1.452 | PPL: 1.20 | Best: 1.14\n","           Mem: 1843 | Buf: 73,712 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9229/50000 [6:01:32<28:44:19,  2.54s/it, loss=1.483, lr=2.83e-04, it/s=0.43, mem=3.7GB, mem_count=1845]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:40:38] Step: 9,230/50k | Loss: 1.483 | PPL: 1.20 | Best: 1.14\n","           Mem: 1846 | Buf: 73,840 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  18%|‚ñà‚ñä        | 9239/50000 [6:02:21<28:51:28,  2.55s/it, loss=1.454, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1847]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:41:38] Step: 9,240/50k | Loss: 1.454 | PPL: 1.20 | Best: 1.14\n","           Mem: 1848 | Buf: 73,920 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñä        | 9254/50000 [6:03:34<28:16:46,  2.50s/it, loss=1.476, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1850]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:42:38] Step: 9,255/50k | Loss: 1.476 | PPL: 1.20 | Best: 1.14\n","           Mem: 1851 | Buf: 74,032 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñä        | 9264/50000 [6:04:23<28:26:16,  2.51s/it, loss=1.454, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1852]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:43:38] Step: 9,265/50k | Loss: 1.454 | PPL: 1.20 | Best: 1.14\n","           Mem: 1853 | Buf: 74,112 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñä        | 9279/50000 [6:05:37<28:53:39,  2.55s/it, loss=1.456, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1855]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:44:38] Step: 9,280/50k | Loss: 1.456 | PPL: 1.20 | Best: 1.14\n","           Mem: 1856 | Buf: 74,240 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñä        | 9289/50000 [6:06:28<29:06:21,  2.57s/it, loss=1.447, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1857]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:45:38] Step: 9,290/50k | Loss: 1.447 | PPL: 1.20 | Best: 1.14\n","           Mem: 1858 | Buf: 74,320 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñä        | 9296/50000 [6:07:15<69:08:00,  6.11s/it, loss=1.444, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1859]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 9300\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñä        | 9299/50000 [6:07:17<28:57:29,  2.56s/it, loss=1.446, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1859]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.93\n","\n","[10:46:38] Step: 9,300/50k | Loss: 1.446 | PPL: 1.20 | Best: 1.14\n","           Mem: 1860 | Buf: 74,400 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  19%|‚ñà‚ñä        | 9300/50000 [6:07:52<141:25:07, 12.51s/it, loss=1.446, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1859]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 9300: Train PPL=4.30 | Eval PPL=1.19 | LR=2.83e-04\n","   VRAM: 3.7GB | Memories: 1860 | Buffer: 74400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñä        | 9309/50000 [6:08:21<30:47:24,  2.72s/it, loss=1.478, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1861]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:47:38] Step: 9,310/50k | Loss: 1.478 | PPL: 1.19 | Best: 1.14\n","           Mem: 1862 | Buf: 74,480 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñä        | 9324/50000 [6:09:36<28:56:44,  2.56s/it, loss=1.473, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1864]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:48:38] Step: 9,325/50k | Loss: 1.473 | PPL: 1.19 | Best: 1.14\n","           Mem: 1865 | Buf: 74,592 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñä        | 9334/50000 [6:10:25<28:43:04,  2.54s/it, loss=1.459, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1866]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:49:38] Step: 9,335/50k | Loss: 1.459 | PPL: 1.19 | Best: 1.14\n","           Mem: 1867 | Buf: 74,672 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñä        | 9346/50000 [6:11:38<70:26:16,  6.24s/it, loss=1.452, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1869]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:50:38] Step: 9,346/50k | Loss: 1.450 | PPL: 1.19 | Best: 1.14\n","           Mem: 1869 | Buf: 74,752 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñä        | 9359/50000 [6:12:31<28:57:52,  2.57s/it, loss=1.449, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1871]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:51:38] Step: 9,360/50k | Loss: 1.449 | PPL: 1.19 | Best: 1.14\n","           Mem: 1872 | Buf: 74,880 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñä        | 9369/50000 [6:13:21<29:17:35,  2.60s/it, loss=1.456, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1873]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:52:38] Step: 9,370/50k | Loss: 1.456 | PPL: 1.19 | Best: 1.14\n","           Mem: 1874 | Buf: 74,960 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9384/50000 [6:14:37<29:17:01,  2.60s/it, loss=1.451, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1876]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:53:38] Step: 9,385/50k | Loss: 1.451 | PPL: 1.19 | Best: 1.14\n","           Mem: 1877 | Buf: 75,072 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9394/50000 [6:15:27<28:56:53,  2.57s/it, loss=1.485, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1878]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:54:38] Step: 9,395/50k | Loss: 1.485 | PPL: 1.19 | Best: 1.14\n","           Mem: 1879 | Buf: 75,152 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9396/50000 [6:15:50<70:26:05,  6.24s/it, loss=1.488, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1879]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 9400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9399/50000 [6:15:53<29:24:50,  2.61s/it, loss=1.470, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1879]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 1.20\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  19%|‚ñà‚ñâ        | 9400/50000 [6:16:28<141:04:11, 12.51s/it, loss=1.470, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1879]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 9400: Train PPL=4.32 | Eval PPL=1.22 | LR=2.83e-04\n","   VRAM: 3.7GB | Memories: 1880 | Buffer: 75200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9404/50000 [6:16:32<40:05:06,  3.55s/it, loss=1.456, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1880]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:55:38] Step: 9,405/50k | Loss: 1.456 | PPL: 1.22 | Best: 1.14\n","           Mem: 1881 | Buf: 75,232 | Phase: wake | ETA: 10.3h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9414/50000 [6:17:22<29:14:19,  2.59s/it, loss=1.461, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1882]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:56:38] Step: 9,415/50k | Loss: 1.461 | PPL: 1.22 | Best: 1.14\n","           Mem: 1883 | Buf: 75,312 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9429/50000 [6:18:37<29:17:24,  2.60s/it, loss=1.438, lr=2.83e-04, it/s=0.42, mem=3.7GB, mem_count=1885]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:57:38] Step: 9,430/50k | Loss: 1.438 | PPL: 1.22 | Best: 1.14\n","           Mem: 1886 | Buf: 75,440 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9439/50000 [6:19:29<29:34:37,  2.63s/it, loss=1.465, lr=2.83e-04, it/s=0.41, mem=3.7GB, mem_count=1887]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:58:38] Step: 9,440/50k | Loss: 1.465 | PPL: 1.22 | Best: 1.14\n","           Mem: 1888 | Buf: 75,520 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9449/50000 [6:20:19<29:14:59,  2.60s/it, loss=1.448, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1889]"]},{"output_type":"stream","name":"stdout","text":["\n","[10:59:38] Step: 9,450/50k | Loss: 1.448 | PPL: 1.22 | Best: 1.14\n","           Mem: 1890 | Buf: 75,600 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9464/50000 [6:21:37<29:45:47,  2.64s/it, loss=1.498, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1892]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:00:38] Step: 9,465/50k | Loss: 1.498 | PPL: 1.22 | Best: 1.14\n","           Mem: 1893 | Buf: 75,712 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9474/50000 [6:22:28<29:41:23,  2.64s/it, loss=1.468, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1894]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:01:38] Step: 9,475/50k | Loss: 1.468 | PPL: 1.22 | Best: 1.14\n","           Mem: 1895 | Buf: 75,792 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9484/50000 [6:23:19<29:22:26,  2.61s/it, loss=1.439, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1896]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:02:38] Step: 9,485/50k | Loss: 1.439 | PPL: 1.22 | Best: 1.14\n","           Mem: 1897 | Buf: 75,872 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9496/50000 [6:24:35<71:45:12,  6.38s/it, loss=1.478, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1899]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 9500\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9499/50000 [6:24:38<29:53:04,  2.66s/it, loss=1.476, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1899]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.90\n","\n","[11:03:38] Step: 9,500/50k | Loss: 1.476 | PPL: 1.22 | Best: 1.14\n","           Mem: 1900 | Buf: 76,000 | Phase: wake | ETA: 10.2h\n","\n","üìä Step 9500: Train PPL=4.32 | Eval PPL=1.19 | LR=2.82e-04\n","   VRAM: 3.7GB | Memories: 1900 | Buffer: 76000\n","‚úÖ Checkpoint saved: step_9500\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9504/50000 [6:25:20<43:20:34,  3.85s/it, loss=1.467, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1900]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:04:38] Step: 9,505/50k | Loss: 1.467 | PPL: 1.19 | Best: 1.14\n","           Mem: 1901 | Buf: 76,032 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9519/50000 [6:26:38<29:58:11,  2.67s/it, loss=1.461, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1903]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:05:38] Step: 9,519/50k | Loss: 1.461 | PPL: 1.19 | Best: 1.14\n","           Mem: 1903 | Buf: 76,144 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9529/50000 [6:27:31<29:55:45,  2.66s/it, loss=1.449, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1905]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:06:38] Step: 9,530/50k | Loss: 1.449 | PPL: 1.19 | Best: 1.14\n","           Mem: 1906 | Buf: 76,240 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9539/50000 [6:28:23<29:52:25,  2.66s/it, loss=1.456, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1907]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:07:38] Step: 9,540/50k | Loss: 1.456 | PPL: 1.19 | Best: 1.14\n","           Mem: 1908 | Buf: 76,320 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9550/50000 [6:29:38<98:08:29,  8.73s/it, loss=1.470, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1909]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:08:38] Step: 9,551/50k | Loss: 1.470 | PPL: 1.19 | Best: 1.14\n","           Mem: 1910 | Buf: 76,400 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9564/50000 [6:30:34<30:03:29,  2.68s/it, loss=1.440, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1912]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:09:38] Step: 9,565/50k | Loss: 1.440 | PPL: 1.19 | Best: 1.14\n","           Mem: 1913 | Buf: 76,512 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9574/50000 [6:31:26<30:02:47,  2.68s/it, loss=1.463, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1914]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:10:38] Step: 9,575/50k | Loss: 1.463 | PPL: 1.19 | Best: 1.14\n","           Mem: 1915 | Buf: 76,592 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9584/50000 [6:32:18<29:54:14,  2.66s/it, loss=1.444, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1916]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:11:38] Step: 9,585/50k | Loss: 1.444 | PPL: 1.19 | Best: 1.14\n","           Mem: 1917 | Buf: 76,672 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9596/50000 [6:33:34<72:15:50,  6.44s/it, loss=1.449, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1919]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 9600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9599/50000 [6:33:37<29:56:49,  2.67s/it, loss=1.469, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1919]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.96\n","\n","[11:12:38] Step: 9,600/50k | Loss: 1.469 | PPL: 1.19 | Best: 1.14\n","           Mem: 1920 | Buf: 76,800 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  19%|‚ñà‚ñâ        | 9600/50000 [6:34:09<132:32:21, 11.81s/it, loss=1.469, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1919]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 9600: Train PPL=4.31 | Eval PPL=1.20 | LR=2.82e-04\n","   VRAM: 3.7GB | Memories: 1920 | Buffer: 76800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9607/50000 [6:34:37<56:19:36,  5.02s/it, loss=1.483, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1921]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:13:38] Step: 9,608/50k | Loss: 1.483 | PPL: 1.20 | Best: 1.14\n","           Mem: 1921 | Buf: 76,848 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9619/50000 [6:35:33<30:25:57,  2.71s/it, loss=1.468, lr=2.82e-04, it/s=0.41, mem=3.7GB, mem_count=1923]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:14:38] Step: 9,620/50k | Loss: 1.468 | PPL: 1.20 | Best: 1.14\n","           Mem: 1924 | Buf: 76,960 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9629/50000 [6:36:25<29:53:29,  2.67s/it, loss=1.469, lr=2.82e-04, it/s=0.40, mem=3.7GB, mem_count=1925]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:15:38] Step: 9,630/50k | Loss: 1.469 | PPL: 1.20 | Best: 1.14\n","           Mem: 1926 | Buf: 77,040 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9639/50000 [6:37:18<30:17:59,  2.70s/it, loss=1.465, lr=2.82e-04, it/s=0.40, mem=3.7GB, mem_count=1927]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:16:38] Step: 9,640/50k | Loss: 1.465 | PPL: 1.20 | Best: 1.14\n","           Mem: 1928 | Buf: 77,120 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9654/50000 [6:38:38<30:29:56,  2.72s/it, loss=1.450, lr=2.82e-04, it/s=0.40, mem=3.7GB, mem_count=1930]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:17:38] Step: 9,655/50k | Loss: 1.450 | PPL: 1.20 | Best: 1.14\n","           Mem: 1930 | Buf: 77,232 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9664/50000 [6:39:31<30:19:23,  2.71s/it, loss=1.455, lr=2.82e-04, it/s=0.40, mem=3.7GB, mem_count=1932]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:18:38] Step: 9,665/50k | Loss: 1.455 | PPL: 1.20 | Best: 1.14\n","           Mem: 1933 | Buf: 77,312 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9674/50000 [6:40:24<30:13:39,  2.70s/it, loss=1.437, lr=2.82e-04, it/s=0.40, mem=3.7GB, mem_count=1934]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:19:38] Step: 9,675/50k | Loss: 1.437 | PPL: 1.20 | Best: 1.14\n","           Mem: 1935 | Buf: 77,392 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9684/50000 [6:41:18<30:24:29,  2.72s/it, loss=1.469, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1936]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:20:38] Step: 9,685/50k | Loss: 1.469 | PPL: 1.20 | Best: 1.14\n","           Mem: 1937 | Buf: 77,472 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9696/50000 [6:42:36<73:04:45,  6.53s/it, loss=1.449, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1939] "]},{"output_type":"stream","name":"stdout","text":["  Batches: 9700\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9699/50000 [6:42:38<30:14:17,  2.70s/it, loss=1.472, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1939]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:21:38] Step: 9,699/50k | Loss: 1.472 | PPL: 1.20 | Best: 1.14\n","           Mem: 1939 | Buf: 77,584 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  19%|‚ñà‚ñâ        | 9699/50000 [6:42:38<30:14:17,  2.70s/it, loss=1.459, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1939]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 1.16\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  19%|‚ñà‚ñâ        | 9700/50000 [6:43:12<135:43:52, 12.12s/it, loss=1.459, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1939]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 9700: Train PPL=4.31 | Eval PPL=1.21 | LR=2.81e-04\n","   VRAM: 3.7GB | Memories: 1940 | Buffer: 77600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9704/50000 [6:43:15<38:40:16,  3.45s/it, loss=1.480, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1940]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:22:38] Step: 9,705/50k | Loss: 1.480 | PPL: 1.21 | Best: 1.14\n","           Mem: 1941 | Buf: 77,632 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9719/50000 [6:44:35<30:18:33,  2.71s/it, loss=1.440, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1943]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:23:38] Step: 9,720/50k | Loss: 1.440 | PPL: 1.21 | Best: 1.14\n","           Mem: 1944 | Buf: 77,760 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9729/50000 [6:45:29<30:49:05,  2.75s/it, loss=1.461, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1945]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:24:38] Step: 9,730/50k | Loss: 1.461 | PPL: 1.21 | Best: 1.14\n","           Mem: 1946 | Buf: 77,840 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9739/50000 [6:46:23<30:18:32,  2.71s/it, loss=1.457, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1947]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:25:38] Step: 9,740/50k | Loss: 1.457 | PPL: 1.21 | Best: 1.14\n","           Mem: 1948 | Buf: 77,920 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  19%|‚ñà‚ñâ        | 9749/50000 [6:47:17<30:48:37,  2.76s/it, loss=1.462, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1949]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:26:38] Step: 9,750/50k | Loss: 1.462 | PPL: 1.21 | Best: 1.14\n","           Mem: 1950 | Buf: 78,000 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9763/50000 [6:48:38<41:05:14,  3.68s/it, loss=1.469, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1952]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:27:38] Step: 9,763/50k | Loss: 1.469 | PPL: 1.21 | Best: 1.14\n","           Mem: 1952 | Buf: 78,096 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9774/50000 [6:49:34<30:36:43,  2.74s/it, loss=1.443, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1954]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:28:38] Step: 9,775/50k | Loss: 1.443 | PPL: 1.21 | Best: 1.14\n","           Mem: 1955 | Buf: 78,192 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9784/50000 [6:50:29<31:22:21,  2.81s/it, loss=1.458, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1956]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:29:38] Step: 9,785/50k | Loss: 1.458 | PPL: 1.21 | Best: 1.14\n","           Mem: 1957 | Buf: 78,272 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9794/50000 [6:51:23<30:55:41,  2.77s/it, loss=1.441, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1958]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:30:38] Step: 9,795/50k | Loss: 1.441 | PPL: 1.21 | Best: 1.14\n","           Mem: 1959 | Buf: 78,352 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9796/50000 [6:51:48<74:28:40,  6.67s/it, loss=1.456, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1959] "]},{"output_type":"stream","name":"stdout","text":["  Batches: 9800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9799/50000 [6:51:51<30:49:06,  2.76s/it, loss=1.454, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1959]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.94\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  20%|‚ñà‚ñâ        | 9800/50000 [6:52:24<137:37:15, 12.32s/it, loss=1.454, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1959]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 9800: Train PPL=4.29 | Eval PPL=1.18 | LR=2.81e-04\n","   VRAM: 3.7GB | Memories: 1960 | Buffer: 78400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9804/50000 [6:52:28<39:11:26,  3.51s/it, loss=1.514, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1960]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:31:38] Step: 9,805/50k | Loss: 1.514 | PPL: 1.18 | Best: 1.14\n","           Mem: 1961 | Buf: 78,432 | Phase: wake | ETA: 10.2h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9814/50000 [6:53:22<30:36:07,  2.74s/it, loss=1.438, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1962]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:32:38] Step: 9,815/50k | Loss: 1.438 | PPL: 1.18 | Best: 1.14\n","           Mem: 1963 | Buf: 78,512 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9824/50000 [6:54:16<30:52:51,  2.77s/it, loss=1.466, lr=2.81e-04, it/s=0.40, mem=3.7GB, mem_count=1964]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:33:38] Step: 9,825/50k | Loss: 1.466 | PPL: 1.18 | Best: 1.14\n","           Mem: 1965 | Buf: 78,592 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9839/50000 [6:55:37<30:28:03,  2.73s/it, loss=1.464, lr=2.81e-04, it/s=0.39, mem=3.7GB, mem_count=1967]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:34:38] Step: 9,840/50k | Loss: 1.464 | PPL: 1.18 | Best: 1.14\n","           Mem: 1968 | Buf: 78,720 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9849/50000 [6:56:32<31:10:13,  2.79s/it, loss=1.453, lr=2.81e-04, it/s=0.39, mem=3.7GB, mem_count=1969]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:35:38] Step: 9,850/50k | Loss: 1.453 | PPL: 1.18 | Best: 1.14\n","           Mem: 1970 | Buf: 78,800 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9859/50000 [6:57:27<31:17:20,  2.81s/it, loss=1.457, lr=2.81e-04, it/s=0.39, mem=3.7GB, mem_count=1971]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:36:38] Step: 9,860/50k | Loss: 1.457 | PPL: 1.18 | Best: 1.14\n","           Mem: 1972 | Buf: 78,880 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9869/50000 [6:58:22<30:51:38,  2.77s/it, loss=1.458, lr=2.81e-04, it/s=0.39, mem=3.7GB, mem_count=1973]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:37:38] Step: 9,870/50k | Loss: 1.458 | PPL: 1.18 | Best: 1.14\n","           Mem: 1974 | Buf: 78,960 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9879/50000 [6:59:17<31:20:08,  2.81s/it, loss=1.459, lr=2.81e-04, it/s=0.39, mem=3.7GB, mem_count=1975]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:38:38] Step: 9,880/50k | Loss: 1.459 | PPL: 1.18 | Best: 1.14\n","           Mem: 1976 | Buf: 79,040 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9890/50000 [7:00:37<105:54:10,  9.51s/it, loss=1.451, lr=2.81e-04, it/s=0.39, mem=3.7GB, mem_count=1977]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:39:38] Step: 9,891/50k | Loss: 1.451 | PPL: 1.18 | Best: 1.14\n","           Mem: 1978 | Buf: 79,120 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9896/50000 [7:01:06<76:11:39,  6.84s/it, loss=1.499, lr=2.81e-04, it/s=0.39, mem=3.7GB, mem_count=1979] "]},{"output_type":"stream","name":"stdout","text":["  Batches: 9900\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9899/50000 [7:01:09<31:21:14,  2.81s/it, loss=1.478, lr=2.81e-04, it/s=0.39, mem=3.7GB, mem_count=1979]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 1.05\n","\n","[11:40:38] Step: 9,900/50k | Loss: 1.478 | PPL: 1.18 | Best: 1.14\n","           Mem: 1980 | Buf: 79,200 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  20%|‚ñà‚ñâ        | 9900/50000 [7:01:45<146:19:02, 13.14s/it, loss=1.478, lr=2.81e-04, it/s=0.39, mem=3.7GB, mem_count=1979]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 9900: Train PPL=4.31 | Eval PPL=1.20 | LR=2.81e-04\n","   VRAM: 3.7GB | Memories: 1980 | Buffer: 79200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9909/50000 [7:02:17<33:09:17,  2.98s/it, loss=1.449, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=1981]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:41:38] Step: 9,910/50k | Loss: 1.449 | PPL: 1.20 | Best: 1.14\n","           Mem: 1982 | Buf: 79,280 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9920/50000 [7:03:38<106:17:02,  9.55s/it, loss=1.467, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=1983]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:42:38] Step: 9,920/50k | Loss: 1.467 | PPL: 1.20 | Best: 1.14\n","           Mem: 1984 | Buf: 79,360 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9934/50000 [7:04:37<31:00:05,  2.79s/it, loss=1.452, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=1986]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:43:38] Step: 9,935/50k | Loss: 1.452 | PPL: 1.20 | Best: 1.14\n","           Mem: 1987 | Buf: 79,472 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9944/50000 [7:05:33<31:20:11,  2.82s/it, loss=1.443, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=1988]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:44:38] Step: 9,945/50k | Loss: 1.443 | PPL: 1.20 | Best: 1.14\n","           Mem: 1989 | Buf: 79,552 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9954/50000 [7:06:28<31:06:45,  2.80s/it, loss=1.455, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=1990]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:45:38] Step: 9,955/50k | Loss: 1.455 | PPL: 1.20 | Best: 1.14\n","           Mem: 1991 | Buf: 79,632 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9964/50000 [7:07:24<31:22:32,  2.82s/it, loss=1.446, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=1992]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:46:38] Step: 9,965/50k | Loss: 1.446 | PPL: 1.20 | Best: 1.14\n","           Mem: 1993 | Buf: 79,712 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9974/50000 [7:08:20<31:14:31,  2.81s/it, loss=1.472, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=1994]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:47:38] Step: 9,975/50k | Loss: 1.472 | PPL: 1.20 | Best: 1.14\n","           Mem: 1995 | Buf: 79,792 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9984/50000 [7:09:16<31:30:42,  2.83s/it, loss=1.488, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=1996]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:48:38] Step: 9,985/50k | Loss: 1.488 | PPL: 1.20 | Best: 1.14\n","           Mem: 1997 | Buf: 79,872 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9996/50000 [7:10:38<77:26:42,  6.97s/it, loss=1.458, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=1999] "]},{"output_type":"stream","name":"stdout","text":["\n","[11:49:38] Step: 9,996/50k | Loss: 1.453 | PPL: 1.20 | Best: 1.14\n","           Mem: 1999 | Buf: 79,952 | Phase: wake | ETA: 10.1h\n","  Batches: 10000\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñâ        | 9999/50000 [7:10:40<31:44:53,  2.86s/it, loss=1.489, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=1999]"]},{"output_type":"stream","name":"stdout","text":["üåô Entering SLEEP phase at step 10000\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  20%|‚ñà‚ñâ        | 9999/50000 [7:10:41<31:44:53,  2.86s/it, loss=1.448, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=1999]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.70\n","\n","üìä Step 10000: Train PPL=4.32 | Eval PPL=1.18 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2000 | Buffer: 80000\n","‚úÖ Checkpoint saved: step_10000\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  20%|‚ñà‚ñà        | 10000/50000 [7:11:23<164:57:40, 14.85s/it, loss=1.448, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=1999]"]},{"output_type":"stream","name":"stdout","text":["\n","üåô Sleep Phase at step 10000 - Memory Consolidation\n","  üîÑ Replaying 25 batches from memory...\n","\n","[11:50:38] Step: 10,000/50k | Loss: 1.448 | PPL: 1.18 | Best: 1.14\n","           Mem: 2000 | Buf: 80,000 | Phase: sleep | ETA: 10.1h\n","  ‚úÖ Replay complete: 25/25 batches\n","  üìâ Memory decay | Memories: 2000\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10009/50000 [7:12:14<38:08:44,  3.43s/it, loss=1.505, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=2001]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:51:38] Step: 10,010/50k | Loss: 1.505 | PPL: 1.18 | Best: 1.14\n","           Mem: 2002 | Buf: 80,080 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10023/50000 [7:13:38<42:28:51,  3.83s/it, loss=1.504, lr=2.80e-04, it/s=0.39, mem=3.7GB, mem_count=2004]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:52:38] Step: 10,023/50k | Loss: 1.544 | PPL: 1.18 | Best: 1.14\n","           Mem: 2004 | Buf: 80,176 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10034/50000 [7:14:36<32:01:36,  2.88s/it, loss=1.523, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2006]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:53:38] Step: 10,035/50k | Loss: 1.523 | PPL: 1.18 | Best: 1.14\n","           Mem: 2007 | Buf: 80,272 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10044/50000 [7:15:34<32:07:00,  2.89s/it, loss=1.490, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2008]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:54:38] Step: 10,045/50k | Loss: 1.490 | PPL: 1.18 | Best: 1.14\n","           Mem: 2009 | Buf: 80,352 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10054/50000 [7:16:31<32:06:11,  2.89s/it, loss=1.481, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2010]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:55:38] Step: 10,055/50k | Loss: 1.481 | PPL: 1.18 | Best: 1.14\n","           Mem: 2011 | Buf: 80,432 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10064/50000 [7:17:28<31:55:41,  2.88s/it, loss=1.494, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2012]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:56:38] Step: 10,065/50k | Loss: 1.494 | PPL: 1.18 | Best: 1.14\n","           Mem: 2013 | Buf: 80,512 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10074/50000 [7:18:25<31:35:11,  2.85s/it, loss=1.488, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2014]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:57:38] Step: 10,075/50k | Loss: 1.488 | PPL: 1.18 | Best: 1.14\n","           Mem: 2015 | Buf: 80,592 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10084/50000 [7:19:22<32:01:23,  2.89s/it, loss=1.497, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2016]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:58:38] Step: 10,085/50k | Loss: 1.497 | PPL: 1.18 | Best: 1.14\n","           Mem: 2017 | Buf: 80,672 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10094/50000 [7:20:19<32:11:05,  2.90s/it, loss=1.476, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2018]"]},{"output_type":"stream","name":"stdout","text":["\n","[11:59:38] Step: 10,095/50k | Loss: 1.476 | PPL: 1.18 | Best: 1.14\n","           Mem: 2019 | Buf: 80,752 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  20%|‚ñà‚ñà        | 10095/50000 [7:20:45<108:53:40,  9.82s/it, loss=1.476, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2018]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 10100\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10099/50000 [7:20:48<32:10:28,  2.90s/it, loss=1.496, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2019]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 1.04\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  20%|‚ñà‚ñà        | 10100/50000 [7:21:27<153:34:55, 13.86s/it, loss=1.496, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2019]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 10100: Train PPL=4.48 | Eval PPL=1.18 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2020 | Buffer: 80800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10104/50000 [7:21:31<43:25:32,  3.92s/it, loss=1.500, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2020]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:00:38] Step: 10,105/50k | Loss: 1.500 | PPL: 1.18 | Best: 1.14\n","           Mem: 2021 | Buf: 80,832 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10114/50000 [7:22:29<32:34:22,  2.94s/it, loss=1.498, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2022]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:01:38] Step: 10,115/50k | Loss: 1.498 | PPL: 1.18 | Best: 1.14\n","           Mem: 2023 | Buf: 80,912 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10124/50000 [7:23:26<32:06:51,  2.90s/it, loss=1.473, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2024]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:02:38] Step: 10,125/50k | Loss: 1.473 | PPL: 1.18 | Best: 1.14\n","           Mem: 2025 | Buf: 80,992 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10134/50000 [7:24:24<32:20:09,  2.92s/it, loss=1.479, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2026]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:03:38] Step: 10,135/50k | Loss: 1.479 | PPL: 1.18 | Best: 1.14\n","           Mem: 2027 | Buf: 81,072 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10144/50000 [7:25:22<32:18:02,  2.92s/it, loss=1.485, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2028]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:04:38] Step: 10,145/50k | Loss: 1.485 | PPL: 1.18 | Best: 1.14\n","           Mem: 2029 | Buf: 81,152 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10154/50000 [7:26:20<32:19:57,  2.92s/it, loss=1.497, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2030]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:05:38] Step: 10,155/50k | Loss: 1.497 | PPL: 1.18 | Best: 1.14\n","           Mem: 2031 | Buf: 81,232 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10164/50000 [7:27:18<32:38:11,  2.95s/it, loss=1.517, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2032]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:06:38] Step: 10,165/50k | Loss: 1.517 | PPL: 1.18 | Best: 1.14\n","           Mem: 2033 | Buf: 81,312 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10174/50000 [7:28:16<32:33:11,  2.94s/it, loss=1.483, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2034]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:07:38] Step: 10,175/50k | Loss: 1.483 | PPL: 1.18 | Best: 1.14\n","           Mem: 2035 | Buf: 81,392 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10184/50000 [7:29:15<32:27:52,  2.94s/it, loss=1.477, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2036]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:08:38] Step: 10,185/50k | Loss: 1.477 | PPL: 1.18 | Best: 1.14\n","           Mem: 2037 | Buf: 81,472 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10195/50000 [7:30:38<110:04:12,  9.95s/it, loss=1.467, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2038]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 10200\n","\n","[12:09:38] Step: 10,195/50k | Loss: 1.467 | PPL: 1.18 | Best: 1.14\n","           Mem: 2039 | Buf: 81,552 | Phase: wake | ETA: 10.1h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10199/50000 [7:30:41<32:27:01,  2.94s/it, loss=1.496, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2039]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 1.12\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  20%|‚ñà‚ñà        | 10200/50000 [7:31:21<157:19:23, 14.23s/it, loss=1.496, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2039]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 10200: Train PPL=4.43 | Eval PPL=1.18 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2040 | Buffer: 81600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10204/50000 [7:31:25<44:01:44,  3.98s/it, loss=1.496, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2040]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:10:38] Step: 10,205/50k | Loss: 1.496 | PPL: 1.18 | Best: 1.14\n","           Mem: 2041 | Buf: 81,632 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10214/50000 [7:32:24<32:52:16,  2.97s/it, loss=1.486, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2042]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:11:38] Step: 10,215/50k | Loss: 1.486 | PPL: 1.18 | Best: 1.14\n","           Mem: 2043 | Buf: 81,712 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10224/50000 [7:33:22<32:32:25,  2.95s/it, loss=1.462, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2044]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:12:38] Step: 10,225/50k | Loss: 1.462 | PPL: 1.18 | Best: 1.14\n","           Mem: 2045 | Buf: 81,792 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10234/50000 [7:34:20<32:04:12,  2.90s/it, loss=1.498, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2046]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:13:38] Step: 10,235/50k | Loss: 1.498 | PPL: 1.18 | Best: 1.14\n","           Mem: 2047 | Buf: 81,872 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  20%|‚ñà‚ñà        | 10244/50000 [7:35:19<32:48:47,  2.97s/it, loss=1.503, lr=2.80e-04, it/s=0.38, mem=3.7GB, mem_count=2048]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:14:38] Step: 10,245/50k | Loss: 1.503 | PPL: 1.18 | Best: 1.14\n","           Mem: 2049 | Buf: 81,952 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10254/50000 [7:36:17<32:15:51,  2.92s/it, loss=1.505, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2050]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:15:38] Step: 10,255/50k | Loss: 1.505 | PPL: 1.18 | Best: 1.14\n","           Mem: 2051 | Buf: 82,032 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10264/50000 [7:37:17<33:00:04,  2.99s/it, loss=1.477, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2052]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:16:38] Step: 10,265/50k | Loss: 1.477 | PPL: 1.18 | Best: 1.14\n","           Mem: 2053 | Buf: 82,112 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10274/50000 [7:38:16<32:50:31,  2.98s/it, loss=1.489, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2054]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:17:38] Step: 10,275/50k | Loss: 1.489 | PPL: 1.18 | Best: 1.14\n","           Mem: 2055 | Buf: 82,192 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10284/50000 [7:39:16<32:56:41,  2.99s/it, loss=1.476, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2056]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:18:38] Step: 10,285/50k | Loss: 1.476 | PPL: 1.18 | Best: 1.14\n","           Mem: 2057 | Buf: 82,272 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10294/50000 [7:40:15<32:56:25,  2.99s/it, loss=1.465, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2058]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:19:38] Step: 10,295/50k | Loss: 1.465 | PPL: 1.18 | Best: 1.14\n","           Mem: 2059 | Buf: 82,352 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  21%|‚ñà‚ñà        | 10295/50000 [7:40:41<110:00:30,  9.97s/it, loss=1.465, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2058]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 10300\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10299/50000 [7:40:44<32:26:44,  2.94s/it, loss=1.456, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2059]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.78\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  21%|‚ñà‚ñà        | 10300/50000 [7:41:24<156:28:39, 14.19s/it, loss=1.456, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2059]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 10300: Train PPL=4.41 | Eval PPL=1.17 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2060 | Buffer: 82400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10304/50000 [7:41:28<43:36:24,  3.95s/it, loss=1.471, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2060]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:20:38] Step: 10,305/50k | Loss: 1.471 | PPL: 1.17 | Best: 1.14\n","           Mem: 2061 | Buf: 82,432 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10314/50000 [7:42:28<33:24:27,  3.03s/it, loss=1.466, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2062]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:21:38] Step: 10,315/50k | Loss: 1.466 | PPL: 1.17 | Best: 1.14\n","           Mem: 2063 | Buf: 82,512 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10324/50000 [7:43:28<33:35:11,  3.05s/it, loss=1.469, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2064]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:22:38] Step: 10,325/50k | Loss: 1.469 | PPL: 1.17 | Best: 1.14\n","           Mem: 2065 | Buf: 82,592 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10334/50000 [7:44:28<32:52:26,  2.98s/it, loss=1.498, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2066]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:23:38] Step: 10,335/50k | Loss: 1.498 | PPL: 1.17 | Best: 1.14\n","           Mem: 2067 | Buf: 82,672 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10344/50000 [7:45:29<33:17:37,  3.02s/it, loss=1.494, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2068]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:24:38] Step: 10,345/50k | Loss: 1.494 | PPL: 1.17 | Best: 1.14\n","           Mem: 2069 | Buf: 82,752 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10354/50000 [7:46:28<32:34:07,  2.96s/it, loss=1.455, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2070]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:25:38] Step: 10,355/50k | Loss: 1.455 | PPL: 1.17 | Best: 1.14\n","           Mem: 2071 | Buf: 82,832 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10364/50000 [7:47:28<33:16:02,  3.02s/it, loss=1.496, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2072]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:26:38] Step: 10,365/50k | Loss: 1.496 | PPL: 1.17 | Best: 1.14\n","           Mem: 2073 | Buf: 82,912 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10374/50000 [7:48:28<32:46:10,  2.98s/it, loss=1.471, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2074]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:27:38] Step: 10,375/50k | Loss: 1.471 | PPL: 1.17 | Best: 1.14\n","           Mem: 2075 | Buf: 82,992 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10384/50000 [7:49:27<32:47:06,  2.98s/it, loss=1.455, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2076]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:28:38] Step: 10,385/50k | Loss: 1.455 | PPL: 1.17 | Best: 1.14\n","           Mem: 2077 | Buf: 83,072 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10394/50000 [7:50:28<33:21:16,  3.03s/it, loss=1.476, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2078]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:29:38] Step: 10,395/50k | Loss: 1.476 | PPL: 1.17 | Best: 1.14\n","           Mem: 2079 | Buf: 83,152 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  21%|‚ñà‚ñà        | 10395/50000 [7:50:55<114:19:17, 10.39s/it, loss=1.476, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2078]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 10400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10399/50000 [7:50:59<33:22:27,  3.03s/it, loss=1.485, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2079]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.79\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  21%|‚ñà‚ñà        | 10400/50000 [7:51:35<147:03:22, 13.37s/it, loss=1.485, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2079]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 10400: Train PPL=4.37 | Eval PPL=1.17 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2080 | Buffer: 83200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10403/50000 [7:51:37<55:39:28,  5.06s/it, loss=1.463, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2080]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:30:38] Step: 10,404/50k | Loss: 1.463 | PPL: 1.17 | Best: 1.14\n","           Mem: 2080 | Buf: 83,216 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10412/50000 [7:52:38<60:29:54,  5.50s/it, loss=1.472, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2082]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:31:38] Step: 10,412/50k | Loss: 1.472 | PPL: 1.17 | Best: 1.14\n","           Mem: 2082 | Buf: 83,296 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10423/50000 [7:53:38<43:34:26,  3.96s/it, loss=1.521, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2084]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:32:38] Step: 10,423/50k | Loss: 1.459 | PPL: 1.17 | Best: 1.14\n","           Mem: 2084 | Buf: 83,376 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10431/50000 [7:54:38<83:15:43,  7.58s/it, loss=1.505, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2086] "]},{"output_type":"stream","name":"stdout","text":["\n","[12:33:38] Step: 10,431/50k | Loss: 1.451 | PPL: 1.17 | Best: 1.14\n","           Mem: 2086 | Buf: 83,440 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10440/50000 [7:55:38<114:43:05, 10.44s/it, loss=1.491, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2087]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:34:38] Step: 10,440/50k | Loss: 1.491 | PPL: 1.17 | Best: 1.14\n","           Mem: 2088 | Buf: 83,520 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10450/50000 [7:56:38<112:53:39, 10.28s/it, loss=1.467, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2089]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:35:38] Step: 10,450/50k | Loss: 1.467 | PPL: 1.17 | Best: 1.14\n","           Mem: 2090 | Buf: 83,600 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10459/50000 [7:57:12<33:04:24,  3.01s/it, loss=1.462, lr=2.80e-04, it/s=0.37, mem=3.7GB, mem_count=2091]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:36:38] Step: 10,460/50k | Loss: 1.462 | PPL: 1.17 | Best: 1.14\n","           Mem: 2092 | Buf: 83,680 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10469/50000 [7:58:13<33:47:07,  3.08s/it, loss=1.463, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2093]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:37:38] Step: 10,470/50k | Loss: 1.463 | PPL: 1.17 | Best: 1.14\n","           Mem: 2094 | Buf: 83,760 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10479/50000 [7:59:14<33:33:54,  3.06s/it, loss=1.442, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2095]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:38:38] Step: 10,480/50k | Loss: 1.442 | PPL: 1.17 | Best: 1.14\n","           Mem: 2096 | Buf: 83,840 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10489/50000 [8:00:15<33:30:27,  3.05s/it, loss=1.463, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2097]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:39:38] Step: 10,490/50k | Loss: 1.463 | PPL: 1.17 | Best: 1.14\n","           Mem: 2098 | Buf: 83,920 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10495/50000 [8:01:13<115:19:27, 10.51s/it, loss=1.488, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2098]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 10500\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10499/50000 [8:01:16<33:36:08,  3.06s/it, loss=1.459, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2099]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.68\n","\n","[12:40:38] Step: 10,500/50k | Loss: 1.459 | PPL: 1.17 | Best: 1.14\n","           Mem: 2100 | Buf: 84,000 | Phase: wake | ETA: 10.0h\n","\n","üìä Step 10500: Train PPL=4.37 | Eval PPL=1.16 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2100 | Buffer: 84000\n","‚úÖ Checkpoint saved: step_10500\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10509/50000 [8:02:38<36:55:07,  3.37s/it, loss=1.502, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2101]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:41:38] Step: 10,509/50k | Loss: 1.502 | PPL: 1.16 | Best: 1.14\n","           Mem: 2101 | Buf: 84,064 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10516/50000 [8:03:38<84:54:33,  7.74s/it, loss=1.490, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2103] "]},{"output_type":"stream","name":"stdout","text":["\n","[12:42:38] Step: 10,516/50k | Loss: 1.468 | PPL: 1.16 | Best: 1.14\n","           Mem: 2103 | Buf: 84,112 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10524/50000 [8:04:11<33:29:49,  3.05s/it, loss=1.483, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2104]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:43:38] Step: 10,525/50k | Loss: 1.483 | PPL: 1.16 | Best: 1.14\n","           Mem: 2105 | Buf: 84,192 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10534/50000 [8:05:12<33:20:57,  3.04s/it, loss=1.458, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2106]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:44:38] Step: 10,535/50k | Loss: 1.458 | PPL: 1.16 | Best: 1.14\n","           Mem: 2107 | Buf: 84,272 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10544/50000 [8:06:14<33:37:02,  3.07s/it, loss=1.485, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2108]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:45:38] Step: 10,545/50k | Loss: 1.485 | PPL: 1.16 | Best: 1.14\n","           Mem: 2109 | Buf: 84,352 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10554/50000 [8:07:15<33:27:40,  3.05s/it, loss=1.459, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2110]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:46:38] Step: 10,555/50k | Loss: 1.459 | PPL: 1.16 | Best: 1.14\n","           Mem: 2111 | Buf: 84,432 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10564/50000 [8:08:17<34:04:20,  3.11s/it, loss=1.454, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2112]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:47:38] Step: 10,565/50k | Loss: 1.454 | PPL: 1.16 | Best: 1.14\n","           Mem: 2113 | Buf: 84,512 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10574/50000 [8:09:20<34:17:42,  3.13s/it, loss=1.460, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2114]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:48:38] Step: 10,575/50k | Loss: 1.460 | PPL: 1.16 | Best: 1.14\n","           Mem: 2115 | Buf: 84,592 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10584/50000 [8:10:22<33:36:14,  3.07s/it, loss=1.465, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2116]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:49:38] Step: 10,585/50k | Loss: 1.465 | PPL: 1.16 | Best: 1.14\n","           Mem: 2117 | Buf: 84,672 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10594/50000 [8:11:25<34:12:47,  3.13s/it, loss=1.482, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2118]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:50:38] Step: 10,595/50k | Loss: 1.482 | PPL: 1.16 | Best: 1.14\n","           Mem: 2119 | Buf: 84,752 | Phase: wake | ETA: 10.0h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  21%|‚ñà‚ñà        | 10595/50000 [8:11:52<115:42:52, 10.57s/it, loss=1.482, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2118]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 10600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10599/50000 [8:11:55<33:44:22,  3.08s/it, loss=1.483, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2119]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.86\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  21%|‚ñà‚ñà        | 10600/50000 [8:12:33<148:00:04, 13.52s/it, loss=1.483, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2119]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 10600: Train PPL=4.35 | Eval PPL=1.16 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2120 | Buffer: 84800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10604/50000 [8:12:37<42:03:48,  3.84s/it, loss=1.475, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2120]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:51:38] Step: 10,605/50k | Loss: 1.475 | PPL: 1.16 | Best: 1.14\n","           Mem: 2121 | Buf: 84,832 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10614/50000 [8:13:38<33:59:44,  3.11s/it, loss=1.469, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2122]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:52:38] Step: 10,614/50k | Loss: 1.463 | PPL: 1.16 | Best: 1.14\n","           Mem: 2122 | Buf: 84,896 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà        | 10619/50000 [8:14:10<33:58:45,  3.11s/it, loss=1.446, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2123]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:53:38] Step: 10,620/50k | Loss: 1.446 | PPL: 1.16 | Best: 1.14\n","           Mem: 2124 | Buf: 84,960 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10629/50000 [8:15:13<34:19:52,  3.14s/it, loss=1.467, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2125]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:54:38] Step: 10,630/50k | Loss: 1.467 | PPL: 1.16 | Best: 1.14\n","           Mem: 2126 | Buf: 85,040 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10639/50000 [8:16:16<34:20:53,  3.14s/it, loss=1.452, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2127]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:55:38] Step: 10,640/50k | Loss: 1.452 | PPL: 1.16 | Best: 1.14\n","           Mem: 2128 | Buf: 85,120 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10649/50000 [8:17:19<34:12:10,  3.13s/it, loss=1.457, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2129]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:56:38] Step: 10,650/50k | Loss: 1.457 | PPL: 1.16 | Best: 1.14\n","           Mem: 2130 | Buf: 85,200 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10659/50000 [8:18:22<33:57:33,  3.11s/it, loss=1.449, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2131]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:57:38] Step: 10,660/50k | Loss: 1.449 | PPL: 1.16 | Best: 1.14\n","           Mem: 2132 | Buf: 85,280 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10669/50000 [8:19:25<33:52:05,  3.10s/it, loss=1.602, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2133]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:58:38] Step: 10,670/50k | Loss: 1.602 | PPL: 1.16 | Best: 1.14\n","           Mem: 2134 | Buf: 85,360 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10679/50000 [8:20:28<34:34:26,  3.17s/it, loss=1.484, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2135]"]},{"output_type":"stream","name":"stdout","text":["\n","[12:59:38] Step: 10,680/50k | Loss: 1.484 | PPL: 1.16 | Best: 1.14\n","           Mem: 2136 | Buf: 85,440 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10689/50000 [8:21:32<34:42:07,  3.18s/it, loss=1.454, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2137]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:00:38] Step: 10,690/50k | Loss: 1.454 | PPL: 1.16 | Best: 1.14\n","           Mem: 2138 | Buf: 85,520 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10695/50000 [8:22:32<118:00:44, 10.81s/it, loss=1.484, lr=2.80e-04, it/s=0.36, mem=3.7GB, mem_count=2138]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 10700\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10699/50000 [8:22:35<34:15:41,  3.14s/it, loss=1.552, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2139]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 1.34\n","\n","[13:01:38] Step: 10,700/50k | Loss: 1.552 | PPL: 1.16 | Best: 1.14\n","           Mem: 2140 | Buf: 85,600 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  21%|‚ñà‚ñà‚ñè       | 10700/50000 [8:23:14<151:55:10, 13.92s/it, loss=1.552, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2139]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 10700: Train PPL=4.34 | Eval PPL=1.16 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2140 | Buffer: 85600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10704/50000 [8:23:17<42:33:45,  3.90s/it, loss=1.484, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2140]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:02:38] Step: 10,705/50k | Loss: 1.484 | PPL: 1.16 | Best: 1.14\n","           Mem: 2141 | Buf: 85,632 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10714/50000 [8:24:22<35:04:55,  3.21s/it, loss=1.466, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2142]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:03:38] Step: 10,715/50k | Loss: 1.466 | PPL: 1.16 | Best: 1.14\n","           Mem: 2143 | Buf: 85,712 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10724/50000 [8:25:26<34:59:02,  3.21s/it, loss=1.447, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2144]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:04:38] Step: 10,725/50k | Loss: 1.447 | PPL: 1.16 | Best: 1.14\n","           Mem: 2145 | Buf: 85,792 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10734/50000 [8:26:32<35:33:17,  3.26s/it, loss=1.451, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2146]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:05:38] Step: 10,735/50k | Loss: 1.451 | PPL: 1.16 | Best: 1.14\n","           Mem: 2147 | Buf: 85,872 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  21%|‚ñà‚ñà‚ñè       | 10744/50000 [8:27:37<34:59:13,  3.21s/it, loss=1.477, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2148]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:06:38] Step: 10,745/50k | Loss: 1.477 | PPL: 1.16 | Best: 1.14\n","           Mem: 2149 | Buf: 85,952 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10751/50000 [8:28:38<86:13:30,  7.91s/it, loss=1.482, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2150] "]},{"output_type":"stream","name":"stdout","text":["\n","[13:07:38] Step: 10,751/50k | Loss: 1.461 | PPL: 1.16 | Best: 1.14\n","           Mem: 2150 | Buf: 86,000 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10759/50000 [8:29:13<34:50:12,  3.20s/it, loss=1.466, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2151]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:08:38] Step: 10,760/50k | Loss: 1.466 | PPL: 1.16 | Best: 1.14\n","           Mem: 2152 | Buf: 86,080 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10769/50000 [8:30:18<35:04:23,  3.22s/it, loss=1.458, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2153]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:09:38] Step: 10,770/50k | Loss: 1.458 | PPL: 1.16 | Best: 1.14\n","           Mem: 2154 | Buf: 86,160 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10779/50000 [8:31:22<34:30:30,  3.17s/it, loss=1.478, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2155]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:10:38] Step: 10,780/50k | Loss: 1.478 | PPL: 1.16 | Best: 1.14\n","           Mem: 2156 | Buf: 86,240 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10789/50000 [8:32:27<34:39:33,  3.18s/it, loss=1.474, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2157]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:11:38] Step: 10,790/50k | Loss: 1.474 | PPL: 1.16 | Best: 1.14\n","           Mem: 2158 | Buf: 86,320 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10795/50000 [8:33:28<120:52:09, 11.10s/it, loss=1.463, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2158]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 10800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10799/50000 [8:33:32<34:53:41,  3.20s/it, loss=1.444, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2159]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.73\n","\n","[13:12:38] Step: 10,800/50k | Loss: 1.444 | PPL: 1.16 | Best: 1.14\n","           Mem: 2160 | Buf: 86,400 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  22%|‚ñà‚ñà‚ñè       | 10800/50000 [8:34:14<165:24:48, 15.19s/it, loss=1.444, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2159]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 10800: Train PPL=4.33 | Eval PPL=1.16 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2160 | Buffer: 86400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10804/50000 [8:34:18<45:45:07,  4.20s/it, loss=1.474, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2160]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:13:38] Step: 10,805/50k | Loss: 1.474 | PPL: 1.16 | Best: 1.14\n","           Mem: 2161 | Buf: 86,432 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10814/50000 [8:35:23<35:34:59,  3.27s/it, loss=1.452, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2162]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:14:38] Step: 10,815/50k | Loss: 1.452 | PPL: 1.16 | Best: 1.14\n","           Mem: 2163 | Buf: 86,512 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10824/50000 [8:36:26<34:27:01,  3.17s/it, loss=1.447, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2164]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:15:38] Step: 10,825/50k | Loss: 1.447 | PPL: 1.16 | Best: 1.14\n","           Mem: 2165 | Buf: 86,592 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10834/50000 [8:37:32<35:21:54,  3.25s/it, loss=1.468, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2166]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:16:38] Step: 10,835/50k | Loss: 1.468 | PPL: 1.16 | Best: 1.14\n","           Mem: 2167 | Buf: 86,672 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10844/50000 [8:38:37<35:32:43,  3.27s/it, loss=1.485, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2168]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:17:38] Step: 10,845/50k | Loss: 1.485 | PPL: 1.16 | Best: 1.14\n","           Mem: 2169 | Buf: 86,752 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10849/50000 [8:39:09<34:52:39,  3.21s/it, loss=1.527, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2169]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:18:38] Step: 10,850/50k | Loss: 1.527 | PPL: 1.16 | Best: 1.14\n","           Mem: 2170 | Buf: 86,800 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10859/50000 [8:40:15<35:14:00,  3.24s/it, loss=1.463, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2171]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:19:38] Step: 10,860/50k | Loss: 1.463 | PPL: 1.16 | Best: 1.14\n","           Mem: 2172 | Buf: 86,880 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10869/50000 [8:41:20<34:35:51,  3.18s/it, loss=1.457, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2173]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:20:38] Step: 10,870/50k | Loss: 1.457 | PPL: 1.16 | Best: 1.14\n","           Mem: 2174 | Buf: 86,960 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10879/50000 [8:42:24<35:02:18,  3.22s/it, loss=1.437, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2175]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:21:38] Step: 10,880/50k | Loss: 1.437 | PPL: 1.16 | Best: 1.14\n","           Mem: 2176 | Buf: 87,040 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10889/50000 [8:43:31<35:59:02,  3.31s/it, loss=1.462, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2177]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:22:38] Step: 10,890/50k | Loss: 1.462 | PPL: 1.16 | Best: 1.14\n","           Mem: 2178 | Buf: 87,120 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10895/50000 [8:44:34<123:56:22, 11.41s/it, loss=1.471, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2178]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 10900\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10899/50000 [8:44:38<35:51:52,  3.30s/it, loss=1.459, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2179]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:23:38] Step: 10,900/50k | Loss: 1.460 | PPL: 1.16 | Best: 1.14\n","           Mem: 2179 | Buf: 87,184 | Phase: wake | ETA: 9.9h\n","   Grad norm: 0.78\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  22%|‚ñà‚ñà‚ñè       | 10900/50000 [8:45:20<164:23:15, 15.14s/it, loss=1.459, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2179]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 10900: Train PPL=4.31 | Eval PPL=1.16 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2180 | Buffer: 87200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10904/50000 [8:45:24<46:15:12,  4.26s/it, loss=1.447, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2180]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:24:38] Step: 10,905/50k | Loss: 1.447 | PPL: 1.16 | Best: 1.14\n","           Mem: 2181 | Buf: 87,232 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10914/50000 [8:46:29<35:11:21,  3.24s/it, loss=1.453, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2182]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:25:38] Step: 10,915/50k | Loss: 1.453 | PPL: 1.16 | Best: 1.14\n","           Mem: 2183 | Buf: 87,312 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10924/50000 [8:47:34<34:56:18,  3.22s/it, loss=1.458, lr=2.80e-04, it/s=0.35, mem=3.7GB, mem_count=2184]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:26:38] Step: 10,925/50k | Loss: 1.458 | PPL: 1.16 | Best: 1.14\n","           Mem: 2185 | Buf: 87,392 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10931/50000 [8:48:37<88:53:10,  8.19s/it, loss=1.466, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2186] "]},{"output_type":"stream","name":"stdout","text":["\n","[13:27:38] Step: 10,932/50k | Loss: 1.466 | PPL: 1.16 | Best: 1.14\n","           Mem: 2186 | Buf: 87,440 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10939/50000 [8:49:13<34:53:53,  3.22s/it, loss=1.463, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2187]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:28:38] Step: 10,940/50k | Loss: 1.463 | PPL: 1.16 | Best: 1.14\n","           Mem: 2188 | Buf: 87,520 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10949/50000 [8:50:19<35:37:02,  3.28s/it, loss=1.460, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2189]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:29:38] Step: 10,950/50k | Loss: 1.460 | PPL: 1.16 | Best: 1.14\n","           Mem: 2190 | Buf: 87,600 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10959/50000 [8:51:26<35:37:59,  3.29s/it, loss=1.454, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2191]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:30:38] Step: 10,960/50k | Loss: 1.454 | PPL: 1.16 | Best: 1.14\n","           Mem: 2192 | Buf: 87,680 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10969/50000 [8:52:32<35:19:27,  3.26s/it, loss=1.477, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2193]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:31:38] Step: 10,970/50k | Loss: 1.477 | PPL: 1.16 | Best: 1.14\n","           Mem: 2194 | Buf: 87,760 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10979/50000 [8:53:38<35:00:54,  3.23s/it, loss=1.461, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2195]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:32:38] Step: 10,980/50k | Loss: 1.461 | PPL: 1.16 | Best: 1.14\n","           Mem: 2196 | Buf: 87,840 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10984/50000 [8:54:11<35:49:58,  3.31s/it, loss=1.459, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2196]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:33:38] Step: 10,985/50k | Loss: 1.459 | PPL: 1.16 | Best: 1.14\n","           Mem: 2197 | Buf: 87,872 | Phase: wake | ETA: 9.9h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10994/50000 [8:55:17<35:10:38,  3.25s/it, loss=1.441, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2198]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:34:38] Step: 10,995/50k | Loss: 1.441 | PPL: 1.16 | Best: 1.14\n","           Mem: 2199 | Buf: 87,952 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  22%|‚ñà‚ñà‚ñè       | 10995/50000 [8:55:47<124:25:24, 11.48s/it, loss=1.441, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2198]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 11000\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 10999/50000 [8:55:51<35:45:04,  3.30s/it, loss=1.479, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2199]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.92\n","\n","üìä Step 11000: Train PPL=4.32 | Eval PPL=1.16 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2200 | Buffer: 88000\n","‚úÖ Checkpoint saved: step_11000\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11002/50000 [8:56:38<90:14:41,  8.33s/it, loss=1.516, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2200] "]},{"output_type":"stream","name":"stdout","text":["\n","[13:35:38] Step: 11,002/50k | Loss: 1.516 | PPL: 1.16 | Best: 1.14\n","           Mem: 2200 | Buf: 88,016 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11009/50000 [8:57:14<38:13:11,  3.53s/it, loss=1.458, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2201]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:36:38] Step: 11,010/50k | Loss: 1.458 | PPL: 1.16 | Best: 1.14\n","           Mem: 2202 | Buf: 88,080 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11019/50000 [8:58:21<36:07:32,  3.34s/it, loss=1.467, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2203]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:37:38] Step: 11,020/50k | Loss: 1.467 | PPL: 1.16 | Best: 1.14\n","           Mem: 2204 | Buf: 88,160 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11029/50000 [8:59:28<35:42:27,  3.30s/it, loss=1.465, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2205]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:38:38] Step: 11,030/50k | Loss: 1.465 | PPL: 1.16 | Best: 1.14\n","           Mem: 2206 | Buf: 88,240 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11039/50000 [9:00:36<36:06:46,  3.34s/it, loss=1.463, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2207]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:39:38] Step: 11,040/50k | Loss: 1.463 | PPL: 1.16 | Best: 1.14\n","           Mem: 2208 | Buf: 88,320 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11044/50000 [9:01:10<36:08:32,  3.34s/it, loss=1.448, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2208]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:40:38] Step: 11,045/50k | Loss: 1.448 | PPL: 1.16 | Best: 1.14\n","           Mem: 2209 | Buf: 88,352 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11054/50000 [9:02:17<36:09:27,  3.34s/it, loss=1.454, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2210]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:41:38] Step: 11,055/50k | Loss: 1.454 | PPL: 1.16 | Best: 1.14\n","           Mem: 2211 | Buf: 88,432 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11064/50000 [9:03:25<35:39:51,  3.30s/it, loss=1.450, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2212]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:42:38] Step: 11,065/50k | Loss: 1.450 | PPL: 1.16 | Best: 1.14\n","           Mem: 2213 | Buf: 88,512 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11074/50000 [9:04:31<35:27:27,  3.28s/it, loss=1.461, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2214]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:43:38] Step: 11,075/50k | Loss: 1.461 | PPL: 1.16 | Best: 1.14\n","           Mem: 2215 | Buf: 88,592 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11084/50000 [9:05:38<36:10:51,  3.35s/it, loss=1.465, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2216]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:44:38] Step: 11,084/50k | Loss: 1.465 | PPL: 1.16 | Best: 1.14\n","           Mem: 2216 | Buf: 88,672 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11089/50000 [9:06:12<36:14:04,  3.35s/it, loss=1.443, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2217]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:45:38] Step: 11,090/50k | Loss: 1.443 | PPL: 1.16 | Best: 1.14\n","           Mem: 2218 | Buf: 88,720 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11095/50000 [9:07:16<124:28:19, 11.52s/it, loss=1.465, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2218]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 11100\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11099/50000 [9:07:20<35:43:42,  3.31s/it, loss=1.453, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2219]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.74\n","\n","[13:46:38] Step: 11,100/50k | Loss: 1.453 | PPL: 1.16 | Best: 1.14\n","           Mem: 2220 | Buf: 88,800 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  22%|‚ñà‚ñà‚ñè       | 11100/50000 [9:08:00<157:53:27, 14.61s/it, loss=1.453, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2219]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 11100: Train PPL=4.29 | Eval PPL=1.15 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2220 | Buffer: 88800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11109/50000 [9:08:38<37:43:33,  3.49s/it, loss=1.457, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2221]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:47:38] Step: 11,109/50k | Loss: 1.457 | PPL: 1.15 | Best: 1.14\n","           Mem: 2221 | Buf: 88,864 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11114/50000 [9:09:13<36:34:06,  3.39s/it, loss=1.460, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2222]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:48:38] Step: 11,115/50k | Loss: 1.460 | PPL: 1.15 | Best: 1.14\n","           Mem: 2223 | Buf: 88,912 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11124/50000 [9:10:21<36:24:26,  3.37s/it, loss=1.446, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2224]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:49:38] Step: 11,125/50k | Loss: 1.446 | PPL: 1.15 | Best: 1.14\n","           Mem: 2225 | Buf: 88,992 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11134/50000 [9:11:29<35:49:55,  3.32s/it, loss=1.454, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2226]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:50:38] Step: 11,135/50k | Loss: 1.454 | PPL: 1.15 | Best: 1.14\n","           Mem: 2227 | Buf: 89,072 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11144/50000 [9:12:38<36:29:07,  3.38s/it, loss=1.460, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2228]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:51:38] Step: 11,145/50k | Loss: 1.452 | PPL: 1.15 | Best: 1.14\n","           Mem: 2228 | Buf: 89,152 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11149/50000 [9:13:12<36:09:20,  3.35s/it, loss=1.460, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2229]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:52:38] Step: 11,150/50k | Loss: 1.460 | PPL: 1.15 | Best: 1.14\n","           Mem: 2230 | Buf: 89,200 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11159/50000 [9:14:20<36:37:32,  3.39s/it, loss=1.467, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2231]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:53:38] Step: 11,160/50k | Loss: 1.467 | PPL: 1.15 | Best: 1.14\n","           Mem: 2232 | Buf: 89,280 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11169/50000 [9:15:29<36:09:09,  3.35s/it, loss=1.473, lr=2.80e-04, it/s=0.34, mem=3.7GB, mem_count=2233]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:54:38] Step: 11,170/50k | Loss: 1.473 | PPL: 1.15 | Best: 1.14\n","           Mem: 2234 | Buf: 89,360 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11179/50000 [9:16:36<35:56:08,  3.33s/it, loss=1.454, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2235]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:55:38] Step: 11,180/50k | Loss: 1.454 | PPL: 1.15 | Best: 1.14\n","           Mem: 2236 | Buf: 89,440 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11184/50000 [9:17:11<36:31:21,  3.39s/it, loss=1.438, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2236]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:56:38] Step: 11,185/50k | Loss: 1.438 | PPL: 1.15 | Best: 1.14\n","           Mem: 2237 | Buf: 89,472 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11194/50000 [9:18:19<36:08:17,  3.35s/it, loss=1.449, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2238]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:57:38] Step: 11,195/50k | Loss: 1.449 | PPL: 1.15 | Best: 1.14\n","           Mem: 2239 | Buf: 89,552 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  22%|‚ñà‚ñà‚ñè       | 11195/50000 [9:18:50<128:38:04, 11.93s/it, loss=1.449, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2238]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 11200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11199/50000 [9:18:54<36:41:48,  3.40s/it, loss=1.489, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2239]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.97\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  22%|‚ñà‚ñà‚ñè       | 11200/50000 [9:19:35<159:31:37, 14.80s/it, loss=1.489, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2239]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 11200: Train PPL=4.30 | Eval PPL=1.15 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2240 | Buffer: 89600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11204/50000 [9:19:38<44:13:29,  4.10s/it, loss=1.516, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2240]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:58:38] Step: 11,205/50k | Loss: 1.516 | PPL: 1.15 | Best: 1.14\n","           Mem: 2240 | Buf: 89,632 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11209/50000 [9:20:13<38:10:42,  3.54s/it, loss=1.456, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2241]"]},{"output_type":"stream","name":"stdout","text":["\n","[13:59:38] Step: 11,210/50k | Loss: 1.456 | PPL: 1.15 | Best: 1.14\n","           Mem: 2242 | Buf: 89,680 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11219/50000 [9:21:23<36:57:26,  3.43s/it, loss=1.453, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2243]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:00:38] Step: 11,220/50k | Loss: 1.453 | PPL: 1.15 | Best: 1.14\n","           Mem: 2244 | Buf: 89,760 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11229/50000 [9:22:33<37:00:07,  3.44s/it, loss=1.441, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2245]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:01:38] Step: 11,230/50k | Loss: 1.441 | PPL: 1.15 | Best: 1.14\n","           Mem: 2246 | Buf: 89,840 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11234/50000 [9:23:08<36:58:19,  3.43s/it, loss=1.461, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2246]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:02:38] Step: 11,235/50k | Loss: 1.461 | PPL: 1.15 | Best: 1.14\n","           Mem: 2247 | Buf: 89,872 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  22%|‚ñà‚ñà‚ñè       | 11244/50000 [9:24:18<37:08:13,  3.45s/it, loss=1.451, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2248]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:03:38] Step: 11,245/50k | Loss: 1.451 | PPL: 1.15 | Best: 1.14\n","           Mem: 2249 | Buf: 89,952 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11254/50000 [9:25:27<36:58:22,  3.44s/it, loss=1.475, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2250]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:04:38] Step: 11,255/50k | Loss: 1.475 | PPL: 1.15 | Best: 1.14\n","           Mem: 2251 | Buf: 90,032 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11264/50000 [9:26:37<36:57:19,  3.43s/it, loss=1.439, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2252]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:05:38] Step: 11,265/50k | Loss: 1.439 | PPL: 1.15 | Best: 1.14\n","           Mem: 2253 | Buf: 90,112 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11269/50000 [9:27:12<36:51:14,  3.43s/it, loss=1.440, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2253]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:06:38] Step: 11,270/50k | Loss: 1.440 | PPL: 1.15 | Best: 1.14\n","           Mem: 2254 | Buf: 90,160 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11279/50000 [9:28:22<36:29:03,  3.39s/it, loss=1.456, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2255]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:07:38] Step: 11,280/50k | Loss: 1.456 | PPL: 1.15 | Best: 1.14\n","           Mem: 2256 | Buf: 90,240 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11289/50000 [9:29:32<37:03:51,  3.45s/it, loss=1.451, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2257]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:08:38] Step: 11,290/50k | Loss: 1.451 | PPL: 1.15 | Best: 1.14\n","           Mem: 2258 | Buf: 90,320 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11295/50000 [9:30:37<127:15:24, 11.84s/it, loss=1.447, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2258]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 11300\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11296/50000 [9:30:38<91:21:05,  8.50s/it, loss=1.477, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2259] "]},{"output_type":"stream","name":"stdout","text":["\n","[14:09:38] Step: 11,296/50k | Loss: 1.447 | PPL: 1.15 | Best: 1.14\n","           Mem: 2259 | Buf: 90,352 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11299/50000 [9:30:41<36:22:40,  3.38s/it, loss=1.447, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2259]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.77\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  23%|‚ñà‚ñà‚ñé       | 11300/50000 [9:31:23<162:07:58, 15.08s/it, loss=1.447, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2259]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 11300: Train PPL=4.28 | Eval PPL=1.15 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2260 | Buffer: 90400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11304/50000 [9:31:26<44:58:16,  4.18s/it, loss=1.463, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2260]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:10:38] Step: 11,305/50k | Loss: 1.463 | PPL: 1.15 | Best: 1.14\n","           Mem: 2261 | Buf: 90,432 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11314/50000 [9:32:37<37:18:03,  3.47s/it, loss=1.434, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2262]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:11:38] Step: 11,315/50k | Loss: 1.434 | PPL: 1.15 | Best: 1.14\n","           Mem: 2263 | Buf: 90,512 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11319/50000 [9:33:12<37:20:18,  3.48s/it, loss=1.450, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2263]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:12:38] Step: 11,320/50k | Loss: 1.450 | PPL: 1.15 | Best: 1.14\n","           Mem: 2264 | Buf: 90,560 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11329/50000 [9:34:22<37:08:36,  3.46s/it, loss=1.482, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2265]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:13:38] Step: 11,330/50k | Loss: 1.482 | PPL: 1.15 | Best: 1.14\n","           Mem: 2266 | Buf: 90,640 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11339/50000 [9:35:32<36:41:07,  3.42s/it, loss=1.456, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2267]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:14:38] Step: 11,340/50k | Loss: 1.456 | PPL: 1.15 | Best: 1.14\n","           Mem: 2268 | Buf: 90,720 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11344/50000 [9:36:08<37:15:39,  3.47s/it, loss=1.460, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2268]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:15:38] Step: 11,345/50k | Loss: 1.460 | PPL: 1.15 | Best: 1.14\n","           Mem: 2269 | Buf: 90,752 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11354/50000 [9:37:19<37:21:38,  3.48s/it, loss=1.441, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2270]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:16:38] Step: 11,355/50k | Loss: 1.441 | PPL: 1.15 | Best: 1.14\n","           Mem: 2271 | Buf: 90,832 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11364/50000 [9:38:29<36:42:02,  3.42s/it, loss=1.469, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2272]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:17:38] Step: 11,365/50k | Loss: 1.469 | PPL: 1.15 | Best: 1.14\n","           Mem: 2273 | Buf: 90,912 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11371/50000 [9:39:38<94:47:26,  8.83s/it, loss=1.454, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2274] "]},{"output_type":"stream","name":"stdout","text":["\n","[14:18:38] Step: 11,371/50k | Loss: 1.454 | PPL: 1.15 | Best: 1.14\n","           Mem: 2274 | Buf: 90,960 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11379/50000 [9:40:16<37:04:18,  3.46s/it, loss=1.488, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2275]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:19:38] Step: 11,380/50k | Loss: 1.488 | PPL: 1.15 | Best: 1.14\n","           Mem: 2276 | Buf: 91,040 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11389/50000 [9:41:26<36:59:21,  3.45s/it, loss=1.433, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2277]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:20:38] Step: 11,390/50k | Loss: 1.433 | PPL: 1.15 | Best: 1.14\n","           Mem: 2278 | Buf: 91,120 | Phase: wake | ETA: 9.8h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11395/50000 [9:42:34<131:50:23, 12.29s/it, loss=1.440, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2278]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 11400\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11399/50000 [9:42:38<37:29:38,  3.50s/it, loss=1.439, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2279]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.63\n","\n","[14:21:38] Step: 11,400/50k | Loss: 1.439 | PPL: 1.15 | Best: 1.14\n","           Mem: 2280 | Buf: 91,200 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  23%|‚ñà‚ñà‚ñé       | 11400/50000 [9:43:20<164:46:55, 15.37s/it, loss=1.439, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2279]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 11400: Train PPL=4.27 | Eval PPL=1.15 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2280 | Buffer: 91200\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11404/50000 [9:43:24<45:46:59,  4.27s/it, loss=1.463, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2280]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:22:38] Step: 11,405/50k | Loss: 1.463 | PPL: 1.15 | Best: 1.14\n","           Mem: 2281 | Buf: 91,232 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11414/50000 [9:44:35<37:45:30,  3.52s/it, loss=1.440, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2282]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:23:38] Step: 11,415/50k | Loss: 1.440 | PPL: 1.15 | Best: 1.14\n","           Mem: 2283 | Buf: 91,312 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11419/50000 [9:45:11<37:08:42,  3.47s/it, loss=1.467, lr=2.80e-04, it/s=0.33, mem=3.7GB, mem_count=2283]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:24:38] Step: 11,420/50k | Loss: 1.467 | PPL: 1.15 | Best: 1.14\n","           Mem: 2284 | Buf: 91,360 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11429/50000 [9:46:21<37:04:25,  3.46s/it, loss=1.461, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2285]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:25:38] Step: 11,430/50k | Loss: 1.461 | PPL: 1.15 | Best: 1.14\n","           Mem: 2286 | Buf: 91,440 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11439/50000 [9:47:34<37:41:41,  3.52s/it, loss=1.447, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2287]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:26:38] Step: 11,440/50k | Loss: 1.447 | PPL: 1.15 | Best: 1.14\n","           Mem: 2288 | Buf: 91,520 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11444/50000 [9:48:09<37:28:03,  3.50s/it, loss=1.435, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2288]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:27:38] Step: 11,445/50k | Loss: 1.435 | PPL: 1.15 | Best: 1.14\n","           Mem: 2289 | Buf: 91,552 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11454/50000 [9:49:20<37:13:51,  3.48s/it, loss=1.438, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2290]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:28:38] Step: 11,455/50k | Loss: 1.438 | PPL: 1.15 | Best: 1.14\n","           Mem: 2291 | Buf: 91,632 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11464/50000 [9:50:32<37:54:40,  3.54s/it, loss=1.450, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2292]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:29:38] Step: 11,465/50k | Loss: 1.450 | PPL: 1.15 | Best: 1.14\n","           Mem: 2293 | Buf: 91,712 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11469/50000 [9:51:09<37:58:38,  3.55s/it, loss=1.432, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2293]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:30:38] Step: 11,470/50k | Loss: 1.432 | PPL: 1.15 | Best: 1.14\n","           Mem: 2294 | Buf: 91,760 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11479/50000 [9:52:20<37:19:18,  3.49s/it, loss=1.449, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2295]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:31:38] Step: 11,480/50k | Loss: 1.449 | PPL: 1.15 | Best: 1.14\n","           Mem: 2296 | Buf: 91,840 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11489/50000 [9:53:32<38:05:42,  3.56s/it, loss=1.451, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2297]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:32:38] Step: 11,490/50k | Loss: 1.451 | PPL: 1.15 | Best: 1.14\n","           Mem: 2298 | Buf: 91,920 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11494/50000 [9:54:09<37:58:35,  3.55s/it, loss=1.473, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2298]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:33:38] Step: 11,495/50k | Loss: 1.473 | PPL: 1.15 | Best: 1.14\n","           Mem: 2299 | Buf: 91,952 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  23%|‚ñà‚ñà‚ñé       | 11495/50000 [9:54:42<135:19:38, 12.65s/it, loss=1.473, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2298]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 11500\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11499/50000 [9:54:45<38:16:52,  3.58s/it, loss=1.445, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2299]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.79\n","\n","üìä Step 11500: Train PPL=4.28 | Eval PPL=1.15 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2300 | Buffer: 92000\n","‚úÖ Checkpoint saved: step_11500\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11504/50000 [9:55:38<50:39:46,  4.74s/it, loss=1.468, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2300]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:34:38] Step: 11,505/50k | Loss: 1.438 | PPL: 1.15 | Best: 1.14\n","           Mem: 2300 | Buf: 92,032 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11509/50000 [9:56:14<40:00:03,  3.74s/it, loss=1.464, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2301]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:35:38] Step: 11,510/50k | Loss: 1.464 | PPL: 1.15 | Best: 1.14\n","           Mem: 2302 | Buf: 92,080 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11519/50000 [9:57:27<38:26:38,  3.60s/it, loss=1.484, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2303]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:36:38] Step: 11,520/50k | Loss: 1.484 | PPL: 1.15 | Best: 1.14\n","           Mem: 2304 | Buf: 92,160 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11525/50000 [9:58:38<136:21:28, 12.76s/it, loss=1.450, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2304]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:37:38] Step: 11,526/50k | Loss: 1.450 | PPL: 1.15 | Best: 1.14\n","           Mem: 2305 | Buf: 92,192 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11534/50000 [9:59:17<37:58:41,  3.55s/it, loss=1.449, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2306]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:38:38] Step: 11,535/50k | Loss: 1.449 | PPL: 1.15 | Best: 1.14\n","           Mem: 2307 | Buf: 92,272 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11544/50000 [10:00:31<38:03:57,  3.56s/it, loss=1.435, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2308]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:39:38] Step: 11,545/50k | Loss: 1.435 | PPL: 1.15 | Best: 1.14\n","           Mem: 2309 | Buf: 92,352 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11549/50000 [10:01:07<37:51:38,  3.54s/it, loss=1.468, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2309]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:40:38] Step: 11,550/50k | Loss: 1.468 | PPL: 1.15 | Best: 1.14\n","           Mem: 2310 | Buf: 92,400 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11559/50000 [10:02:19<37:40:15,  3.53s/it, loss=1.441, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2311]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:41:38] Step: 11,560/50k | Loss: 1.441 | PPL: 1.15 | Best: 1.14\n","           Mem: 2312 | Buf: 92,480 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11569/50000 [10:03:32<38:24:26,  3.60s/it, loss=1.454, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2313]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:42:38] Step: 11,570/50k | Loss: 1.454 | PPL: 1.15 | Best: 1.14\n","           Mem: 2314 | Buf: 92,560 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11574/50000 [10:04:10<39:24:44,  3.69s/it, loss=1.448, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2314]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:43:38] Step: 11,575/50k | Loss: 1.448 | PPL: 1.15 | Best: 1.14\n","           Mem: 2315 | Buf: 92,592 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11584/50000 [10:05:24<38:21:32,  3.59s/it, loss=1.449, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2316]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:44:38] Step: 11,585/50k | Loss: 1.449 | PPL: 1.15 | Best: 1.14\n","           Mem: 2317 | Buf: 92,672 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11594/50000 [10:06:37<38:26:07,  3.60s/it, loss=1.447, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2318]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:45:38] Step: 11,595/50k | Loss: 1.447 | PPL: 1.15 | Best: 1.14\n","           Mem: 2319 | Buf: 92,752 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  23%|‚ñà‚ñà‚ñé       | 11595/50000 [10:07:10<135:05:11, 12.66s/it, loss=1.447, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2318]"]},{"output_type":"stream","name":"stdout","text":["  Batches: 11600\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11599/50000 [10:07:14<38:17:49,  3.59s/it, loss=1.455, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2319]"]},{"output_type":"stream","name":"stdout","text":["   Grad norm: 0.95\n","\n","[14:46:38] Step: 11,600/50k | Loss: 1.455 | PPL: 1.15 | Best: 1.14\n","           Mem: 2320 | Buf: 92,800 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  23%|‚ñà‚ñà‚ñé       | 11600/50000 [10:08:01<179:40:33, 16.84s/it, loss=1.455, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2319]"]},{"output_type":"stream","name":"stdout","text":["\n","üìä Step 11600: Train PPL=4.27 | Eval PPL=1.15 | LR=2.80e-04\n","   VRAM: 3.7GB | Memories: 2320 | Buffer: 92800\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11604/50000 [10:08:05<49:32:55,  4.65s/it, loss=1.446, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2320]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:47:38] Step: 11,605/50k | Loss: 1.446 | PPL: 1.15 | Best: 1.14\n","           Mem: 2321 | Buf: 92,832 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11614/50000 [10:09:19<38:55:29,  3.65s/it, loss=1.462, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2322]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:48:38] Step: 11,615/50k | Loss: 1.462 | PPL: 1.15 | Best: 1.14\n","           Mem: 2323 | Buf: 92,912 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11624/50000 [10:10:33<38:19:18,  3.59s/it, loss=1.441, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2324]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:49:38] Step: 11,625/50k | Loss: 1.441 | PPL: 1.15 | Best: 1.14\n","           Mem: 2325 | Buf: 92,992 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11629/50000 [10:11:11<38:40:45,  3.63s/it, loss=1.437, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2325]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:50:38] Step: 11,630/50k | Loss: 1.437 | PPL: 1.15 | Best: 1.14\n","           Mem: 2326 | Buf: 93,040 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11639/50000 [10:12:26<39:04:07,  3.67s/it, loss=1.442, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2327]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:51:38] Step: 11,640/50k | Loss: 1.442 | PPL: 1.15 | Best: 1.14\n","           Mem: 2328 | Buf: 93,120 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11647/50000 [10:13:38<70:51:59,  6.65s/it, loss=1.430, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2329]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:52:38] Step: 11,648/50k | Loss: 1.430 | PPL: 1.15 | Best: 1.14\n","           Mem: 2329 | Buf: 93,168 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11654/50000 [10:14:17<38:52:38,  3.65s/it, loss=1.465, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2330]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:53:38] Step: 11,655/50k | Loss: 1.465 | PPL: 1.15 | Best: 1.14\n","           Mem: 2331 | Buf: 93,232 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11664/50000 [10:15:32<38:50:59,  3.65s/it, loss=1.451, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2332]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:54:38] Step: 11,665/50k | Loss: 1.451 | PPL: 1.15 | Best: 1.14\n","           Mem: 2333 | Buf: 93,312 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11669/50000 [10:16:09<38:19:10,  3.60s/it, loss=1.455, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2333]"]},{"output_type":"stream","name":"stdout","text":["\n","[14:55:38] Step: 11,670/50k | Loss: 1.455 | PPL: 1.15 | Best: 1.14\n","           Mem: 2334 | Buf: 93,360 | Phase: wake | ETA: 9.7h\n"]},{"output_type":"stream","name":"stderr","text":["Training (Optimized):  23%|‚ñà‚ñà‚ñé       | 11678/50000 [10:17:23<51:51:07,  4.87s/it, loss=1.448, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2335]"]},{"output_type":"stream","name":"stdout","text":["\n","‚èπÔ∏è Interrupted\n","‚úÖ Checkpoint saved: step_11678\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining (Optimized):  23%|‚ñà‚ñà‚ñé       | 11678/50000 [10:17:28<33:46:16,  3.17s/it, loss=1.448, lr=2.80e-04, it/s=0.32, mem=3.7GB, mem_count=2335]"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Checkpoint saved\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Checkpoint saved: step_11678\n","\n","======================================================================\n","‚úÖ TRAINING COMPLETE (OPTIMIZED)\n","======================================================================\n","‚è±Ô∏è  Total Time: 10.29 hours\n","üìä Steps: 11678/50000\n","üöÄ Speed: 0.32 it/s\n","üß† Memories: 2335\n","üìà Final Train PPL: 4.29\n","üìà Final Eval PPL: 1.15\n","üìà Best PPL: 1.14\n","üíæ Checkpoints: /content/drive/MyDrive/aura_checkpoints\n","======================================================================\n"]}]},{"cell_type":"code","source":["print(\"=\"*70)\n","print(\"DIAGNOSING PLATEAU / REGRESSION\")\n","print(\"=\"*70)\n","\n","print(f\"\\nüìä Current Status:\")\n","print(f\"   Step: {global_step}\")\n","print(f\"   Loss: {losses[-1]:.3f} (should be ~2.6)\")\n","print(f\"   Train PPL: {math.exp(min(losses[-1], 20)):.2f}\")\n","print(f\"   Eval PPL: {perplexities[-1]:.2f}\")\n","print(f\"   Best PPL: {min(perplexities):.2f}\")\n","print(f\"   LR: {scheduler.get_last_lr()[0]:.2e}\")\n","\n","# Check loss history\n","if len(losses) > 100:\n","    early_avg = sum(losses[:100]) / 100\n","    recent_avg = sum(losses[-100:]) / 100\n","    print(f\"\\nüìâ Loss Trend:\")\n","    print(f\"   Early avg (first 100): {early_avg:.3f}\")\n","    print(f\"   Recent avg (last 100): {recent_avg:.3f}\")\n","\n","    if recent_avg > early_avg + 0.5:\n","        print(f\"   ‚ö†Ô∏è WARNING: Loss INCREASED by {recent_avg - early_avg:.3f}\")\n","        print(f\"   This suggests training regressed!\")\n","\n","# Check if we're in the cosine decay part\n","warmup_done = global_step > config.warmup_steps\n","progress = (global_step - config.warmup_steps) / max(1, config.max_steps - config.warmup_steps)\n","print(f\"\\n‚è±Ô∏è Schedule Progress:\")\n","print(f\"   Warmup complete: {warmup_done}\")\n","print(f\"   Cosine progress: {progress*100:.1f}%\")\n","print(f\"   Current LR: {scheduler.get_last_lr()[0]:.2e} (peak was {config.lr:.2e})\")\n","\n","print(\"=\"*70)\n"],"metadata":{"id":"ycpFjN_DzyC3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"=\"*70)\n","print(\"FIXING LEARNING RATE\")\n","print(\"=\"*70)\n","\n","print(f\"\\nCurrent LR: {scheduler.get_last_lr()[0]:.2e}\")\n","print(f\"Config peak LR: {config.lr:.2e}\")\n","print(f\"Issue: LR never warmed up to peak!\")\n","\n","config.lr = 3e-4\n","\n","# Solution: Create fresh optimizer and scheduler at correct position\n","print(f\"\\nüîß Resetting optimizer to step {global_step}...\")\n","\n","# Create new optimizer\n","optimizer = torch.optim.AdamW(\n","    model.parameters(),\n","    lr=3e-4,  # Start at config.lr (3e-4)\n","    weight_decay=config.weight_decay,\n","    betas=(0.9, 0.95)\n",")\n","\n","# Create new scheduler\n","def warmup_cosine(step):\n","    if step < config.warmup_steps:\n","        return (step + 1) / config.warmup_steps\n","    progress = (step - config.warmup_steps) / max(1, config.max_steps - config.warmup_steps)\n","    return 0.5 * (1 + np.cos(np.pi * progress))\n","\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, warmup_cosine)\n","\n","# Step scheduler to current position\n","for _ in range(global_step):\n","    scheduler.step()\n","\n","current_lr = scheduler.get_last_lr()[0]\n","print(f\"‚úÖ New optimizer created\")\n","print(f\"   Current LR: {current_lr:.2e}\")\n","print(f\"   Warmup steps: {config.warmup_steps}\")\n","print(f\"   At step {global_step} (warmup done: {global_step >= config.warmup_steps})\")\n","\n","print(\"=\"*70)\n"],"metadata":{"id":"24FMqVW20FHe"},"execution_count":null,"outputs":[]}]}