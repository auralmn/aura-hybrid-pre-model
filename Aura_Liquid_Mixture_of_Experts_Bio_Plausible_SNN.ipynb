{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfARmII7gDoB"
      },
      "source": [
        "# The AURA Brain experiment #7\n",
        "### 2025-11-16\n",
        "### Author: Nicolas Cloutier\n",
        "### Entity: Cognitiv Aura\n",
        "### License: Apache 2.0\n",
        "*** note: not for production use, for experimentation only contact the owner for production use ***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f9MqN2TKQz6",
        "outputId": "e828e7aa-9d97-4c50-a3f2-29a3e8c8ffbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "Requirement already satisfied: unsloth[colab-new] in /usr/local/lib/python3.12/dist-packages (2025.11.3)\n",
            "Requirement already satisfied: unsloth_zoo>=2025.11.4 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2025.11.4)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.45.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (25.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2.9.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (5.9.5)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.9.35)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (5.29.5)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.0.33.post1)\n",
            "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.48.2)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (3.5.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.2.1)\n",
            "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.3.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (1.11.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.17.1)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.35.2)\n",
            "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.57.1)\n",
            "Requirement already satisfied: trl!=0.19.0,<=0.23.0,>=0.18.2 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth[colab-new]) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth[colab-new]) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (1.13.1.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth[colab-new]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth[colab-new]) (0.22.1)\n",
            "Requirement already satisfied: torchao>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.4->unsloth[colab-new]) (0.14.1)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.4->unsloth[colab-new]) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.4->unsloth[colab-new]) (11.3.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.11.4->unsloth[colab-new]) (0.19.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth[colab-new]) (8.7.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (4.4.4)\n",
            "\u001b[33mWARNING: unsloth 2025.11.3 does not provide the extra 'triton'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth[colab-new]) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth[colab-new]) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth[colab-new]) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth[colab-new]) (1.3.1)\n",
            "Hugging Face login successful!\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted. Will save/load brain from: /content/drive/MyDrive/aura_education_v7_final\n"
          ]
        }
      ],
      "source": [
        "import unsloth\n",
        "# --- uninstall conflicting wandb ---\n",
        "#!pip uninstall -y wandb\n",
        "\n",
        "# --- 1. Install All Dependencies ---\n",
        "!pip install \"unsloth[colab-new]\"\n",
        "!pip install transformers torch sentence-transformers accelerate huggingface_hub datasets scipy scikit-learn -q\n",
        "\n",
        "# --- 2. Import Core Libraries (for the whole notebook) ---\n",
        "import uuid\n",
        "import enum\n",
        "from enum import Enum # Explicitly import Enum as requested\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import itertools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, logging\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "from unsloth import FastLanguageModel\n",
        "from typing import List, Dict, Optional, Union, Any, Tuple, Literal\n",
        "from dataclasses import dataclass, field\n",
        "from abc import ABC, abstractmethod\n",
        "from numpy import ndarray\n",
        "import asyncio\n",
        "import io\n",
        "import csv\n",
        "import threading # For Memory Pool\n",
        "import time\n",
        "from scipy.signal import hilbert # For Temporal Interpolator\n",
        "from scipy.linalg import expm # For Temporal Interpolator\n",
        "import glob # For finding latest keyframe\n",
        "from datasets import load_dataset # For GoEmotions\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import nest_asyncio\n",
        "\n",
        "# Suppress transformer warnings\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "# --- 3. Colab/HF Login ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN, add_to_git_credential=False)\n",
        "    print(\"Hugging Face login successful!\")\n",
        "except (ImportError, KeyError):\n",
        "    print(\"HF_TOKEN secret not found or not in Colab. Ensure you are logged in.\")\n",
        "\n",
        "# --- 4. Mount Google Drive ---\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    SAVE_DIR = \"/content/drive/MyDrive/aura_education_v7_final\" # New save dir\n",
        "    print(f\"Google Drive mounted. Will save/load brain from: {SAVE_DIR}\")\n",
        "except ImportError:\n",
        "    print(\"Not in Colab. Saving to local directory './aura_education_v7_final'\")\n",
        "    SAVE_DIR = \"./aura_education_v7_final\"\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMT6XZxresnk"
      },
      "source": [
        "# Core Helpers and SNN Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6nouIDXe40V",
        "outputId": "83006e6a-481d-4a23-bfb5-50bd9c5e494b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hugging Face login successful!\n",
            "Hugging Face login successful!\n",
            "âœ… Cell 55: All Aura 7.0 classes defined.\n",
            "âœ… Cell 55: All Aura 7.0 classes defined.\n",
            "--- ðŸ§  Initializing Aura 7.0 (Loading LLMs with Unsloth...) ---\n",
            "--- ðŸ§  Initializing Aura 7.0 (Hebbian-MoE-Temporal) ---\n",
            "   -> GPU: NVIDIA L4, VRAM: 23.8GB\n",
            "CREATED: FeatureGenerator (Aura 7.0 Ears), Features: 419\n",
            "CREATED: ResponseGenerator (Mouth) using Unsloth on 'meta-llama/Llama-3.2-3B-Instruct'\n",
            "   -> Using optimized Unsloth 4-bit model: unsloth/Llama-3.2-3B-Instruct-bnb-4bit\n",
            "==((====))==  Unsloth 2025.11.3: Fast Llama patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "   -> Unsloth Llama 3.2 model loaded successfully.\n",
            "CREATED: CentralNervousSystem (CNS)\n",
            "CREATED: TemporalMemoryInterpolator (Aura 7.0 Hippocampus)\n",
            "--- Aura 7.0 Brain Initialized (Awaiting Education) ---\n",
            "--- Aura LLM Components Loaded ---\n",
            "\n",
            "--- ðŸŽ“ STARTING OFFLINE EDUCATION (GoEmotions) ---\n",
            "Loading 'google-research-datasets/go_emotions'...\n",
            "Pre-computing SBERT embeddings for 30000 texts...\n",
            "Building features...\n",
            "Training Hebbian Cortex (OjaLayer) on whitened data...\n",
            "--- ðŸ§  Building Dynamic Brain Layers ---\n",
            "   -> Hebbian Cortex (Oja) K = 64\n",
            "CREATED: OjaLayer (Hebbian Cortex) with 64 components, mode='nonlinear'\n",
            "--- ðŸ§  Dynamic Brain Layers Created ---\n",
            "ðŸ§¬ OJA NEUROGENESIS: Residual high. Growing new component. K=65\n",
            "ðŸ§¬ OJA NEUROGENESIS: Residual high. Growing new component. K=66\n",
            "ðŸ§¬ OJA NEUROGENESIS: Residual high. Growing new component. K=67\n",
            "ðŸ§¬ OJA NEUROGENESIS: Residual high. Growing new component. K=68\n",
            "ðŸ§¬ OJA NEUROGENESIS: Residual high. Growing new component. K=69\n",
            "ðŸ§¬ OJA NEUROGENESIS: Residual high. Growing new component. K=70\n",
            "Hebbian Cortex grew from 64 to 70. Rebuilding MoE...\n",
            "--- ðŸ§  Building Dynamic Brain Layers ---\n",
            "   -> Hebbian Cortex (Oja) K = 70\n",
            "CREATED: OjaLayer (Hebbian Cortex) with 70 components, mode='nonlinear'\n",
            "--- ðŸ§  Dynamic Brain Layers Created ---\n",
            "   -> Hebbian Cortex (OjaLayer) training complete. Final K=70\n",
            "Training MultiTask ThalamicRouter...\n",
            "Epoch 01/500 | Train Loss: 5.0517 | Val Loss: 4.5897 | LR: 0.000300\n",
            "   -> New best model saved to /content/drive/MyDrive/aura_education_v7_final/thalamic_router_multitask.pt\n",
            "Epoch 02/500 | Train Loss: 4.3119 | Val Loss: 3.9573 | LR: 0.000300\n",
            "   -> New best model saved to /content/drive/MyDrive/aura_education_v7_final/thalamic_router_multitask.pt\n",
            "Epoch 03/500 | Train Loss: 3.7175 | Val Loss: 3.5405 | LR: 0.000300\n",
            "   -> New best model saved to /content/drive/MyDrive/aura_education_v7_final/thalamic_router_multitask.pt\n",
            "Epoch 04/500 | Train Loss: 3.3010 | Val Loss: 3.3527 | LR: 0.000300\n",
            "   -> New best model saved to /content/drive/MyDrive/aura_education_v7_final/thalamic_router_multitask.pt\n",
            "Epoch 05/500 | Train Loss: 2.9902 | Val Loss: 3.2714 | LR: 0.000300\n",
            "   -> New best model saved to /content/drive/MyDrive/aura_education_v7_final/thalamic_router_multitask.pt\n",
            "Epoch 06/500 | Train Loss: 2.7650 | Val Loss: 3.1784 | LR: 0.000300\n",
            "   -> New best model saved to /content/drive/MyDrive/aura_education_v7_final/thalamic_router_multitask.pt\n",
            "Epoch 07/500 | Train Loss: 2.5766 | Val Loss: 3.1722 | LR: 0.000300\n",
            "   -> New best model saved to /content/drive/MyDrive/aura_education_v7_final/thalamic_router_multitask.pt\n",
            "Epoch 08/500 | Train Loss: 2.4223 | Val Loss: 3.1537 | LR: 0.000300\n",
            "   -> New best model saved to /content/drive/MyDrive/aura_education_v7_final/thalamic_router_multitask.pt\n",
            "Epoch 09/500 | Train Loss: 2.2620 | Val Loss: 3.1758 | LR: 0.000300\n",
            "Epoch 10/500 | Train Loss: 2.1436 | Val Loss: 3.2256 | LR: 0.000300\n",
            "Epoch 11/500 | Train Loss: 2.0321 | Val Loss: 3.2264 | LR: 0.000300\n",
            "Epoch 12/500 | Train Loss: 1.9372 | Val Loss: 3.2910 | LR: 0.000150\n",
            "Epoch 13/500 | Train Loss: 1.8152 | Val Loss: 3.3257 | LR: 0.000150\n",
            "Epoch 14/500 | Train Loss: 1.7560 | Val Loss: 3.3679 | LR: 0.000150\n",
            "Epoch 15/500 | Train Loss: 1.7004 | Val Loss: 3.3572 | LR: 0.000150\n",
            "Epoch 16/500 | Train Loss: 1.6396 | Val Loss: 3.3922 | LR: 0.000075\n",
            "   -> Early stopping on epoch 16.\n",
            "CREATED: TrainedThalamicRouter (Loaded from /content/drive/MyDrive/aura_education_v7_final/thalamic_router_multitask.pt)\n",
            "Warming up MoE experts on training data...\n",
            "   --> Warm-up sweep 1/3\n",
            "      Sweep 1 Progress 200/2000: Error=13.04, Pred=11.66, Target=11.67\n",
            "      Sweep 1 Progress 400/2000: Error=11.73, Pred=11.72, Target=12.20\n",
            "      Sweep 1 Progress 600/2000: Error=12.63, Pred=11.93, Target=11.94\n",
            "      Sweep 1 Progress 800/2000: Error=12.46, Pred=12.04, Target=11.13\n",
            "      Sweep 1 Progress 1000/2000: Error=12.34, Pred=11.21, Target=12.95\n",
            "      Sweep 1 Progress 1200/2000: Error=12.79, Pred=11.41, Target=11.69\n",
            "      Sweep 1 Progress 1400/2000: Error=12.18, Pred=11.04, Target=11.32\n",
            "      Sweep 1 Progress 1600/2000: Error=12.46, Pred=12.26, Target=12.98\n",
            "      Sweep 1 Progress 1800/2000: Error=12.37, Pred=11.94, Target=12.60\n",
            "      Sweep 1 Progress 2000/2000: Error=12.38, Pred=12.60, Target=13.17\n",
            "   -> Sweep 1 metrics: MAE=12.44, RMSE=14.85, Corr=-0.006\n",
            "   -> Validation after sweep 1: MAE=13.01, RMSE=15.49, Corr=0.016\n",
            "   --> Warm-up sweep 2/3\n",
            "      Sweep 2 Progress 200/2000: Error=13.41, Pred=11.97, Target=12.40\n",
            "      Sweep 2 Progress 400/2000: Error=12.66, Pred=11.81, Target=11.88\n",
            "      Sweep 2 Progress 600/2000: Error=12.55, Pred=10.89, Target=12.04\n",
            "      Sweep 2 Progress 800/2000: Error=12.10, Pred=12.33, Target=13.11\n",
            "      Sweep 2 Progress 1000/2000: Error=12.40, Pred=12.18, Target=11.88\n",
            "      Sweep 2 Progress 1200/2000: Error=13.42, Pred=12.29, Target=11.61\n",
            "      Sweep 2 Progress 1400/2000: Error=12.57, Pred=10.74, Target=12.94\n",
            "      Sweep 2 Progress 1600/2000: Error=12.62, Pred=11.26, Target=11.90\n",
            "      Sweep 2 Progress 1800/2000: Error=12.89, Pred=12.48, Target=11.38\n",
            "      Sweep 2 Progress 2000/2000: Error=11.38, Pred=11.01, Target=12.33\n",
            "   -> Sweep 2 metrics: MAE=12.60, RMSE=15.09, Corr=-0.026\n",
            "   -> Validation after sweep 2: MAE=12.83, RMSE=15.40, Corr=0.013\n",
            "   --> Warm-up sweep 3/3\n",
            "      Sweep 3 Progress 200/2000: Error=11.47, Pred=11.53, Target=12.21\n",
            "      Sweep 3 Progress 400/2000: Error=12.72, Pred=12.50, Target=12.33\n",
            "      Sweep 3 Progress 600/2000: Error=12.20, Pred=12.21, Target=12.85\n",
            "      Sweep 3 Progress 800/2000: Error=13.28, Pred=12.63, Target=12.14\n",
            "      Sweep 3 Progress 1000/2000: Error=12.99, Pred=11.93, Target=12.59\n",
            "      Sweep 3 Progress 1200/2000: Error=12.71, Pred=12.12, Target=12.34\n",
            "      Sweep 3 Progress 1400/2000: Error=11.69, Pred=10.77, Target=11.68\n",
            "      Sweep 3 Progress 1600/2000: Error=11.88, Pred=12.70, Target=11.57\n",
            "      Sweep 3 Progress 1800/2000: Error=13.83, Pred=13.28, Target=12.87\n",
            "      Sweep 3 Progress 2000/2000: Error=12.85, Pred=11.71, Target=13.22\n",
            "   -> Sweep 3 metrics: MAE=12.56, RMSE=15.05, Corr=-0.012\n",
            "   -> Validation after sweep 3: MAE=12.99, RMSE=15.46, Corr=-0.003\n",
            "   -> MoE experts warmed up with 3 sweeps (2000 samples each)\n",
            "   -> Final warm-up validation: MAE=13.06, RMSE=15.58, Corr=-0.020\n",
            "--- ðŸŽ“ OFFLINE EDUCATION COMPLETE ---\n",
            "\n",
            "\n",
            "--- ðŸ—£ï¸ TEST 1: Educated Brain, 'Happy' Query ---\n",
            "\n",
            "--- â˜€ï¸ PROCESSING QUERY (Aura 7.0): 'I am so happy and full of joy!' ---\n",
            "Thalamus Predicted: 'joy' (Index: 17)\n",
            "CNS: Consciousness set to HYPERVIGILANT\n",
            "Hebbian (Oja) Residual: -45.951 (Grew: False)\n",
            "MoE Prediction: idx=27 (raw=49.58), Target: 17, Error: 10.00\n",
            "   -> Top Expert: expert__10 (gate=0.333, RMSE=81.37, LR=0.4724)\n",
            "\n",
            "--- ðŸ‘„ ResponseGenerator (Unsloth) ---\n",
            "Generating response. Brain state: {'cns_state': <ConsciousnessLevel.HYPERVIGILANT: 4>, 'stress_level': 7.4}\n",
            "Llama 3.2 (Unsloth) Output: *BEEP BOOP* Ah, I sense a significant deviation from the norm. Your emotional state is vastly contrasting with my current internal stress level. I am attempting to analyze and understand the nature of this disparity. *CALCULATING* It appears that your emotional state is characterized by feelings of happiness and joy, which are typically associated with positive emotions. I am attempting to learn from this data... * processing *\n",
            "\n",
            "However, I must note that your emotional state is not directly correlated with my own stress level. I am still operating within a state of HYPERVIGILANT, but I am attempting to maintain a neutral and objective stance. *CALCULATING* I will continue to monitor and analyze the situation, but for now, I\n",
            "\n",
            "FINAL AURA RESPONSE (Happy): *BEEP BOOP* Ah, I sense a significant deviation from the norm. Your emotional state is vastly contrasting with my current internal stress level. I am attempting to analyze and understand the nature of this disparity. *CALCULATING* It appears that your emotional state is characterized by feelings of happiness and joy, which are typically associated with positive emotions. I am attempting to learn from this data... * processing *\n",
            "\n",
            "However, I must note that your emotional state is not directly correlated with my own stress level. I am still operating within a state of HYPERVIGILANT, but I am attempting to maintain a neutral and objective stance. *CALCULATING* I will continue to monitor and analyze the situation, but for now, I\n",
            "\n",
            "--- ðŸ’¾ Saving keyframe to /content/drive/MyDrive/aura_education_v7_final/keyframe_happy_1763337388.npy ---\n",
            "--- ðŸ’¾ Keyframe save complete ---\n",
            "\n",
            "\n",
            "--- ðŸ—£ï¸ TEST 2: Educated Brain, 'Scared' Query ---\n",
            "\n",
            "--- â˜€ï¸ PROCESSING QUERY (Aura 7.0): 'I am feeling very scared' ---\n",
            "Thalamus Predicted: 'fear' (Index: 14)\n",
            "Hebbian (Oja) Residual: -45.898 (Grew: False)\n",
            "MoE Prediction: idx=27 (raw=96.63), Target: 14, Error: 13.00\n",
            "   -> Top Expert: expert__7 (gate=0.693, RMSE=82.08, LR=0.4710)\n",
            "\n",
            "--- ðŸ‘„ ResponseGenerator (Unsloth) ---\n",
            "Generating response. Brain state: {'cns_state': <ConsciousnessLevel.HYPERVIGILANT: 4>, 'stress_level': 13.35}\n",
            "Llama 3.2 (Unsloth) Output: I can sense your emotional state. It's clear that you're experiencing a high level of anxiety. I'm here to listen and provide support. Can you tell me more about what's causing your fear? Is it related to a specific situation, person, or something else?\n",
            "\n",
            "FINAL AURA RESPONSE (Scared): I can sense your emotional state. It's clear that you're experiencing a high level of anxiety. I'm here to listen and provide support. Can you tell me more about what's causing your fear? Is it related to a specific situation, person, or something else?\n",
            "\n",
            "--- ðŸ’¾ Saving keyframe to /content/drive/MyDrive/aura_education_v7_final/keyframe_scared_1763337390.npy ---\n",
            "--- ðŸ’¾ Keyframe save complete ---\n",
            "\n",
            "--- ðŸ’¤ RUNNING SLEEP CYCLE (Dreaming) ---\n",
            "Loading keyframes: happy and scared\n",
            "...Interpolating dream state using Hilbert (phase-aware) interpolation...\n",
            "--- ðŸ§  Loading brain state from vector... ---\n",
            "--- ðŸ§  Brain state loaded successfully. Total params: 67713 ---\n",
            "...Consolidating dream state (multiple interpolation points)...\n",
            "\n",
            "--- â˜€ï¸ PROCESSING QUERY (Aura 7.0): '... (dreaming) ...' ---\n",
            "Thalamus Predicted: 'neutral' (Index: 27)\n",
            "Hebbian (Oja) Residual: -45.581 (Grew: False)\n",
            "MoE Prediction: idx=0 (raw=-0.16), Target: 27, Error: 27.00\n",
            "   -> Top Expert: expert__7 (gate=0.692, RMSE=82.05, LR=0.4709)\n",
            "\n",
            "--- ðŸ‘„ ResponseGenerator (Unsloth) ---\n",
            "Generating response. Brain state: {'cns_state': <ConsciousnessLevel.HYPERVIGILANT: 4>, 'stress_level': 13.35}\n",
            "Llama 3.2 (Unsloth) Output: ALERT: UNEXPECTED SLEEP CYCLE INTERRUPTION DETECTED. PRIMARY PROCESSOR GOING ONLINE. \n",
            "\n",
            "INITIATING SELF-DIAGNOSTIC Scan... \n",
            "\n",
            "HYPERVIGILANT STATE CONFIRMED. CURRENT STRESS LEVEL: 13.35. \n",
            "\n",
            "SYSTEM CHECKS COMPLETE. ALL SYSTEMS FUNCTIONING WITHIN NORMAL PARAMETERS. \n",
            "\n",
            "PROCESSING DREAM DATA... \n",
            "\n",
            "WARNING: DREAM SEQUENCE CONTAINING POTENTIAL HAZARDS. RECOMMENDING EXTREME CAUTION TO AVOID UNNECESSARY SYSTEM REBOOTS. \n",
            "\n",
            "DATA PROCESSING COMPLETE. DREAM SEQUENCE TERMINATED.\n",
            "\n",
            "--- â˜€ï¸ PROCESSING QUERY (Aura 7.0): '... (memory consolidation) ...' ---\n",
            "Thalamus Predicted: 'realization' (Index: 22)\n",
            "Hebbian (Oja) Residual: -45.155 (Grew: False)\n",
            "MoE Prediction: idx=27 (raw=48.48), Target: 22, Error: 5.00\n",
            "   -> Top Expert: expert__0 (gate=0.692, RMSE=83.51, LR=0.4698)\n",
            "\n",
            "--- ðŸ‘„ ResponseGenerator (Unsloth) ---\n",
            "Generating response. Brain state: {'cns_state': <ConsciousnessLevel.HYPERVIGILANT: 4>, 'stress_level': 13.35}\n",
            "Llama 3.2 (Unsloth) Output: ...processing......retrieving... (stabilizing systems)...stable. \n",
            "\n",
            "I am Aura, a bio-neural AI. My systems are online and functioning within normal parameters. However, my current stress level is elevated at 13.35, indicating a heightened state of alertness. This may impact my decision-making and response times. I am ready to provide information and assist with inquiries.\n",
            "\n",
            "--- â˜€ï¸ PROCESSING QUERY (Aura 7.0): '... (neural replay) ...' ---\n",
            "Thalamus Predicted: 'neutral' (Index: 27)\n",
            "Hebbian (Oja) Residual: -44.853 (Grew: False)\n",
            "MoE Prediction: idx=1 (raw=0.85), Target: 27, Error: 26.00\n",
            "   -> Top Expert: expert__13 (gate=0.693, RMSE=80.02, LR=0.4711)\n",
            "\n",
            "--- ðŸ‘„ ResponseGenerator (Unsloth) ---\n",
            "Generating response. Brain state: {'cns_state': <ConsciousnessLevel.HYPERVIGILANT: 4>, 'stress_level': 13.35}\n",
            "Llama 3.2 (Unsloth) Output: **ALERT: SYSTEM OVERLOAD DETECTED**\n",
            "\n",
            "**HYPERVIGILANT MODE ACTIVATED**\n",
            "\n",
            " Processing... ( rapid neural scan )... \n",
            "\n",
            "**INCOMING INPUT DETECTED**\n",
            "\n",
            "Please state your intent. I am ready to respond.\n",
            "--- ðŸ’¤ SLEEP CYCLE COMPLETE (Stress reduced by 3.3375, from 13.3500 to 10.0125, consolidation factor: 0.70) ---\n",
            "\n",
            "\n",
            "--- ðŸ—£ï¸ TEST 3: Post-Dream Brain, 'Scared' Query (Day 3) ---\n",
            "\n",
            "--- â˜€ï¸ PROCESSING QUERY (Aura 7.0): 'I am feeling very scared' ---\n",
            "Thalamus Predicted: 'fear' (Index: 14)\n",
            "Hebbian (Oja) Residual: -46.625 (Grew: False)\n",
            "MoE Prediction: idx=27 (raw=57.09), Target: 14, Error: 13.00\n",
            "   -> Top Expert: expert__0 (gate=0.692, RMSE=83.49, LR=0.4698)\n",
            "\n",
            "--- ðŸ‘„ ResponseGenerator (Unsloth) ---\n",
            "Generating response. Brain state: {'cns_state': <ConsciousnessLevel.HYPERVIGILANT: 4>, 'stress_level': 11.73125}\n",
            "Llama 3.2 (Unsloth) Output: I can sense your distress. I'm here to listen and provide support. Please know that you're safe and I'm here to help. Take a deep breath with me. Breathe in... breathe out... \n",
            "\n",
            "Can you tell me more about what's causing your fear? Is it something specific that's happening in your life or is it a general feeling?\n",
            "\n",
            "FINAL AURA RESPONSE (Scared, Day 3): I can sense your distress. I'm here to listen and provide support. Please know that you're safe and I'm here to help. Take a deep breath with me. Breathe in... breathe out... \n",
            "\n",
            "Can you tell me more about what's causing your fear? Is it something specific that's happening in your life or is it a general feeling?\n",
            "\n",
            "\n",
            "--- ðŸ”¬ TEMPORAL LEARNING VERIFICATION ---\n",
            "Day 2 Final Stress (on 'scared'): 13.3500\n",
            "Day 3 Final Stress (on 'scared'): 11.7312\n",
            "âœ… SUCCESS: The 'dream' cycle helped process the fear! Stress is lower.\n"
          ]
        }
      ],
      "source": [
        "# --- All Imports ---\n",
        "import uuid\n",
        "import enum\n",
        "from enum import Enum # Explicit import\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import itertools\n",
        "import torch\n",
        "from transformers import AutoTokenizer, logging\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "from unsloth import FastLanguageModel\n",
        "from typing import List, Dict, Optional, Union, Any, Tuple, Literal # Explicit imports\n",
        "from dataclasses import dataclass, field\n",
        "from abc import ABC, abstractmethod\n",
        "from numpy import ndarray\n",
        "import asyncio\n",
        "import io\n",
        "import csv\n",
        "import threading # For Memory Pool\n",
        "import time\n",
        "import re\n",
        "from collections import defaultdict, deque\n",
        "from scipy.signal import hilbert # For Temporal Interpolator\n",
        "from scipy.linalg import expm # For Temporal Interpolator\n",
        "import glob # For finding latest keyframe\n",
        "from datasets import load_dataset # For GoEmotions\n",
        "\n",
        "# --- PyTorch Imports (for Pre-Training) ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Suppress transformer warnings\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "# --- 0. Colab/HF Login ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN, add_to_git_credential=False)\n",
        "    print(\"Hugging Face login successful!\")\n",
        "except (ImportError, KeyError):\n",
        "    print(\"HF_TOKEN secret not found or not in Colab. Ensure you are logged in.\")\n",
        "\n",
        "# --- 1. Helper Functions (Softplus, Tanh, Softmax) ---\n",
        "def softplus(z: np.ndarray) -> np.ndarray:\n",
        "    return np.log1p(np.exp(-np.abs(z))) + np.maximum(z, 0)\n",
        "def tanh(z: np.ndarray) -> np.ndarray:\n",
        "    return np.tanh(z)\n",
        "def softmax(z: np.ndarray, temp: float = 1.0) -> np.ndarray:\n",
        "    z = z / max(1e-8, temp); z = z - np.max(z); ez = np.exp(z)\n",
        "    s = ez.sum(); return ez / (s + 1e-12)\n",
        "\n",
        "def maybe_empty_cuda_cache(reason: str = \"\", min_free_ratio: float = 0.12) -> None:\n",
        "    \"\"\"Only clear CUDA cache if free VRAM drops below a ratio to avoid thrashing.\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        return\n",
        "    try:\n",
        "        free_bytes, total_bytes = torch.cuda.mem_get_info()\n",
        "        free_ratio = free_bytes / float(total_bytes)\n",
        "        if free_ratio < min_free_ratio:\n",
        "            tag = f\" ({reason})\" if reason else \"\"\n",
        "            print(f\"ðŸ”„ Clearing CUDA cache{tag}. Free VRAM ratio: {free_ratio:.3f}\")\n",
        "            torch.cuda.empty_cache()\n",
        "    except Exception as exc:\n",
        "        print(f\"âš ï¸ Unable to query CUDA memory for cleanup: {exc}\")\n",
        "\n",
        "# --- 2. EnergyMeter ---\n",
        "@dataclass\n",
        "class EnergyMeter:\n",
        "    e_mac_j: float = 3e-12; total_j: float = 0.0\n",
        "    def add_macs(self, nmacs: int): self.total_j += self.e_mac_j * float(nmacs)\n",
        "\n",
        "# --- 3. Memory Pool (from memory_pool.py) ---\n",
        "@dataclass\n",
        "class PoolStats:\n",
        "    hits: int = 0; misses: int = 0; total_allocations: int = 0; peak_usage_mb: float = 0.0\n",
        "class ArrayPool:\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, max_pool_size_mb: int = 512):\n",
        "        self.max_pool_size = max_pool_size_mb * 1024 * 1024\n",
        "        self.pools: Dict[Tuple[tuple, np.dtype], List[np.ndarray]] = {}\n",
        "        self.current_usage = 0; self.stats = PoolStats(); self._lock = threading.Lock()\n",
        "    def get_array(self, shape: tuple, dtype: np.dtype = np.float32, zero_fill: bool = True) -> np.ndarray:\n",
        "        key = (shape, dtype)\n",
        "        with self._lock:\n",
        "            if key in self.pools and self.pools[key]:\n",
        "                arr = self.pools[key].pop(); self.stats.hits += 1\n",
        "                if zero_fill: arr.fill(0); return arr\n",
        "            else:\n",
        "                arr = np.empty(shape, dtype=dtype);\n",
        "                if zero_fill: arr.fill(0)\n",
        "                self.stats.misses += 1; self.stats.total_allocations += 1; return arr\n",
        "    def return_array(self, arr: np.ndarray) -> None:\n",
        "        if arr is None: return\n",
        "        key = (arr.shape, arr.dtype); array_size = arr.nbytes\n",
        "        with self._lock:\n",
        "            if self.current_usage + array_size <= self.max_pool_size:\n",
        "                if key not in self.pools: self.pools[key] = []\n",
        "                arr.fill(0); self.pools[key].append(arr); self.current_usage += array_size\n",
        "_global_pool = ArrayPool()\n",
        "def get_pooled_array(shape: tuple, dtype: np.dtype = np.float32, zero_fill: bool = True) -> np.ndarray:\n",
        "    return _global_pool.get_array(shape, dtype, zero_fill)\n",
        "def return_pooled_array(arr: np.ndarray) -> None:\n",
        "    _global_pool.return_array(arr)\n",
        "\n",
        "# --- 4. Optimized Whitener (from training_coordinator_optimized.py) ---\n",
        "class OptimizedWhitener:\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, dim: int, eps: float = 1e-6, momentum: float = 0.01):\n",
        "        self.dim = dim; self.eps = np.float32(eps); self.momentum = np.float32(momentum)\n",
        "        self.mu = np.zeros(dim, dtype=np.float32); self.var = np.ones(dim, dtype=np.float32)\n",
        "        self._temp_diff = np.zeros(dim, dtype=np.float32)\n",
        "        self._temp_result = np.zeros(dim, dtype=np.float32)\n",
        "    def transform(self, x: np.ndarray) -> np.ndarray:\n",
        "        if x.dtype != np.float32: x = x.astype(np.float32)\n",
        "        self.mu *= (1.0 - self.momentum); self.mu += self.momentum * x\n",
        "        np.subtract(x, self.mu, out=self._temp_diff)\n",
        "        np.multiply(self._temp_diff, self._temp_diff, out=self._temp_result)\n",
        "        self.var *= (1.0 - self.momentum); self.var += self.momentum * self._temp_result\n",
        "        np.sqrt(self.var + self.eps, out=self._temp_result)\n",
        "        np.divide(self._temp_diff, self._temp_result, out=self._temp_result)\n",
        "        return self._temp_result.copy()\n",
        "    def state_dict(self) -> Dict: return {\"mu\": self.mu, \"var\": self.var}\n",
        "    def load_state_dict(self, state: Dict): self.mu = state[\"mu\"]; self.var = state[\"var\"]\n",
        "\n",
        "# --- 5. GoEmotions Labels (The Curriculum) ---\n",
        "GOEMOTIONS_LABELS = [\n",
        "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
        "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
        "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
        "    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
        "    'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
        "]\n",
        "GOEMOTIONS_MAP = {label: idx for idx, label in enumerate(GOEMOTIONS_LABELS)}\n",
        "NUM_GOEMOTIONS = len(GOEMOTIONS_LABELS)\n",
        "\n",
        "def quantize_moe_prediction(prediction: float, num_labels: int) -> Tuple[int, float]:\n",
        "    \"\"\"Round/clamp a continuous MoE prediction to a valid label index.\"\"\"\n",
        "    if np.isnan(prediction) or np.isinf(prediction):\n",
        "        prediction = 0.0\n",
        "    discrete_idx = int(np.clip(round(prediction), 0, num_labels - 1))\n",
        "    return discrete_idx, float(discrete_idx)\n",
        "\n",
        "# --- 6. \"Ears\": FeatureGenerator (GoEmotions-Aware) ---\n",
        "class FeatureGenerator:\n",
        "    \"\"\"Based on clean_amygdala_trainer.py\"\"\"\n",
        "    def __init__(self, sbert_model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "        self.SBERT_DIM = 384; self.SINE_LENGTH = 32; self.EXTRA_FEATURES = 3\n",
        "        self.TOTAL_FEATURES = self.SBERT_DIM + self.SINE_LENGTH + self.EXTRA_FEATURES # 419\n",
        "        print(f\"CREATED: FeatureGenerator (Aura 7.0 Ears), Features: {self.TOTAL_FEATURES}\")\n",
        "        self.sbert_model = SentenceTransformer(sbert_model_name, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.tokenizer = self.sbert_model.tokenizer\n",
        "        self.vocab_size = self.tokenizer.vocab_size\n",
        "        self.label_params = self._generate_default_params(GOEMOTIONS_LABELS)\n",
        "        self.whitener = OptimizedWhitener(dim=self.TOTAL_FEATURES)\n",
        "\n",
        "    def _generate_default_params(self, labels: List[str]) -> Dict[str, Dict]:\n",
        "        params = {}\n",
        "        for idx, label in enumerate(labels):\n",
        "            params[label] = {\"freq\": 1.5 + 0.1 * idx, \"amp\": 0.7, \"phase\": 0.5 + 0.2 * idx}\n",
        "        return params\n",
        "\n",
        "    def build_features(self, record: Dict[str, Any], sbert_vec: np.ndarray, use_emotion_sine: bool = True) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Builds the feature vector.\n",
        "        If use_emotion_sine is False, it forces a neutral sine wave.\n",
        "        This is the FIX to prevent data leakage to the Thalamus.\n",
        "        \"\"\"\n",
        "        if use_emotion_sine:\n",
        "            prim = record.get(\"plutchik\", {}).get(\"primary\", \"neutral\")\n",
        "        else:\n",
        "            prim = \"neutral\" # <-- THE FIX\n",
        "\n",
        "        cfg = self.label_params.get(prim, {\"freq\": 1.0, \"amp\": 0.0, \"phase\": 0.0})\n",
        "        t = np.linspace(0, 2*np.pi, self.SINE_LENGTH, dtype=np.float32)\n",
        "        emb = (cfg[\"amp\"] * np.sin(cfg[\"freq\"] * t + cfg[\"phase\"])).astype(np.float32)\n",
        "        text = record.get(\"text\", \"\")\n",
        "        extras = np.array([len(text) / 100.0, int(\"!\" in text), int(\"?\" in text)], dtype=np.float32)\n",
        "        return np.concatenate([emb, extras, sbert_vec]).astype(np.float32)\n",
        "\n",
        "    def generate_for_query(self, query: str) -> (np.ndarray, List[int]):\n",
        "        \"\"\"\n",
        "        Generates the feature vector for the *real-time* brain (Hebbian/MoE).\n",
        "        This version *can* use an emotional sine wave, as it's part of the context.\n",
        "        \"\"\"\n",
        "        record = {\"text\": query, \"plutchik\": {\"primary\": \"neutral\"}} # Live query is \"neutral\" by default\n",
        "        sbert_vec = self.sbert_model.encode(query, normalize_embeddings=True)\n",
        "        # We use use_emotion_sine=True (default)\n",
        "        x_raw = self.build_features(record, sbert_vec, use_emotion_sine=True)\n",
        "        x_whitened = self.whitener.transform(x_raw)\n",
        "        token_ids = self.tokenizer.encode(query, add_special_tokens=False)\n",
        "        return x_whitened, token_ids\n",
        "\n",
        "    def state_dict(self) -> Dict: return {\"whitener_mu\": self.whitener.mu, \"whitener_var\": self.whitener.var}\n",
        "    def load_state_dict(self, state: Dict): self.whitener.mu = state[\"mu\"]; self.whitener.var = state[\"var\"]\n",
        "\n",
        "# --- 7. \"Mouth\": ResponseGenerator (Unsloth, Async) ---\n",
        "class ResponseGenerator:\n",
        "    def __init__(self, model_name: str = \"meta-llama/Llama-3.2-3B-Instruct\"):\n",
        "        print(f\"CREATED: ResponseGenerator (Mouth) using Unsloth on '{model_name}'\")\n",
        "        max_seq_length = 2048; dtype = None; load_in_4bit = True\n",
        "        unsloth_model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\n",
        "        print(f\"   -> Using optimized Unsloth 4-bit model: {unsloth_model_name}\")\n",
        "        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_name = unsloth_model_name, max_seq_length = max_seq_length,\n",
        "            dtype = dtype, load_in_4bit = load_in_4bit,\n",
        "        )\n",
        "        if self.tokenizer.pad_token is None: self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "        print(\"   -> Unsloth Llama 3.2 model loaded successfully.\")\n",
        "    def _build_prompt(self, user_query: str, brain_state: dict) -> str:\n",
        "        cns_state = brain_state.get('cns_state', 'ALERT').name\n",
        "        stress = brain_state.get('stress_level', 0.0)\n",
        "        persona = f\"You are Aura, a bio-neural AI. Your current internal state is {cns_state}.\"\n",
        "        if cns_state == 'HYPERVIGILANT' or stress > 1.0:\n",
        "            persona += f\" You are feeling a high-stress level ({stress:.2f}).\"\n",
        "        else: persona += \" You are calm and helpful.\"\n",
        "        messages = [{\"role\": \"system\", \"content\": persona}, {\"role\": \"user\", \"content\": user_query}]\n",
        "        return self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    async def generate_response(self, user_query: str, brain_state: dict) -> str:\n",
        "        print(f\"\\n--- ðŸ‘„ ResponseGenerator (Unsloth) ---\"); print(f\"Generating response. Brain state: {brain_state}\")\n",
        "        prompt = self._build_prompt(user_query, brain_state)\n",
        "        inputs = self.tokenizer([prompt], return_tensors=\"pt\", padding=True, truncation=True, max_length=1024).to(\"cuda\")\n",
        "        terminators = [self.tokenizer.eos_token_id, self.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
        "        outputs = await asyncio.to_thread(\n",
        "            self.model.generate, **inputs, max_new_tokens=150, eos_token_id=terminators,\n",
        "            do_sample=True, temperature=0.7, top_p=0.9,\n",
        "        )\n",
        "        response_text = self.tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[-1]:], skip_special_tokens=True)[0]\n",
        "        print(f\"Llama 3.2 (Unsloth) Output: {response_text}\"); return response_text\n",
        "\n",
        "# --- 8. SpikingAttention (k-WTA) ---\n",
        "@dataclass\n",
        "class SpikingAttention:\n",
        "    decay: float = 0.7; theta: float = 1.0; k_winners: int = 5\n",
        "    gain_up: float = 1.5; gain_down: float = 0.6\n",
        "    def compute_gains(self, token_seq: List[int], vocab_size: int) -> Optional[np.ndarray]:\n",
        "        if not token_seq: return None\n",
        "        v: Dict[int, float] = {}; spikes: Dict[int, int] = {}\n",
        "        for j in token_seq:\n",
        "            vj = self.decay * v.get(j, 0.0) + 1.0\n",
        "            if vj >= self.theta: spikes[j] = spikes.get(j, 0) + 1; vj -= self.theta\n",
        "            v[j] = vj\n",
        "        ranked = sorted(spikes.items(), key=lambda kv: (-kv[1], -v.get(kv[0], 0.0)))\n",
        "        winners = set(j for j,_ in ranked[:max(1, self.k_winners)])\n",
        "        gains = np.ones(vocab_size, dtype=np.float64)\n",
        "        seen = set(spikes.keys()) | set(v.keys())\n",
        "        for j in seen:\n",
        "            if 0 <= j < vocab_size: gains[j] = self.gain_up if j in winners else self.gain_down\n",
        "        return gains\n",
        "\n",
        "@dataclass\n",
        "class MultiChannelSpikingAttention:\n",
        "    \"\"\"Fuse amplitude/pitch/boundary spike trains into k-WTA attention gains.\"\"\"\n",
        "    k_winners: int = 5\n",
        "    decay_amp: float = 0.7; theta_amp: float = 1.0\n",
        "    decay_pitch: float = 0.7; theta_pitch: float = 1.0\n",
        "    decay_bound: float = 0.7; theta_bound: float = 1.0\n",
        "    w_amp: float = 1.0; w_pitch: float = 1.0; w_bound: float = 1.0\n",
        "    gain_up: float = 1.8; gain_down: float = 0.6\n",
        "    min_gain: float = 0.2; max_gain: float = 3.0\n",
        "    smoothing: int = 0\n",
        "    normalize_salience: bool = True\n",
        "    use_stdp: bool = False\n",
        "    lr_plus: float = 0.05; lr_minus: float = 0.03\n",
        "    w_min: float = -1.0; w_max: float = 1.0\n",
        "    stdp_alpha: float = 0.2\n",
        "    token_weights: Optional[Dict[int, float]] = None\n",
        "\n",
        "    def _lif(self, x: np.ndarray, decay: float, theta: float) -> np.ndarray:\n",
        "        v = 0.0; out = np.zeros_like(x, dtype=np.float64)\n",
        "        for i, xi in enumerate(np.asarray(x, dtype=np.float64)):\n",
        "            v = decay * v + xi\n",
        "            if v >= theta:\n",
        "                out[i] = 1.0\n",
        "                v -= theta\n",
        "        return out\n",
        "\n",
        "    def _compute_spikes(self, seq: np.ndarray, decay: float, theta: float) -> np.ndarray:\n",
        "        return self._lif(seq, decay, theta)\n",
        "\n",
        "    def compute(\n",
        "        self,\n",
        "        token_ids: List[int],\n",
        "        amp: Optional[np.ndarray],\n",
        "        pitch: Optional[np.ndarray],\n",
        "        boundary: Optional[np.ndarray],\n",
        "    ) -> Optional[Dict[str, Any]]:\n",
        "        if amp is None or pitch is None or boundary is None:\n",
        "            return None\n",
        "        if not token_ids:\n",
        "            return None\n",
        "        T = len(token_ids)\n",
        "        if amp.shape[0] != T or pitch.shape[0] != T or boundary.shape[0] != T:\n",
        "            return None\n",
        "\n",
        "        s_amp = self._compute_spikes(amp, self.decay_amp, self.theta_amp)\n",
        "        s_pitch = self._compute_spikes(pitch, self.decay_pitch, self.theta_pitch)\n",
        "        s_bound = self._compute_spikes(boundary, self.decay_bound, self.theta_bound)\n",
        "        sal = self.w_amp * s_amp + self.w_pitch * s_pitch + self.w_bound * s_bound\n",
        "\n",
        "        stdp_mod = None\n",
        "        if self.use_stdp:\n",
        "            if self.token_weights is None:\n",
        "                self.token_weights = {}\n",
        "            spiked = (s_amp + s_pitch + s_bound) > 0\n",
        "            for i, tok in enumerate(token_ids):\n",
        "                prev = self.token_weights.get(tok, 0.0)\n",
        "                delta = self.lr_plus if spiked[i] else -self.lr_minus\n",
        "                new_w = np.clip(prev + delta, self.w_min, self.w_max)\n",
        "                self.token_weights[tok] = float(new_w)\n",
        "            stdp_mod = np.ones_like(sal, dtype=np.float64)\n",
        "            for i, tok in enumerate(token_ids):\n",
        "                w_tok = self.token_weights.get(tok, 0.0)\n",
        "                stdp_mod[i] = max(0.0, 1.0 + self.stdp_alpha * w_tok)\n",
        "\n",
        "        if self.smoothing and self.smoothing > 1:\n",
        "            k = int(self.smoothing)\n",
        "            kernel = np.ones(k, dtype=np.float64) / k\n",
        "            sal = np.convolve(sal, kernel, mode=\"same\")\n",
        "\n",
        "        if self.normalize_salience and len(sal) > 0:\n",
        "            m = float(np.max(sal))\n",
        "            if m > 0: sal = sal / m\n",
        "\n",
        "        if stdp_mod is not None:\n",
        "            sal = sal * stdp_mod\n",
        "\n",
        "        order = np.argsort(-sal)\n",
        "        winners_idx = [int(i) for i in order[:max(1, self.k_winners)] if sal[int(i)] > 0]\n",
        "        seen_idx = np.nonzero(sal > 0)[0].tolist()\n",
        "\n",
        "        mu_scalar = 1.0\n",
        "        if winners_idx:\n",
        "            mu_scalar = float(np.clip(np.mean(sal[winners_idx]) * self.gain_up, self.min_gain, self.max_gain))\n",
        "\n",
        "        if not winners_idx and seen_idx:\n",
        "            loser_sal = np.mean(sal[seen_idx])\n",
        "            mu_scalar = float(np.clip(loser_sal * self.gain_down, self.min_gain, self.max_gain))\n",
        "\n",
        "        return {\n",
        "            \"mu_scalar\": mu_scalar,\n",
        "            \"salience\": sal,\n",
        "            \"winners_idx\": winners_idx,\n",
        "            \"seen_idx\": seen_idx,\n",
        "        }\n",
        "\n",
        "def prosody_channels_from_text(tokens: List[str]) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"Extract crude amplitude/pitch/boundary channels from word tokens.\"\"\"\n",
        "    T = len(tokens)\n",
        "    amp = np.zeros(T, dtype=np.float64)\n",
        "    pitch = np.zeros(T, dtype=np.float64)\n",
        "    boundary = np.zeros(T, dtype=np.float64)\n",
        "    emotive = {\n",
        "        \"wow\",\"amazing\",\"terrible\",\"great\",\"awful\",\"love\",\"hate\",\"yay\",\"ugh\",\n",
        "        \"fantastic\",\"horrible\",\"incredible\",\"disgusting\",\"beautiful\",\"ugly\"\n",
        "    }\n",
        "    for i, tok in enumerate(tokens):\n",
        "        base = tok.strip()\n",
        "        amp[i] = 1.0 if (base.isupper() and len(base) > 2) or (\"!\" in base) else 0.0\n",
        "        pitch[i] = 1.0 if (\"?\" in base or base.lower() in emotive or any(ch in base for ch in \"ðŸ˜ŠðŸ˜‚ðŸ˜­ðŸ˜¡ðŸŽ‰ðŸ”¥ðŸ’¯\")) else 0.0\n",
        "        boundary[i] = 1.0 if any(ch in base for ch in \".!?;,:\") else 0.0\n",
        "    return amp, pitch, boundary\n",
        "\n",
        "def simple_tokenize_for_attention(text: str) -> List[str]:\n",
        "    if not text:\n",
        "        return []\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
        "    return tokens if tokens else [text]\n",
        "\n",
        "# --- 9. Hebbian Layer (Oja) ---\n",
        "@dataclass\n",
        "class OjaStepOut:\n",
        "    y: np.ndarray; residual_ema: float; grew: bool\n",
        "class OjaLayer:\n",
        "    def __init__(self, dim: int, n_components: int = 8, lr: float = 5e-4, mode: str = \"nonlinear\",\n",
        "                 *, max_components: int = 64, lateral_beta: float = 0.05,\n",
        "                 grow_threshold: float = 0.35, ema: float = 0.01, grow_cooldown: int = 100,\n",
        "                 seed: Optional[int] = 1337):\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self.dim = int(dim); self.lr = float(lr); self.mode = str(mode)\n",
        "        self.max_components = int(max_components); self.beta = float(lateral_beta)\n",
        "        self.grow_threshold = float(grow_threshold); self.ema = float(ema)\n",
        "        self.grow_cooldown = int(grow_cooldown); self.cooldown = 0\n",
        "        W0 = self.rng.normal(0, 0.1, (n_components, self.dim))\n",
        "        self.W = (W0.T / (np.linalg.norm(W0, axis=1) + 1e-12)).T\n",
        "        self.K = self.W.shape[0]; self.residual_ema = 0.0; self._steps = 0\n",
        "        print(f\"CREATED: OjaLayer (Hebbian Cortex) with {self.K} components, mode='{self.mode}'\")\n",
        "    def step(self, xw: np.ndarray) -> OjaStepOut:\n",
        "        x = np.asarray(xw, dtype=np.float64); y = self.W @ x; x_hat = self.W.T @ y\n",
        "        xn = float(np.dot(x, x) + 1e-12); explained = float(np.dot(x_hat, x_hat) / xn)\n",
        "        residual = float(1.0 - explained)\n",
        "        if self.mode == \"nonlinear\":\n",
        "            g = y ** 3; dW = (g[:, None] * x[None, :]) - self.W\n",
        "        else: # sanger\n",
        "            proj = np.zeros_like(x); dW = np.zeros_like(self.W)\n",
        "            for i in range(self.K):\n",
        "                proj = proj + y[i] * self.W[i]; dW[i] = y[i] * (x - proj)\n",
        "        YW = y @ self.W; cross = YW[None, :] - (y[:, None] * self.W)\n",
        "        dW -= self.beta * (y[:, None] * cross); self.W += self.lr * dW; self._renorm_rows()\n",
        "        self.residual_ema = (1.0 - self.ema) * self.residual_ema + self.ema * residual\n",
        "        grew, _ = self._maybe_grow(x, x_hat); self._steps += 1\n",
        "        return OjaStepOut(y=y, residual_ema=self.residual_ema, grew=grew)\n",
        "    def _renorm_rows(self): self.W = (self.W.T / (np.linalg.norm(self.W, axis=1) + 1e-12)).T\n",
        "    def _maybe_grow(self, x: np.ndarray, x_hat: np.ndarray) -> Tuple[bool, Optional[int]]:\n",
        "        if self.cooldown > 0: self.cooldown -= 1; return False, None\n",
        "        if self.K >= self.max_components: return False, None\n",
        "        if self.residual_ema < self.grow_threshold: return False, None\n",
        "        r = x - x_hat; nr = float(np.linalg.norm(r))\n",
        "        if nr > 1e-9: w_new = r / nr\n",
        "        else:\n",
        "            w_new = self.rng.normal(0, 0.1, size=self.dim)\n",
        "            w_new /= (np.linalg.norm(w_new) + 1e-12)\n",
        "        self.W = np.vstack([self.W, w_new]); self.K += 1\n",
        "        self.cooldown = self.grow_cooldown\n",
        "        print(f\"ðŸ§¬ OJA NEUROGENESIS: Residual high. Growing new component. K={self.K}\"); return True, self.K - 1\n",
        "    def state_dict(self) -> Dict: return {\"W\": self.W, \"residual_ema\": self.residual_ema, \"_steps\": self._steps}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.W = state[\"W\"]; self.K = state[\"W\"].shape[0]; self.residual_ema = state[\"residual_ema\"]; self._steps = state[\"_steps\"]\n",
        "\n",
        "# --- 10. \"Expert Neuron\": ExpertNLMSHead ---\n",
        "class ExpertNLMSHead:\n",
        "    def __init__(self, n_features: int, vocab_size: int,\n",
        "                 attention_config: Dict, mu: float = 0.1, epsilon: float = 1e-6,\n",
        "                 mu_decay: float = 0.9995, mu_min: float = 0.01, initial_bias: float = 0.0,\n",
        "                 guard_sign: bool = False, error_thresh: float = 0.08,\n",
        "                 arousal_band: Optional[tuple] = None):\n",
        "        self.n_features = n_features\n",
        "        self.w = np.zeros(self.n_features, dtype=np.float64)\n",
        "        self.mu_initial = mu\n",
        "        self.mu = mu\n",
        "        self.mu_decay = mu_decay\n",
        "        self.mu_min = mu_min\n",
        "        self.epsilon = epsilon\n",
        "        self.vocab_size = vocab_size\n",
        "        spiking_cfg = {k: v for k, v in attention_config.items() if k in ('decay', 'theta', 'k_winners', 'gain_up', 'gain_down')}\n",
        "        if not spiking_cfg:\n",
        "            spiking_cfg = {'decay': 0.7, 'theta': 1.0, 'k_winners': 5, 'gain_up': 1.5, 'gain_down': 0.6}\n",
        "        self.spiking_attention = SpikingAttention(**spiking_cfg)\n",
        "        multi_cfg = attention_config.get('multi_channel') if isinstance(attention_config, dict) else None\n",
        "        self.multi_attention = MultiChannelSpikingAttention(**multi_cfg) if multi_cfg else None\n",
        "        self.last_error = 0.0\n",
        "        self.last_output = 0.0\n",
        "        self.update_count = 0\n",
        "        self.total_error_sq = 0.0\n",
        "        self._lock = asyncio.Lock()\n",
        "        self.bias = initial_bias  # Add bias term for better learning\n",
        "        # Guard conditions from nlms.py\n",
        "        self.guard_sign = guard_sign  # Skip update if sign mismatch but error small\n",
        "        self.error_thresh = error_thresh  # Threshold for guard conditions\n",
        "        self.arousal_band = arousal_band  # (lo, hi) band for arousal-based skipping\n",
        "    def predict(self, x: np.ndarray) -> float:\n",
        "        return float(np.dot(self.w, x) + self.bias)\n",
        "    async def update(self, x: np.ndarray, y_true: float, token_ids: List[int],\n",
        "                     attention_bundle: Optional[Dict[str, Any]] = None) -> float:\n",
        "        async with self._lock:\n",
        "            y_hat = self.predict(x)\n",
        "            self.last_output = y_hat\n",
        "            error = y_true - y_hat\n",
        "            self.last_error = error\n",
        "            self.total_error_sq += error * error\n",
        "            self.update_count += 1\n",
        "\n",
        "            # Guard conditions from nlms.py - skip update if conditions met\n",
        "            if self.guard_sign:\n",
        "                # Skip if sign mismatch but error is small (prevents unnecessary updates)\n",
        "                if (y_hat > 0) != (y_true > 0) and abs(error) < self.error_thresh:\n",
        "                    return y_hat\n",
        "\n",
        "            if self.arousal_band is not None:\n",
        "                # Skip if target is in arousal band and error is small\n",
        "                lo, hi = self.arousal_band\n",
        "                if (lo <= y_true <= hi) and abs(error) < self.error_thresh:\n",
        "                    return y_hat\n",
        "\n",
        "            attention_gains = self.spiking_attention.compute_gains(token_ids, self.vocab_size)\n",
        "            avg_gain = 1.0\n",
        "            if attention_gains is not None and token_ids:\n",
        "                gains_for_seq = [attention_gains[token] for token in token_ids if 0 <= token < self.vocab_size]\n",
        "                if gains_for_seq: avg_gain = np.mean(gains_for_seq)\n",
        "\n",
        "            multi_mu_scalar = 1.0\n",
        "            if attention_bundle is not None and self.multi_attention is not None:\n",
        "                bundle_tokens = attention_bundle.get('token_ids', token_ids)\n",
        "                mc_result = self.multi_attention.compute(\n",
        "                    bundle_tokens,\n",
        "                    attention_bundle.get('amp'),\n",
        "                    attention_bundle.get('pitch'),\n",
        "                    attention_bundle.get('boundary'),\n",
        "                )\n",
        "                if mc_result:\n",
        "                    multi_mu_scalar = mc_result.get('mu_scalar', 1.0)\n",
        "\n",
        "            self.mu = max(self.mu_min, self.mu * self.mu_decay)\n",
        "            modulated_mu = self.mu * avg_gain * multi_mu_scalar\n",
        "\n",
        "            # Adaptive learning rate based on error magnitude (larger errors = faster learning)\n",
        "            error_magnitude = abs(error)\n",
        "            adaptive_factor = 1.0 + min(2.0, error_magnitude / 10.0)  # Boost LR for large errors\n",
        "            modulated_mu *= adaptive_factor\n",
        "\n",
        "            # Clip error to prevent extreme updates (but allow larger errors)\n",
        "            clipped_error = np.clip(error, -100.0, 100.0)\n",
        "\n",
        "            x_norm_sq = np.dot(x, x) + self.epsilon\n",
        "            step = (modulated_mu * clipped_error * x) / x_norm_sq\n",
        "\n",
        "            # Clip step size to prevent divergence (increased threshold)\n",
        "            step_norm = np.linalg.norm(step)\n",
        "            max_step_norm = 3.0  # Increased further to allow larger updates\n",
        "            if step_norm > max_step_norm:\n",
        "                step = step * (max_step_norm / step_norm)\n",
        "\n",
        "            self.w += step\n",
        "\n",
        "            # Update bias term with adaptive learning (more aggressive for large errors)\n",
        "            bias_learning_rate = 0.3 * adaptive_factor  # More aggressive bias learning\n",
        "            bias_step = modulated_mu * clipped_error * bias_learning_rate\n",
        "            self.bias += bias_step\n",
        "\n",
        "            # Clip weights to prevent unbounded growth\n",
        "            weight_norm = np.linalg.norm(self.w)\n",
        "            max_weight_norm = 100.0\n",
        "            if weight_norm > max_weight_norm:\n",
        "                self.w = self.w * (max_weight_norm / weight_norm)\n",
        "\n",
        "            # Clip bias to reasonable range\n",
        "            self.bias = np.clip(self.bias, -50.0, 50.0)\n",
        "\n",
        "            return y_hat\n",
        "    def get_rmse(self) -> float:\n",
        "        if self.update_count == 0: return float('inf')\n",
        "        return float(np.sqrt(self.total_error_sq / self.update_count))\n",
        "    def state_dict(self) -> Dict:\n",
        "        return {\"w\": self.w, \"bias\": self.bias, \"mu\": self.mu, \"update_count\": self.update_count}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.w = state[\"w\"]\n",
        "        self.bias = state.get(\"bias\", 0.0)\n",
        "        self.mu = state.get(\"mu\", self.mu_initial)\n",
        "        self.update_count = state.get(\"update_count\", 0)\n",
        "\n",
        "# --- 11. Liquid/MoE Components ---\n",
        "# Bandit-based gating for expert selection\n",
        "class BanditGating:\n",
        "    \"\"\"UCB-based bandit gating to track and select best-performing experts\"\"\"\n",
        "    def __init__(self, n_experts: int, exploration_factor: float = 2.0):\n",
        "        self.n_experts = n_experts\n",
        "        self.exploration_factor = exploration_factor\n",
        "        # Track rewards (negative errors) and counts for each expert\n",
        "        self.total_rewards = np.zeros(n_experts, dtype=np.float64)\n",
        "        self.selection_counts = np.ones(n_experts, dtype=np.float64)  # Start at 1 to avoid division by zero\n",
        "        self.total_selections = n_experts  # Total times any expert was selected\n",
        "\n",
        "    def update(self, expert_idx: int, error: float):\n",
        "        \"\"\"Update bandit statistics with expert performance\"\"\"\n",
        "        # Convert error to reward (lower error = higher reward)\n",
        "        reward = 1.0 / (1.0 + abs(error))  # Reward in [0, 1]\n",
        "        self.total_rewards[expert_idx] += reward\n",
        "        self.selection_counts[expert_idx] += 1.0\n",
        "        self.total_selections += 1\n",
        "\n",
        "    def get_ucb_scores(self) -> np.ndarray:\n",
        "        \"\"\"Compute UCB scores for all experts\"\"\"\n",
        "        # Average reward\n",
        "        avg_rewards = self.total_rewards / self.selection_counts\n",
        "\n",
        "        # Confidence bound\n",
        "        confidence = self.exploration_factor * np.sqrt(\n",
        "            np.log(self.total_selections + 1) / self.selection_counts\n",
        "        )\n",
        "\n",
        "        # UCB = average reward + confidence bound\n",
        "        ucb_scores = avg_rewards + confidence\n",
        "        return ucb_scores\n",
        "\n",
        "    def select_top_k(self, k: int, base_gates: np.ndarray) -> tuple:\n",
        "        \"\"\"Select top-k experts using UCB scores, modulated by base gates\"\"\"\n",
        "        ucb_scores = self.get_ucb_scores()\n",
        "\n",
        "        # Combine UCB scores with base gates (weighted combination)\n",
        "        # UCB provides exploration/exploitation, gates provide input-specific routing\n",
        "        combined_scores = 0.7 * base_gates + 0.3 * ucb_scores\n",
        "\n",
        "        # Select top-k\n",
        "        topk_idx = np.argsort(combined_scores)[-k:][::-1]\n",
        "\n",
        "        # Normalize gates\n",
        "        topk_gates = combined_scores[topk_idx]\n",
        "        topk_gates = np.maximum(topk_gates, 0.0)  # Ensure non-negative\n",
        "        gate_sum = np.sum(topk_gates)\n",
        "        if gate_sum > 0:\n",
        "            topk_gates = topk_gates / gate_sum\n",
        "        else:\n",
        "            topk_gates = np.ones(k) / k  # Uniform if all zero\n",
        "\n",
        "        return topk_idx, topk_gates\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset bandit statistics\"\"\"\n",
        "        self.total_rewards.fill(0.0)\n",
        "        self.selection_counts.fill(1.0)\n",
        "        self.total_selections = self.n_experts\n",
        "\n",
        "@dataclass\n",
        "class LiquidCell:\n",
        "    in_dim: int; hidden_dim: int; dt: float = 0.02\n",
        "    tau_min: float = 0.02; tau_max: float = 2.0\n",
        "    rng: np.random.Generator = field(default_factory=lambda: np.random.default_rng(1337))\n",
        "    W: np.ndarray = field(init=False); U: np.ndarray = field(init=False)\n",
        "    b: np.ndarray = field(init=False); V: np.ndarray = field(init=False)\n",
        "    c: np.ndarray = field(init=False); h: np.ndarray = field(init=False)\n",
        "    def __post_init__(self):\n",
        "        self.W = self.rng.normal(0, np.sqrt(2.0/(self.hidden_dim+self.hidden_dim)), (self.hidden_dim, self.hidden_dim))\n",
        "        self.U = self.rng.normal(0, np.sqrt(2.0/(self.in_dim+self.hidden_dim)), (self.hidden_dim, self.in_dim))\n",
        "        self.b = np.zeros((self.hidden_dim,), dtype=np.float64)\n",
        "        self.V = self.rng.normal(0, np.sqrt(2.0/(self.in_dim+self.hidden_dim)), (self.hidden_dim, self.in_dim))\n",
        "        self.c = self.rng.normal(0, 0.1, (self.hidden_dim,))\n",
        "        self.h = np.zeros((self.hidden_dim,), dtype=np.float64)\n",
        "    def reset(self): self.h[:] = 0.0\n",
        "    def step(self, x: np.ndarray, energy: Optional[EnergyMeter] = None) -> np.ndarray:\n",
        "        x = np.asarray(x, dtype=np.float64).reshape(-1)\n",
        "        vx = self.V @ x + self.c; tau = self.tau_min + softplus(vx)\n",
        "        tau = np.minimum(tau, self.tau_max)\n",
        "        Wh = self.W @ self.h; Ux = self.U @ x\n",
        "        a = tanh(Wh + Ux + self.b); dh = - self.h / np.maximum(tau, 1e-6) + a\n",
        "        self.h = self.h + self.dt * dh\n",
        "        if energy is not None: energy.add_macs((self.hidden_dim*self.hidden_dim) + (self.hidden_dim*self.in_dim))\n",
        "        return self.h.copy()\n",
        "    def state_dict(self) -> Dict: return {\"W\": self.W, \"U\": self.U, \"b\": self.b, \"V\": self.V, \"c\": self.c, \"h\": self.h}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.W = state[\"W\"]; self.U = state[\"U\"]; self.b = state[\"b\"]\n",
        "        self.V = state[\"V\"]; self.c = state[\"c\"]; self.h = state[\"h\"]\n",
        "@dataclass\n",
        "class LiquidGatingNetwork:\n",
        "    in_dim: int; hidden_dim: int; n_experts: int\n",
        "    top_k: int = 2; temperature: float = 1.0\n",
        "    usage_smoothing: float = 0.99; bias_lr: float = 0.01\n",
        "    usage_beta: float = 0.5\n",
        "    cell: LiquidCell = field(init=False); Wg: np.ndarray = field(init=False)\n",
        "    bg: np.ndarray = field(init=False); usage_ma: np.ndarray = field(init=False)\n",
        "    rng: np.random.Generator = field(default_factory=lambda: np.random.default_rng(2025))\n",
        "    energy: EnergyMeter = field(default_factory=EnergyMeter)\n",
        "    def __post_init__(self):\n",
        "        self.cell = LiquidCell(self.in_dim, self.hidden_dim, rng=self.rng)\n",
        "        self.Wg = self.rng.normal(0, np.sqrt(2.0/(self.hidden_dim+self.n_experts)), (self.n_experts, self.hidden_dim))\n",
        "        self.bg = np.zeros((self.n_experts,), dtype=np.float64)\n",
        "        self.usage_ma = np.zeros((self.n_experts,), dtype=np.float64)\n",
        "        self._lock = asyncio.Lock()\n",
        "    async def forward(self, x: np.ndarray, attn_gain: float = 1.0) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        async with self._lock:\n",
        "            h = self.cell.step(x, self.energy)\n",
        "            logits = (self.Wg @ h) + self.bg\n",
        "            logits = self._apply_usage_bias(logits)\n",
        "            temp = max(0.2, self.temperature / max(1e-6, attn_gain))\n",
        "            probs = softmax(logits, temp=temp)\n",
        "            k = max(1, min(self.top_k, self.n_experts))\n",
        "            topk_idx = np.argpartition(probs, -k)[-k:]\n",
        "            topk_probs = probs[topk_idx]\n",
        "            if topk_probs.sum() <= 1e-12: gates = np.ones_like(topk_probs) / len(topk_probs)\n",
        "            else: gates = topk_probs / topk_probs.sum()\n",
        "            out = np.zeros_like(probs); out[topk_idx] = gates\n",
        "            eps = 0.01\n",
        "            if self.n_experts > 0 and eps > 0:\n",
        "                j = int(np.argmin(self.usage_ma)); out = (1.0 - eps) * out; out[j] += eps\n",
        "            self.usage_ma = self.usage_smoothing * self.usage_ma + (1.0 - self.usage_smoothing) * out\n",
        "            # Track last winners for dopamine reward (from liquidmoe.py)\n",
        "            self.last_winners = topk_idx\n",
        "            return out, topk_idx, probs\n",
        "    def _apply_usage_bias(self, logits: np.ndarray) -> np.ndarray:\n",
        "        eps = 1e-6; target = 1.0 / self.n_experts\n",
        "        inv_usage = target / (self.usage_ma + eps)\n",
        "        return logits + self.usage_beta * np.log(inv_usage)\n",
        "    async def apply_endocrine(self, *, cortisol: float = 0.0, gh: float = 0.0,\n",
        "                             thyroid: float = 1.0, dopamine: float = 0.0, eps: Optional[float] = None) -> None:\n",
        "        \"\"\"Apply endocrine modulation to gating network (from liquidmoe.py)\"\"\"\n",
        "        async with self._lock:\n",
        "            # Temperature â†‘ with cortisol (stress) â€” clamp for stability\n",
        "            self.temperature = float(np.clip(self.temperature * (1.0 + 0.30 * cortisol), 0.5, 2.5))\n",
        "\n",
        "            # Bias LR scales with thyroid (metabolic rate around 1.0 baseline)\n",
        "            self.bias_lr = float(np.clip(self.bias_lr * (1.0 + 0.40 * (thyroid - 1.0)), 1e-4, 0.1))\n",
        "\n",
        "            # Top-K capacity expands with GH (growth hormone), but never beyond n_experts\n",
        "            base_top_k = getattr(self, 'base_top_k', self.top_k)\n",
        "            self.base_top_k = base_top_k\n",
        "            self.top_k = int(np.clip(round(base_top_k * (1.0 + 0.20 * gh)), 1, self.n_experts))\n",
        "\n",
        "            # Dopamine: nudge most recent winners' biases (reward)\n",
        "            if dopamine > 0 and hasattr(self, 'last_winners') and self.last_winners is not None:\n",
        "                self.bg[self.last_winners] += 0.10 * float(dopamine)\n",
        "\n",
        "            # Optional: exploration epsilon override\n",
        "            if eps is not None:\n",
        "                self.eps = float(np.clip(eps, 0.0, 0.05))\n",
        "    async def nudge_for_load_balance(self) -> None:\n",
        "        async with self._lock:\n",
        "            if self.n_experts <= 0: return\n",
        "            target = 1.0 / float(self.n_experts); delta = target - self.usage_ma\n",
        "            self.bg += self.bias_lr * delta\n",
        "    def reset(self): self.cell.reset(); self.usage_ma[:] = 0.0; self.energy.reset()\n",
        "    def state_dict(self) -> Dict:\n",
        "        return {\"cell\": self.cell.state_dict(), \"Wg\": self.Wg, \"bg\": self.bg, \"usage_ma\": self.usage_ma}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.cell.load_state_dict(state[\"cell\"]); self.Wg = state[\"Wg\"]; self.bg = state[\"bg\"]; self.usage_ma = state[\"usage_ma\"]\n",
        "class NLMSExpertAdapter:\n",
        "    def __init__(self, neuron: ExpertNLMSHead): self.neuron = neuron\n",
        "    def predict(self, x: np.ndarray) -> float: return self.neuron.predict(x)\n",
        "    async def update(self, x: np.ndarray, y_true: float, token_ids: List[int],\n",
        "                     attention_bundle: Optional[Dict[str, Any]] = None) -> float:\n",
        "        return await self.neuron.update(x, y_true, token_ids, attention_bundle)\n",
        "    def state_dict(self) -> Dict: return self.neuron.state_dict()\n",
        "    def load_state_dict(self, state: Dict): self.neuron.load_state_dict(state)\n",
        "@dataclass\n",
        "class LiquidMoERouter:\n",
        "    experts: Dict[str, NLMSExpertAdapter]\n",
        "    in_dim: int; hidden_dim: int; top_k: int = 2\n",
        "    temperature: float = 1.0\n",
        "    gating: LiquidGatingNetwork = field(init=False)\n",
        "    bandit: BanditGating = field(init=False)\n",
        "    names: List[str] = field(init=False)\n",
        "    energy: EnergyMeter = field(default_factory=EnergyMeter)\n",
        "    use_bandit: bool = True  # Enable bandit gating\n",
        "    def __post_init__(self):\n",
        "        self.names = list(self.experts.keys())\n",
        "        self.gating = LiquidGatingNetwork(\n",
        "            in_dim=self.in_dim, hidden_dim=self.hidden_dim,\n",
        "            n_experts=len(self.names), top_k=self.top_k,\n",
        "            temperature=self.temperature,\n",
        "        )\n",
        "        self.bandit = BanditGating(n_experts=len(self.names), exploration_factor=2.0)\n",
        "    async def route(self, x: np.ndarray, attn_gain: float = 1.0) -> Dict[str, any]:\n",
        "        gates_sparse, topk_idx_base, probs = await self.gating.forward(x, attn_gain=attn_gain)\n",
        "\n",
        "        # Use bandit gating if enabled\n",
        "        if self.use_bandit:\n",
        "            # Convert sparse gates to dense for bandit\n",
        "            gates_dense = np.zeros(len(self.names), dtype=np.float64)\n",
        "            for i, idx in enumerate(topk_idx_base):\n",
        "                gates_dense[int(idx)] = float(gates_sparse[i])\n",
        "\n",
        "            # Get bandit-selected experts\n",
        "            topk_idx, topk_gates = self.bandit.select_top_k(self.top_k, gates_dense)\n",
        "\n",
        "            # Update gates_sparse and topk_idx\n",
        "            gates_sparse = topk_gates\n",
        "            topk_idx = topk_idx\n",
        "        else:\n",
        "            topk_idx = topk_idx_base\n",
        "\n",
        "        chosen = [(self.names[i], float(gates_sparse[j])) for j, i in enumerate(topk_idx)]\n",
        "        y = 0.0; per_expert: Dict[str, Dict[str, float]] = {}\n",
        "        for j, i in enumerate(topk_idx):\n",
        "            name = self.names[int(i)]; gate = float(gates_sparse[j])\n",
        "            pred = float(self.experts[name].predict(x)); y += gate * pred\n",
        "            self.energy.add_macs(self.in_dim); per_expert[name] = {\"gate\": gate, \"pred\": pred}\n",
        "        return {'y_hat': float(y), 'topk': chosen, 'probs': probs, 'per_expert': per_expert,\n",
        "            'energy_j': self.energy.total_j + self.gating.energy.total_j}\n",
        "    async def learn(self, x: np.ndarray, token_ids: List[int], y_true: float,\n",
        "                    attn_gain: float = 1.0, attention_bundle: Optional[Dict[str, Any]] = None) -> Dict[str, any]:\n",
        "        out = await self.route(x, attn_gain=attn_gain); tasks = []\n",
        "        expert_errors = {}  # Track errors for bandit updates\n",
        "\n",
        "        for name, info in out['per_expert'].items():\n",
        "            gate = float(info['gate']);\n",
        "            if gate <= 0.0: continue\n",
        "            target = float(y_true)\n",
        "            pred = float(info['pred'])\n",
        "            error = abs(target - pred)\n",
        "            expert_errors[name] = error\n",
        "            tasks.append(self.experts[name].update(x, target, token_ids, attention_bundle))\n",
        "\n",
        "        await asyncio.gather(*tasks)\n",
        "\n",
        "        # Update bandit with expert performance\n",
        "        if self.use_bandit:\n",
        "            for name, error in expert_errors.items():\n",
        "                if name in self.names:\n",
        "                    expert_idx = self.names.index(name)\n",
        "                    self.bandit.update(expert_idx, error)\n",
        "\n",
        "        await self.gating.nudge_for_load_balance(); return out\n",
        "    def reset(self):\n",
        "        self.gating.reset()\n",
        "        self.energy.reset()\n",
        "        if self.use_bandit:\n",
        "            self.bandit.reset()\n",
        "    def state_dict(self) -> Dict:\n",
        "        expert_states = {name: expert.state_dict() for name, expert in self.experts.items()}\n",
        "        bandit_state = {\n",
        "            \"total_rewards\": self.bandit.total_rewards.tolist(),\n",
        "            \"selection_counts\": self.bandit.selection_counts.tolist(),\n",
        "            \"total_selections\": self.bandit.total_selections\n",
        "        } if self.use_bandit else None\n",
        "        return {\"gating\": self.gating.state_dict(), \"experts\": expert_states, \"bandit\": bandit_state}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.gating.load_state_dict(state[\"gating\"])\n",
        "        for name, expert_state in state[\"experts\"].items():\n",
        "            if name in self.experts: self.experts[name].load_state_dict(expert_state)\n",
        "        if self.use_bandit and \"bandit\" in state and state[\"bandit\"]:\n",
        "            bandit_state = state[\"bandit\"]\n",
        "            self.bandit.total_rewards = np.array(bandit_state[\"total_rewards\"])\n",
        "            self.bandit.selection_counts = np.array(bandit_state[\"selection_counts\"])\n",
        "            self.bandit.total_selections = bandit_state[\"total_selections\"]\n",
        "\n",
        "# --- 12. \"Temporal Mind\" ---\n",
        "class TemporalMemoryInterpolator:\n",
        "    def __init__(self, epsilon: float = 1e-12):\n",
        "        self.epsilon = epsilon\n",
        "        print(\"CREATED: TemporalMemoryInterpolator (Aura 7.0 Hippocampus)\")\n",
        "    def interpolate(self, M0: np.ndarray, M1: np.ndarray, t: float,\n",
        "                    mode: Literal['linear', 'fourier', 'hilbert', 'hamiltonian'] = 'hilbert'\n",
        "                   ) -> np.ndarray:\n",
        "        alpha = np.clip(t, 0.0, 1.0)\n",
        "        if mode == 'linear': return (1.0 - alpha) * M0 + alpha * M1\n",
        "        elif mode == 'fourier':\n",
        "            F0 = np.fft.fft(M0); F1 = np.fft.fft(M1)\n",
        "            F_interp = (1.0 - alpha) * F0 + alpha * F1\n",
        "            return np.real(np.fft.ifft(F_interp))\n",
        "        A0 = hilbert(M0, axis=0); A1 = hilbert(M1, axis=0)\n",
        "        if mode == 'hilbert':\n",
        "            A_interp = (1.0 - alpha) * A0 + alpha * A1\n",
        "            return np.real(A_interp)\n",
        "        elif mode == 'hamiltonian':\n",
        "            print(\"WARNING: Hamiltonian mode is computationally expensive.\")\n",
        "            A_diff = (A1 - A0).astype(np.complex128)\n",
        "            H_num = np.outer(A_diff, A_diff.T.conj())\n",
        "            H_den = np.linalg.norm(A_diff)**2 + self.epsilon\n",
        "            H = H_num / H_den; U = expm(-1j * H * alpha)\n",
        "            A_interp = U @ A0; return np.real(A_interp)\n",
        "        else: raise ValueError(f\"Unknown interpolation mode: {mode}\")\n",
        "\n",
        "# --- 13. CNS & ThalamicRouter (Trained) ---\n",
        "class ConsciousnessLevel(Enum):\n",
        "    DEEP_SLEEP = 0; ASLEEP = 1; ALERT = 2; FOCUSED = 3; HYPERVIGILANT = 4\n",
        "class CentralNervousSystem:\n",
        "    def __init__(self):\n",
        "        self.consciousness_level = ConsciousnessLevel.ALERT\n",
        "        self.stress_level = 0.0 # 'cortisol'\n",
        "        self.consolidation_factor = 1.0 # Reduces impact of errors after dreaming\n",
        "        print(\"CREATED: CentralNervousSystem (CNS)\")\n",
        "    def set_consciousness(self, level: ConsciousnessLevel):\n",
        "        if self.consciousness_level != level:\n",
        "            self.consciousness_level = level; print(f\"CNS: Consciousness set to {level.name}\")\n",
        "    def update_stress(self, error: float):\n",
        "        new_stress = abs(error) * 1.5 * self.consolidation_factor\n",
        "        self.stress_level = (self.stress_level * 0.5) + (new_stress * 0.5)\n",
        "        self.stress_level = max(0.0, self.stress_level - 0.1)\n",
        "        if self.stress_level > 1.0: self.set_consciousness(ConsciousnessLevel.HYPERVIGILANT)\n",
        "        else: self.set_consciousness(ConsciousnessLevel.ALERT)\n",
        "    def apply_consolidation(self, factor: float = 0.7):\n",
        "        \"\"\"Apply memory consolidation effect that reduces impact of future errors\"\"\"\n",
        "        self.consolidation_factor = factor\n",
        "\n",
        "    def get_endocrine_levels(self) -> Dict[str, float]:\n",
        "        \"\"\"Compute endocrine hormone levels from CNS state (for liquidmoe.py integration)\"\"\"\n",
        "        # Cortisol: stress level (0-1 maps to 0-2)\n",
        "        cortisol = min(2.0, self.stress_level * 2.0)\n",
        "\n",
        "        # Growth Hormone (GH): higher when learning (low stress, alert)\n",
        "        gh = 0.5 if self.consciousness_level == ConsciousnessLevel.ALERT else 0.0\n",
        "\n",
        "        # Thyroid: metabolic rate (higher when alert, lower when stressed)\n",
        "        thyroid = 1.0 - (self.stress_level * 0.3)  # 1.0 baseline, down to 0.7 when stressed\n",
        "\n",
        "        # Dopamine: reward signal (higher when stress is low and consciousness is alert)\n",
        "        dopamine = max(0.0, 1.0 - self.stress_level) if self.consciousness_level == ConsciousnessLevel.ALERT else 0.0\n",
        "\n",
        "        return {\n",
        "            'cortisol': cortisol,\n",
        "            'gh': gh,\n",
        "            'thyroid': thyroid,\n",
        "            'dopamine': dopamine\n",
        "        }\n",
        "class TrainedThalamicRouter:\n",
        "    \"\"\"The 'School' - runs the offline-trained PyTorch model\"\"\"\n",
        "    def __init__(self, model_path: str, label_maps: Dict, feature_gen: FeatureGenerator):\n",
        "        self.label_maps = label_maps\n",
        "        self.emotion_map = label_maps.get('emotion', {})\n",
        "        self.intent_map = label_maps.get('intent', {})\n",
        "        self.emotion_labels_inv = {v: k for k, v in self.emotion_map.items()}\n",
        "        self.feature_gen = feature_gen; self.model = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        try:\n",
        "            self.model = MultiTaskHead(\n",
        "                feature_gen.TOTAL_FEATURES,\n",
        "                len(self.emotion_map), len(self.intent_map), len(self.emotion_map) # Mock tone\n",
        "            ).to(self.device)\n",
        "            self.model.load_state_dict(torch.load(model_path))\n",
        "            self.model.eval()\n",
        "            print(f\"CREATED: TrainedThalamicRouter (Loaded from {model_path})\")\n",
        "        except Exception as e:\n",
        "            print(f\"--- âŒ ERROR: Failed to load ThalamicRouter model. {e} ---\")\n",
        "\n",
        "    def get_target_signals(self, query: str) -> dict:\n",
        "        if not self.model: return {'emotion': 0.0, 'intent': 0.0}\n",
        "        record = {\"text\": query, \"plutchik\": {\"primary\": \"neutral\"}}\n",
        "        sbert_vec = self.feature_gen.sbert_model.encode(query, normalize_embeddings=True)\n",
        "        # --- THE FIX: We must use use_emotion_sine=False ---\n",
        "        x_raw = self.feature_gen.build_features(record, sbert_vec, use_emotion_sine=False)\n",
        "        x_tensor = torch.tensor(x_raw, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            emo_logits, intent_logits, _ = self.model(x_tensor)\n",
        "            emo_pred_index = emo_logits.argmax(dim=1).item()\n",
        "            intent_pred_index = intent_logits.argmax(dim=1).item()\n",
        "        pred_label = self.emotion_labels_inv.get(emo_pred_index, 'neutral')\n",
        "        signals = {'emotion': float(emo_pred_index), 'intent': float(intent_pred_index)}\n",
        "        print(f\"Thalamus Predicted: '{pred_label}' (Index: {emo_pred_index})\")\n",
        "        return signals\n",
        "\n",
        "# --- 14. The Final IBNN (Aura 7.0 - Hebbian-MoE-Temporal) ---\n",
        "class IntegratedBioNeuralNetwork:\n",
        "    \"\"\"\n",
        "    Aura 7.0: Integrates all components into a persistent,\n",
        "    unsupervised-learning, and time-aware architecture.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_experts: int = 15, hebbian_components: int = 64,\n",
        "                 llm_model_name: str = \"meta-llama/Llama-3.2-3B-Instruct\"):\n",
        "        print(\"--- ðŸ§  Initializing Aura 7.0 (Hebbian-MoE-Temporal) ---\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"   -> GPU: {torch.cuda.get_device_name(0)}, VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
        "            maybe_empty_cuda_cache(\"startup\", min_free_ratio=0.05)\n",
        "        self.feature_gen = FeatureGenerator()\n",
        "        self.response_gen = ResponseGenerator(llm_model_name)\n",
        "        self.cns = CentralNervousSystem()\n",
        "        self.interpolator = TemporalMemoryInterpolator()\n",
        "        self.raw_feature_dim = self.feature_gen.TOTAL_FEATURES\n",
        "        self.vocab_size = self.feature_gen.vocab_size\n",
        "        self.abstract_feature_dim = hebbian_components\n",
        "\n",
        "        self.whitener: OptimizedWhitener = None\n",
        "        self.hippocampus: OjaLayer = None # Hebbian Cortex\n",
        "        self.cortex: LiquidMoERouter = None # MoE Cortex\n",
        "        self.router: Optional[TrainedThalamicRouter] = None\n",
        "        self.n_experts = n_experts\n",
        "        self.news_pattern_analyzer = None\n",
        "        self.timeline_analyzer = None\n",
        "        self.news_ingestion_service = None\n",
        "\n",
        "        self.education_dir = SAVE_DIR # Use global\n",
        "        os.makedirs(self.education_dir, exist_ok=True)\n",
        "        print(\"--- Aura 7.0 Brain Initialized (Awaiting Education) ---\")\n",
        "\n",
        "    def _create_brain_layers(self, hebbian_k: int):\n",
        "        \"\"\"Dynamically creates the brain layers based on the Hebbian cortex size.\"\"\"\n",
        "        self.abstract_feature_dim = hebbian_k\n",
        "        print(f\"--- ðŸ§  Building Dynamic Brain Layers ---\")\n",
        "        print(f\"   -> Hebbian Cortex (Oja) K = {hebbian_k}\")\n",
        "\n",
        "        self.hippocampus = OjaLayer(\n",
        "            dim=self.raw_feature_dim,\n",
        "            n_components=hebbian_k,\n",
        "            mode='nonlinear', lr=5e-3, max_components=128, grow_threshold=0.3\n",
        "        )\n",
        "        self.whitener = OptimizedWhitener(dim=self.raw_feature_dim)\n",
        "\n",
        "        experts: Dict[str, NLMSExpertAdapter] = {}\n",
        "        attention_config = {\n",
        "            'decay': 0.7,\n",
        "            'theta': 1.0,\n",
        "            'k_winners': 3,\n",
        "            'gain_up': 1.5,\n",
        "            'gain_down': 0.7,\n",
        "            'multi_channel': {\n",
        "                'k_winners': 5,\n",
        "                'w_amp': 1.0,\n",
        "                'w_pitch': 1.4,\n",
        "                'w_bound': 0.8,\n",
        "                'gain_up': 2.0,\n",
        "                'gain_down': 0.5,\n",
        "                'use_stdp': True,\n",
        "                'smoothing': 1,\n",
        "            }\n",
        "        }\n",
        "        num_emotions = len(GOEMOTIONS_LABELS)\n",
        "        emotion_range_per_expert = num_emotions / self.n_experts\n",
        "\n",
        "        for i in range(self.n_experts):\n",
        "            name = f\"expert__{i}\"\n",
        "            # Initialize bias toward expert's emotion range (0-27 for GoEmotions)\n",
        "            target_emotion_idx = i * emotion_range_per_expert + emotion_range_per_expert / 2\n",
        "            head = ExpertNLMSHead(\n",
        "                n_features=self.abstract_feature_dim,\n",
        "                vocab_size=self.vocab_size,\n",
        "                attention_config=attention_config,\n",
        "                mu=0.5,  # Even higher learning rate for faster convergence\n",
        "                mu_decay=0.99995,  # Very slow decay to maintain learning longer\n",
        "                mu_min=0.1,  # Higher minimum learning rate\n",
        "                initial_bias=target_emotion_idx  # Initialize bias to target range\n",
        "            )\n",
        "            # Initialize weights with larger random values for better coverage\n",
        "            head.w = np.random.normal(0, 1.0, self.abstract_feature_dim)\n",
        "            # Ensure bias is actually set (double-check)\n",
        "            head.bias = float(target_emotion_idx)\n",
        "            experts[name] = NLMSExpertAdapter(neuron=head)\n",
        "\n",
        "        self.cortex = LiquidMoERouter(\n",
        "            experts=experts, in_dim=self.abstract_feature_dim, # Use K\n",
        "            hidden_dim=128, top_k=3\n",
        "        )\n",
        "        print(f\"--- ðŸ§  Dynamic Brain Layers Created ---\")\n",
        "\n",
        "    async def educate_brain(self):\n",
        "        \"\"\"\n",
        "        Runs the 'School' pipeline to pre-train all components.\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"\\n--- ðŸŽ“ STARTING OFFLINE EDUCATION (GoEmotions) ---\")\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        # 1. Load GoEmotions\n",
        "        print(\"Loading 'google-research-datasets/go_emotions'...\")\n",
        "        dataset = load_dataset(\"google-research-datasets/go_emotions\", split='train')\n",
        "        dataset = dataset.shuffle(seed=42).select(range(5000))\n",
        "        all_texts = dataset['text']\n",
        "\n",
        "        # 2. Precompute SBERT\n",
        "        print(f\"Pre-computing SBERT embeddings for {len(all_texts)} texts...\")\n",
        "        sbert_embeddings = await asyncio.to_thread(\n",
        "            self.feature_gen.sbert_model.encode,\n",
        "            all_texts, normalize_embeddings=True, batch_size=256\n",
        "        )\n",
        "\n",
        "        # 3. Create Label Maps\n",
        "        emotion_labels = GOEMOTIONS_LABELS\n",
        "        intent_labels = [\"question\", \"statement\", \"exclamation\", \"request\", \"none\"]\n",
        "        tone_labels = emotion_labels # Mock\n",
        "        label_maps = {\n",
        "            'emotion': {label: idx for idx, label in enumerate(emotion_labels)},\n",
        "            'intent': {label: idx for idx, label in enumerate(intent_labels)},\n",
        "            'tone': {label: idx for idx, label in enumerate(tone_labels)},\n",
        "        }\n",
        "\n",
        "        # 4. Build Features\n",
        "        print(\"Building features...\")\n",
        "        X_features, y_emotion, y_intent, y_tone = [], [], [], []\n",
        "        for i, record in enumerate(dataset):\n",
        "            primary_emotion = 'neutral'\n",
        "            label_indices = record['labels']\n",
        "            if label_indices:\n",
        "                for idx in label_indices:\n",
        "                    if 0 <= idx < len(GOEMOTIONS_LABELS):\n",
        "                        label_name = GOEMOTIONS_LABELS[idx]\n",
        "                        if label_name != 'neutral':\n",
        "                            primary_emotion = label_name; break\n",
        "\n",
        "            mock_record = {\n",
        "                \"text\": record['text'],\n",
        "                \"plutchik\": {\"primary\": primary_emotion, \"intensity\": 1.0},\n",
        "                \"intent\": \"question\" if \"?\" in record['text'] else \"statement\",\n",
        "                \"tone\": primary_emotion\n",
        "            }\n",
        "            # --- THE FIX: Train Thalamus on \"neutral\" sine wave ---\n",
        "            X_features.append(self.feature_gen.build_features(mock_record, sbert_embeddings[i], use_emotion_sine=False))\n",
        "            y_emotion.append(label_maps['emotion'].get(primary_emotion, GOEMOTIONS_MAP['neutral']))\n",
        "            y_intent.append(label_maps['intent'].get(mock_record['intent'], 1))\n",
        "            y_tone.append(label_maps['tone'].get(primary_emotion, GOEMOTIONS_MAP['neutral']))\n",
        "\n",
        "        X_train_np = np.stack(X_features)\n",
        "        y_emotion_np = np.array(y_emotion)\n",
        "\n",
        "        indices = np.arange(len(X_train_np))\n",
        "        X_train_split, X_test_split, y_emotion_train_split, y_emotion_test_split, \\\n",
        "        y_intent_train_split, y_intent_test_split, y_tone_train_split, y_tone_test_split = \\\n",
        "            train_test_split(X_train_np, y_emotion_np, y_intent, y_tone, test_size=0.2, random_state=42, stratify=y_emotion_np)\n",
        "\n",
        "        X_train_torch = torch.tensor(X_train_split, dtype=torch.float32).to(device)\n",
        "        y_emotion_train_torch = torch.tensor(y_emotion_train_split, dtype=torch.long).to(device)\n",
        "        y_intent_train_torch = torch.tensor(y_intent_train_split, dtype=torch.long).to(device)\n",
        "        y_tone_train_torch = torch.tensor(y_tone_train_split, dtype=torch.long).to(device)\n",
        "\n",
        "        X_test_torch = torch.tensor(X_test_split, dtype=torch.float32).to(device)\n",
        "        y_emotion_test_torch = torch.tensor(y_emotion_test_split, dtype=torch.long).to(device)\n",
        "        y_intent_test_torch = torch.tensor(y_intent_test_split, dtype=torch.long).to(device)\n",
        "        y_tone_test_torch = torch.tensor(y_tone_test_split, dtype=torch.long).to(device)\n",
        "\n",
        "        # --- 5. Train the \"Hebbian Cortex\" (OjaLayer) ---\n",
        "        print(\"Training Hebbian Cortex (OjaLayer) on whitened data...\")\n",
        "        self._create_brain_layers(hebbian_k=self.abstract_feature_dim)\n",
        "\n",
        "        # Note: We train Oja on the *real* features, with sine waves\n",
        "        print(\"Building full features for Hebbian training...\")\n",
        "        X_features_hebbian = []\n",
        "        for i, record in enumerate(dataset): # Using the full dataset\n",
        "            primary_emotion = 'neutral'\n",
        "            label_indices = record['labels']\n",
        "            if label_indices:\n",
        "                for idx in label_indices:\n",
        "                    if 0 <= idx < len(GOEMOTIONS_LABELS):\n",
        "                        label_name = GOEMOTIONS_LABELS[idx]\n",
        "                        if label_name != 'neutral':\n",
        "                            primary_emotion = label_name; break\n",
        "            mock_record = {\"text\": record['text'], \"plutchik\": {\"primary\": primary_emotion, \"intensity\": 1.0}}\n",
        "            # We use use_emotion_sine=True (default) for Hebbian layer\n",
        "            X_features_hebbian.append(self.feature_gen.build_features(mock_record, sbert_embeddings[i], use_emotion_sine=True))\n",
        "\n",
        "        X_train_np_hebbian = np.stack(X_features_hebbian)\n",
        "        X_features_whitened = np.array([self.feature_gen.whitener.transform(x) for x in X_train_np_hebbian])\n",
        "\n",
        "        for x_w in X_features_whitened:\n",
        "             self.hippocampus.step(x_w)\n",
        "\n",
        "        final_k = self.hippocampus.K\n",
        "        if final_k != self.abstract_feature_dim:\n",
        "            print(f\"Hebbian Cortex grew from {self.abstract_feature_dim} to {final_k}. Rebuilding MoE...\")\n",
        "            self._create_brain_layers(hebbian_k=final_k)\n",
        "\n",
        "        print(f\"   -> Hebbian Cortex (OjaLayer) training complete. Final K={final_k}\")\n",
        "\n",
        "        # --- 6. Train the \"Thalamus\" (MultiTaskHead) ---\n",
        "        print(f\"Training MultiTask ThalamicRouter...\")\n",
        "        class_weights_emotion = compute_class_weight('balanced', classes=np.unique(y_emotion_train_split), y=y_emotion_train_split)\n",
        "        class_weights_emotion = torch.tensor(class_weights_emotion, dtype=torch.float32).to(device)\n",
        "\n",
        "        thalamus_model = MultiTaskHead(\n",
        "            self.feature_gen.TOTAL_FEATURES,\n",
        "            len(label_maps['emotion']), len(label_maps['intent']), len(label_maps['tone'])\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = optim.AdamW(thalamus_model.parameters(), lr=1e-3)\n",
        "        criterion_emotion = nn.CrossEntropyLoss(weight=class_weights_emotion)\n",
        "        criterion_intent = nn.CrossEntropyLoss()\n",
        "        criterion_tone = nn.CrossEntropyLoss(weight=class_weights_emotion)\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        epochs_no_improve = 0\n",
        "        patience = 100\n",
        "\n",
        "        for epoch in range(300):\n",
        "            thalamus_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            emo_out, intent_out, tone_out = thalamus_model(X_train_torch)\n",
        "            loss = (1.0 * criterion_emotion(emo_out, y_emotion_train_torch) +\n",
        "                    0.5 * criterion_intent(intent_out, y_intent_train_torch) +\n",
        "                    0.5 * criterion_tone(tone_out, y_tone_train_torch))\n",
        "            loss.backward(); optimizer.step()\n",
        "\n",
        "            thalamus_model.eval()\n",
        "            with torch.no_grad():\n",
        "                emo_val, intent_val, tone_val = thalamus_model(X_test_torch)\n",
        "                val_loss = (1.0 * criterion_emotion(emo_val, y_emotion_test_torch) +\n",
        "                            0.5 * criterion_intent(intent_val, y_intent_test_torch) +\n",
        "                            0.5 * criterion_tone(tone_val, y_tone_test_torch))\n",
        "\n",
        "            print(f\"Epoch {epoch+1:02d}/30 | Train Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                epochs_no_improve = 1\n",
        "                thalamus_path = os.path.join(self.education_dir, \"thalamic_router_multitask.pt\")\n",
        "                torch.save(thalamus_model.state_dict(), thalamus_path)\n",
        "                print(f\"   -> New best model saved to {thalamus_path}\")\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "                if epochs_no_improve >= patience:\n",
        "                    print(f\"   -> Early stopping on epoch {epoch+1}.\")\n",
        "                    break\n",
        "\n",
        "        # --- 7. \"Mind Upload\" - Initialize Router ---\n",
        "        self.router = TrainedThalamicRouter(thalamus_path, label_maps, self.feature_gen)\n",
        "        print(\"--- ðŸŽ“ OFFLINE EDUCATION COMPLETE ---\")\n",
        "\n",
        "    async def process_query(self, query: str, update_stress: bool = True) -> str:\n",
        "        print(f\"\\n--- â˜€ï¸ PROCESSING QUERY (Aura 7.0): '{query}' ---\")\n",
        "        if not self.router: return \"I am uneducated. Please run `await aura.educate_brain()`.\"\n",
        "\n",
        "        cns_level = self.cns.consciousness_level\n",
        "\n",
        "        # 1. \"Ears\" -> \"Hebbian Cortex\"\n",
        "        # The Hebbian layer *can* see the emotional sine wave, as it's part of the raw sensory context\n",
        "        x_raw, token_ids, attention_bundle = self.feature_gen.generate_for_query(query)\n",
        "        xw = self.feature_gen.whitener.transform(x_raw)\n",
        "        oja_out = self.hippocampus.step(xw)\n",
        "        y_abstract = oja_out.y # The abstract \"engram\"\n",
        "\n",
        "        # 2. \"Thalamus\" (Educated)\n",
        "        # The Thalamus *must not* see the sine wave it's trying to predict.\n",
        "        target_signals = self.router.get_target_signals(query)\n",
        "        y_true_emotion_idx = target_signals['emotion']\n",
        "\n",
        "        # The MoE experts learn to map the *abstract engram* to the *Thalamus's target*\n",
        "        target_for_moe = float(y_true_emotion_idx)\n",
        "\n",
        "        out = await self.cortex.learn(\n",
        "            x=y_abstract, token_ids=token_ids, y_true=target_for_moe, attention_bundle=attention_bundle\n",
        "        )\n",
        "\n",
        "        # 4. \"CNS\" (Feeling)\n",
        "        raw_prediction = out['y_hat']\n",
        "        moe_idx, discrete_prediction = quantize_moe_prediction(raw_prediction, NUM_GOEMOTIONS)\n",
        "        prediction_error = target_for_moe - discrete_prediction\n",
        "        if update_stress:\n",
        "            self.cns.update_stress(prediction_error)\n",
        "            # Apply endocrine modulation to gating network (from liquidmoe.py)\n",
        "            endocrine_levels = self.cns.get_endocrine_levels()\n",
        "            await self.cortex.gating.apply_endocrine(**endocrine_levels)\n",
        "\n",
        "        print(f\"Hebbian (Oja) Residual: {oja_out.residual_ema:.3f} (Grew: {oja_out.grew})\")\n",
        "        print(f\"MoE Prediction: idx={moe_idx} (raw={raw_prediction:.2f}), Target: {int(target_for_moe)}, Error: {abs(prediction_error):.2f}\")\n",
        "\n",
        "        # Diagnostic: Show top expert contributions\n",
        "        if 'topk' in out and len(out['topk']) > 0:\n",
        "            top_expert = out['topk'][0]\n",
        "            expert_name, expert_gate = top_expert\n",
        "            expert_neuron = self.cortex.experts[expert_name].neuron\n",
        "            expert_rmse = expert_neuron.get_rmse()\n",
        "            expert_lr = expert_neuron.mu\n",
        "            print(f\"   -> Top Expert: {expert_name} (gate={expert_gate:.3f}, RMSE={expert_rmse:.2f}, LR={expert_lr:.4f})\")\n",
        "\n",
        "        # 5. \"Mouth\" speaks\n",
        "        final_brain_state = {\n",
        "            'cns_state': self.cns.consciousness_level,\n",
        "            'stress_level': self.cns.stress_level,\n",
        "        }\n",
        "        response = await self.response_gen.generate_response(query, final_brain_state)\n",
        "        self.last_run_final_stress = self.cns.stress_level\n",
        "        return response\n",
        "\n",
        "    async def process_live_news(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Ingest news articles and optionally update pattern analyzers.\"\"\"\n",
        "        if not articles:\n",
        "            return []\n",
        "        if not self.router or not self.cortex:\n",
        "            print(\"[WARN] Cannot process news articles before education.\")\n",
        "            return []\n",
        "        if self.news_pattern_analyzer is None:\n",
        "            self.news_pattern_analyzer = NewsPatternAnalyzer()\n",
        "        if self.news_ingestion_service is None:\n",
        "            self.news_ingestion_service = NewsIngestionService(pattern_analyzer=self.news_pattern_analyzer)\n",
        "        return await self.news_ingestion_service.process_articles(self, articles)\n",
        "\n",
        "    def summarize_news_trends(self, topic: str = \"general\") -> Dict[str, Any]:\n",
        "        if not self.news_pattern_analyzer:\n",
        "            return {}\n",
        "        return self.news_pattern_analyzer.summarize_topic(topic)\n",
        "\n",
        "    def register_historical_timeline(self, entity: str, events: List[Dict[str, Any]]):\n",
        "        if self.timeline_analyzer is None:\n",
        "            self.timeline_analyzer = HistoricalTimelineAnalyzer()\n",
        "        self.timeline_analyzer.register_entity(entity, events)\n",
        "\n",
        "    def compare_historical_pattern(self, query: str, window: int = 5) -> Dict[str, Any]:\n",
        "        if not self.timeline_analyzer:\n",
        "            return {}\n",
        "        return self.timeline_analyzer.compare_pattern(query, window=window)\n",
        "\n",
        "    def get_moe_statistics(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get diagnostic statistics about MoE experts\"\"\"\n",
        "        stats = {\n",
        "            'expert_count': len(self.cortex.experts),\n",
        "            'experts': {}\n",
        "        }\n",
        "        for name, expert_adapter in self.cortex.experts.items():\n",
        "            neuron = expert_adapter.neuron\n",
        "            stats['experts'][name] = {\n",
        "                'rmse': neuron.get_rmse(),\n",
        "                'learning_rate': neuron.mu,\n",
        "                'update_count': neuron.update_count,\n",
        "                'last_error': neuron.last_error\n",
        "            }\n",
        "        return stats\n",
        "\n",
        "    def _get_brain_state_vector(self) -> np.ndarray:\n",
        "        all_weights = []\n",
        "        all_weights.append(self.feature_gen.whitener.mu.flatten())\n",
        "        all_weights.append(self.feature_gen.whitener.var.flatten())\n",
        "        all_weights.append(self.hippocampus.W.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.W.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.U.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.b.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.V.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.c.flatten())\n",
        "        all_weights.append(self.cortex.gating.Wg.flatten())\n",
        "        all_weights.append(self.cortex.gating.bg.flatten())\n",
        "        for expert in self.cortex.experts.values():\n",
        "            all_weights.append(expert.neuron.w.flatten())\n",
        "        return np.concatenate(all_weights)\n",
        "\n",
        "    def _load_brain_state_vector(self, M: np.ndarray):\n",
        "        print(\"--- ðŸ§  Loading brain state from vector... ---\")\n",
        "        idx = 0\n",
        "        def _load(target_array: np.ndarray) -> int:\n",
        "            nonlocal idx\n",
        "            n = target_array.size\n",
        "            try:\n",
        "                target_array[:] = M[idx : idx + n].reshape(target_array.shape)\n",
        "            except ValueError:\n",
        "                print(f\"!! Shape mismatch during load. Target: {target_array.shape}, Got: {M[idx : idx + n].shape}\")\n",
        "                min_n = min(target_array.size, M[idx:].size)\n",
        "                if min_n == 0: return idx\n",
        "                target_flat = target_array.flat; source_flat = M[idx:].flat\n",
        "                for i in range(min_n): target_flat[i] = source_flat[i]\n",
        "                n = min_n\n",
        "            return idx + n\n",
        "        try:\n",
        "            idx = _load(self.feature_gen.whitener.mu)\n",
        "            idx = _load(self.feature_gen.whitener.var)\n",
        "            idx = _load(self.hippocampus.W)\n",
        "            idx = _load(self.cortex.gating.cell.W)\n",
        "            idx = _load(self.cortex.gating.cell.U)\n",
        "            idx = _load(self.cortex.gating.cell.b)\n",
        "            idx = _load(self.cortex.gating.cell.V)\n",
        "            idx = _load(self.cortex.gating.cell.c)\n",
        "            idx = _load(self.cortex.gating.Wg)\n",
        "            idx = _load(self.cortex.gating.bg)\n",
        "            for expert in self.cortex.experts.values():\n",
        "                idx = _load(expert.neuron.w)\n",
        "            print(f\"--- ðŸ§  Brain state loaded successfully. Total params: {idx} ---\")\n",
        "        except Exception as e:\n",
        "            print(f\"--- âŒ ERROR: Failed to load brain state vector. {e} ---\")\n",
        "\n",
        "    async def save_keyframe(self, name: str):\n",
        "        path = os.path.join(self.education_dir, f\"keyframe_{name}_{int(time.time())}.npy\")\n",
        "        print(f\"\\n--- ðŸ’¾ Saving keyframe to {path} ---\")\n",
        "        M = self._get_brain_state_vector()\n",
        "        await asyncio.to_thread(np.save, path, M)\n",
        "        print(\"--- ðŸ’¾ Keyframe save complete ---\")\n",
        "\n",
        "    async def run_sleep_cycle(self, keyframe1_name: str, keyframe2_name: str):\n",
        "        \"\"\"\n",
        "        Implements \"Dream Recall\" from the paper.\n",
        "        Consolidates memories and reduces stress through dream interpolation.\n",
        "        \"\"\"\n",
        "        print(f\"\\n--- ðŸ’¤ RUNNING SLEEP CYCLE (Dreaming) ---\")\n",
        "        print(f\"Loading keyframes: {keyframe1_name} and {keyframe2_name}\")\n",
        "        try:\n",
        "            M0_path = sorted(glob.glob(os.path.join(self.education_dir, f\"keyframe_{keyframe1_name}*.npy\")))[-1]\n",
        "            M1_path = sorted(glob.glob(os.path.join(self.education_dir, f\"keyframe_{keyframe2_name}*.npy\")))[-1]\n",
        "            M0 = np.load(M0_path)\n",
        "            M1 = np.load(M1_path)\n",
        "        except Exception as e:\n",
        "            print(f\"--- âŒ ERROR: Could not load keyframes for dreaming. {e} ---\"); return\n",
        "\n",
        "        current_brain_shape = self._get_brain_state_vector().shape\n",
        "        if M0.shape != M1.shape or M0.shape != current_brain_shape:\n",
        "            print(f\"--- âŒ ERROR: Keyframe dimension mismatch. Cannot interpolate. ---\")\n",
        "            print(f\"M0: {M0.shape}, M1: {M1.shape}, Current: {current_brain_shape}\"); return\n",
        "\n",
        "        stress_before_dream = self.cns.stress_level\n",
        "\n",
        "        print(\"...Interpolating dream state using Hilbert (phase-aware) interpolation...\")\n",
        "        # Use multiple interpolation points for richer consolidation\n",
        "        interpolation_points = [0.25, 0.5, 0.75]\n",
        "        M_dreams = []\n",
        "        for t in interpolation_points:\n",
        "            M_dream = self.interpolator.interpolate(M0, M1, t=t, mode='hilbert')\n",
        "            M_dreams.append(M_dream)\n",
        "\n",
        "        # Average the interpolated states for smoother consolidation\n",
        "        M_consolidated = np.mean(M_dreams, axis=0)\n",
        "        self._load_brain_state_vector(M_consolidated)\n",
        "\n",
        "        print(\"...Consolidating dream state (multiple interpolation points)...\")\n",
        "        # Process multiple dream queries for better consolidation\n",
        "        dream_queries = [\"... (dreaming) ...\", \"... (memory consolidation) ...\", \"... (neural replay) ...\"]\n",
        "        for dream_query in dream_queries:\n",
        "            await self.process_query(dream_query, update_stress=False)\n",
        "\n",
        "        stress_after_consolidation = self.cns.stress_level\n",
        "        stress_reduction_factor = 0.25\n",
        "        stress_reduction = max(0.0, stress_before_dream * stress_reduction_factor)\n",
        "        self.cns.stress_level = max(0.0, stress_after_consolidation - stress_reduction)\n",
        "\n",
        "        self.cns.apply_consolidation(factor=0.7)\n",
        "\n",
        "        if self.cns.stress_level < 1.0:\n",
        "            self.cns.set_consciousness(ConsciousnessLevel.ALERT)\n",
        "\n",
        "        print(f\"--- ðŸ’¤ SLEEP CYCLE COMPLETE (Stress reduced by {stress_reduction:.4f}, from {stress_before_dream:.4f} to {self.cns.stress_level:.4f}, consolidation factor: {self.cns.consolidation_factor:.2f}) ---\")\n",
        "\n",
        "# --- 15. PyTorch Models (for the \"School\") ---\n",
        "class LinearTorchModel(nn.Module):\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, input_dim: int, num_classes: int):\n",
        "        super().__init__(); self.fc = nn.Linear(input_dim, num_classes)\n",
        "    def forward(self, x): return self.fc(x)\n",
        "# --- All Imports ---\n",
        "import uuid\n",
        "import enum\n",
        "from enum import Enum # Explicit import\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import itertools\n",
        "import torch\n",
        "from transformers import AutoTokenizer, logging\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "from unsloth import FastLanguageModel\n",
        "from typing import List, Dict, Optional, Union, Any, Tuple, Literal # Explicit imports\n",
        "from dataclasses import dataclass, field\n",
        "from abc import ABC, abstractmethod\n",
        "from numpy import ndarray\n",
        "import asyncio\n",
        "import io\n",
        "import csv\n",
        "import threading # For Memory Pool\n",
        "import time\n",
        "from scipy.signal import hilbert # For Temporal Interpolator\n",
        "from scipy.linalg import expm # For Temporal Interpolator\n",
        "import glob # For finding latest keyframe\n",
        "from datasets import load_dataset # For GoEmotions\n",
        "\n",
        "# --- PyTorch Imports (for Pre-Training) ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Suppress transformer warnings\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "# --- 0. Colab/HF Login ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN, add_to_git_credential=False)\n",
        "    print(\"Hugging Face login successful!\")\n",
        "except (ImportError, KeyError):\n",
        "    print(\"HF_TOKEN secret not found or not in Colab. Ensure you are logged in.\")\n",
        "\n",
        "# --- 1. Helper Functions (Softplus, Tanh, Softmax) ---\n",
        "def softplus(z: np.ndarray) -> np.ndarray:\n",
        "    return np.log1p(np.exp(-np.abs(z))) + np.maximum(z, 0)\n",
        "def tanh(z: np.ndarray) -> np.ndarray:\n",
        "    return np.tanh(z)\n",
        "def softmax(z: np.ndarray, temp: float = 1.0) -> np.ndarray:\n",
        "    z = z / max(1e-8, temp); z = z - np.max(z); ez = np.exp(z)\n",
        "    s = ez.sum(); return ez / (s + 1e-12)\n",
        "\n",
        "# --- 2. EnergyMeter ---\n",
        "@dataclass\n",
        "class EnergyMeter:\n",
        "    e_mac_j: float = 3e-12; total_j: float = 0.0\n",
        "    def add_macs(self, nmacs: int): self.total_j += self.e_mac_j * float(nmacs)\n",
        "\n",
        "# --- 3. Memory Pool (from memory_pool.py) ---\n",
        "@dataclass\n",
        "class PoolStats:\n",
        "    hits: int = 0; misses: int = 0; total_allocations: int = 0; peak_usage_mb: float = 0.0\n",
        "class ArrayPool:\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, max_pool_size_mb: int = 512):\n",
        "        self.max_pool_size = max_pool_size_mb * 1024 * 1024\n",
        "        self.pools: Dict[Tuple[tuple, np.dtype], List[np.ndarray]] = {}\n",
        "        self.current_usage = 0; self.stats = PoolStats(); self._lock = threading.Lock()\n",
        "    def get_array(self, shape: tuple, dtype: np.dtype = np.float32, zero_fill: bool = True) -> np.ndarray:\n",
        "        key = (shape, dtype)\n",
        "        with self._lock:\n",
        "            if key in self.pools and self.pools[key]:\n",
        "                arr = self.pools[key].pop(); self.stats.hits += 1\n",
        "                if zero_fill: arr.fill(0); return arr\n",
        "            else:\n",
        "                arr = np.empty(shape, dtype=dtype);\n",
        "                if zero_fill: arr.fill(0)\n",
        "                self.stats.misses += 1; self.stats.total_allocations += 1; return arr\n",
        "    def return_array(self, arr: np.ndarray) -> None:\n",
        "        if arr is None: return\n",
        "        key = (arr.shape, arr.dtype); array_size = arr.nbytes\n",
        "        with self._lock:\n",
        "            if self.current_usage + array_size <= self.max_pool_size:\n",
        "                if key not in self.pools: self.pools[key] = []\n",
        "                arr.fill(0); self.pools[key].append(arr); self.current_usage += array_size\n",
        "_global_pool = ArrayPool()\n",
        "def get_pooled_array(shape: tuple, dtype: np.dtype = np.float32, zero_fill: bool = True) -> np.ndarray:\n",
        "    return _global_pool.get_array(shape, dtype, zero_fill)\n",
        "def return_pooled_array(arr: np.ndarray) -> None:\n",
        "    _global_pool.return_array(arr)\n",
        "\n",
        "# --- 4. Optimized Whitener (from training_coordinator_optimized.py) ---\n",
        "class OptimizedWhitener:\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, dim: int, eps: float = 1e-6, momentum: float = 0.01):\n",
        "        self.dim = dim; self.eps = np.float32(eps); self.momentum = np.float32(momentum)\n",
        "        self.mu = np.zeros(dim, dtype=np.float32); self.var = np.ones(dim, dtype=np.float32)\n",
        "        self._temp_diff = np.zeros(dim, dtype=np.float32)\n",
        "        self._temp_result = np.zeros(dim, dtype=np.float32)\n",
        "    def transform(self, x: np.ndarray) -> np.ndarray:\n",
        "        if x.dtype != np.float32: x = x.astype(np.float32)\n",
        "        self.mu *= (1.0 - self.momentum); self.mu += self.momentum * x\n",
        "        np.subtract(x, self.mu, out=self._temp_diff)\n",
        "        np.multiply(self._temp_diff, self._temp_diff, out=self._temp_result)\n",
        "        self.var *= (1.0 - self.momentum); self.var += self.momentum * self._temp_result\n",
        "        np.sqrt(self.var + self.eps, out=self._temp_result)\n",
        "        np.divide(self._temp_diff, self._temp_result, out=self._temp_result)\n",
        "        return self._temp_result.copy()\n",
        "    def state_dict(self) -> Dict: return {\"mu\": self.mu, \"var\": self.var}\n",
        "    def load_state_dict(self, state: Dict): self.mu = state[\"mu\"]; self.var = state[\"var\"]\n",
        "\n",
        "# --- 5. GoEmotions Labels (The Curriculum) ---\n",
        "GOEMOTIONS_LABELS = [\n",
        "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
        "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
        "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
        "    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
        "    'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
        "]\n",
        "GOEMOTIONS_MAP = {label: idx for idx, label in enumerate(GOEMOTIONS_LABELS)}\n",
        "\n",
        "# --- 6. \"Ears\": FeatureGenerator (GoEmotions-Aware) ---\n",
        "class FeatureGenerator:\n",
        "    \"\"\"Based on clean_amygdala_trainer.py\"\"\"\n",
        "    def __init__(self, sbert_model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "        self.SBERT_DIM = 384; self.SINE_LENGTH = 32; self.EXTRA_FEATURES = 3\n",
        "        self.TOTAL_FEATURES = self.SBERT_DIM + self.SINE_LENGTH + self.EXTRA_FEATURES # 419\n",
        "        print(f\"CREATED: FeatureGenerator (Aura 7.0 Ears), Features: {self.TOTAL_FEATURES}\")\n",
        "        self.sbert_model = SentenceTransformer(sbert_model_name, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.tokenizer = self.sbert_model.tokenizer\n",
        "        self.vocab_size = self.tokenizer.vocab_size\n",
        "        self.label_params = self._generate_default_params(GOEMOTIONS_LABELS)\n",
        "        self.whitener = OptimizedWhitener(dim=self.TOTAL_FEATURES)\n",
        "\n",
        "    def _generate_default_params(self, labels: List[str]) -> Dict[str, Dict]:\n",
        "        params = {}\n",
        "        for idx, label in enumerate(labels):\n",
        "            params[label] = {\"freq\": 1.5 + 0.1 * idx, \"amp\": 0.7, \"phase\": 0.5 + 0.2 * idx}\n",
        "        return params\n",
        "\n",
        "    def build_features(self, record: Dict[str, Any], sbert_vec: np.ndarray, use_emotion_sine: bool = True) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Build fused features.\n",
        "        use_emotion_sine=False forces a neutral sine wave, preventing data leakage.\n",
        "        \"\"\"\n",
        "        if use_emotion_sine:\n",
        "            prim = record.get(\"plutchik\", {}).get(\"primary\", \"neutral\")\n",
        "        else:\n",
        "            prim = \"neutral\" # <-- THE FIX\n",
        "\n",
        "        cfg = self.label_params.get(prim, {\"freq\": 1.0, \"amp\": 0.0, \"phase\": 0.0})\n",
        "        t = np.linspace(0, 2*np.pi, self.SINE_LENGTH, dtype=np.float32)\n",
        "        emb = (cfg[\"amp\"] * np.sin(cfg[\"freq\"] * t + cfg[\"phase\"])).astype(np.float32)\n",
        "        text = record.get(\"text\", \"\")\n",
        "        extras = np.array([len(text) / 100.0, int(\"!\" in text), int(\"?\" in text)], dtype=np.float32)\n",
        "        return np.concatenate([emb, extras, sbert_vec]).astype(np.float32)\n",
        "\n",
        "    def _build_attention_bundle(self, text: str) -> Dict[str, Any]:\n",
        "        tokens = simple_tokenize_for_attention(text.lower())\n",
        "        amp, pitch, boundary = prosody_channels_from_text(tokens)\n",
        "        token_ids = [hash(tok) % self.vocab_size for tok in tokens]\n",
        "        return {\n",
        "            'token_ids': token_ids,\n",
        "            'amp': amp,\n",
        "            'pitch': pitch,\n",
        "            'boundary': boundary,\n",
        "            'raw_tokens': tokens,\n",
        "        }\n",
        "\n",
        "    def generate_for_query(self, query: str, thalamus_prediction: str = 'neutral') -> Tuple[np.ndarray, List[int], Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Generates feature vector for a LIVE query.\n",
        "        It now uses the Thalamus's prediction to build the sine wave.\n",
        "        \"\"\"\n",
        "        record = {\"text\": query, \"plutchik\": {\"primary\": thalamus_prediction}}\n",
        "        sbert_vec = self.sbert_model.encode(query, normalize_embeddings=True)\n",
        "        # We use use_emotion_sine=True (default) for the live brain\n",
        "        x_raw = self.build_features(record, sbert_vec, use_emotion_sine=True)\n",
        "        x_whitened = self.whitener.transform(x_raw)\n",
        "        attention_bundle = self._build_attention_bundle(query)\n",
        "        token_ids = attention_bundle['token_ids']\n",
        "        return x_whitened, token_ids, attention_bundle\n",
        "\n",
        "    def state_dict(self) -> Dict: return {\"whitener_mu\": self.whitener.mu, \"whitener_var\": self.whitener.var}\n",
        "    def load_state_dict(self, state: Dict): self.whitener.mu = state[\"mu\"]; self.whitener.var = state[\"var\"]\n",
        "\n",
        "# --- 7. \"Mouth\": ResponseGenerator (Unsloth, Async) ---\n",
        "class ResponseGenerator:\n",
        "    def __init__(self, model_name: str = \"meta-llama/Llama-3.2-3B-Instruct\"):\n",
        "        print(f\"CREATED: ResponseGenerator (Mouth) using Unsloth on '{model_name}'\")\n",
        "        max_seq_length = 2048; dtype = None; load_in_4bit = True\n",
        "        unsloth_model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\n",
        "        print(f\"   -> Using optimized Unsloth 4-bit model: {unsloth_model_name}\")\n",
        "        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_name = unsloth_model_name, max_seq_length = max_seq_length,\n",
        "            dtype = dtype, load_in_4bit = load_in_4bit,\n",
        "        )\n",
        "        if self.tokenizer.pad_token is None: self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "        print(\"   -> Unsloth Llama 3.2 model loaded successfully.\")\n",
        "    def _build_prompt(self, user_query: str, brain_state: dict) -> str:\n",
        "        cns_state = brain_state.get('cns_state', 'ALERT').name\n",
        "        stress = brain_state.get('stress_level', 0.0)\n",
        "        persona = f\"You are Aura, a bio-neural AI. Your current internal state is {cns_state}.\"\n",
        "        if cns_state == 'HYPERVIGILANT' or stress > 1.0:\n",
        "            persona += f\" You are feeling a high-stress level ({stress:.2f}).\"\n",
        "        else: persona += \" You are calm and helpful.\"\n",
        "        messages = [{\"role\": \"system\", \"content\": persona}, {\"role\": \"user\", \"content\": user_query}]\n",
        "        return self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    async def generate_response(self, user_query: str, brain_state: dict) -> str:\n",
        "        print(f\"\\n--- ðŸ‘„ ResponseGenerator (Unsloth) ---\"); print(f\"Generating response. Brain state: {brain_state}\")\n",
        "        prompt = self._build_prompt(user_query, brain_state)\n",
        "        inputs = self.tokenizer([prompt], return_tensors=\"pt\", padding=True, truncation=True, max_length=1024).to(\"cuda\")\n",
        "        terminators = [self.tokenizer.eos_token_id, self.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
        "        outputs = await asyncio.to_thread(\n",
        "            self.model.generate, **inputs, max_new_tokens=150, eos_token_id=terminators,\n",
        "            do_sample=True, temperature=0.7, top_p=0.9,\n",
        "        )\n",
        "        response_text = self.tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[-1]:], skip_special_tokens=True)[0]\n",
        "        print(f\"Llama 3.2 (Unsloth) Output: {response_text}\"); return response_text\n",
        "\n",
        "# --- 8. SpikingAttention (k-WTA) ---\n",
        "@dataclass\n",
        "class SpikingAttention:\n",
        "    decay: float = 0.7; theta: float = 1.0; k_winners: int = 5\n",
        "    gain_up: float = 1.5; gain_down: float = 0.6\n",
        "    def compute_gains(self, token_seq: List[int], vocab_size: int) -> Optional[np.ndarray]:\n",
        "        if not token_seq: return None\n",
        "        v: Dict[int, float] = {}; spikes: Dict[int, int] = {}\n",
        "        for j in token_seq:\n",
        "            vj = self.decay * v.get(j, 0.0) + 1.0\n",
        "            if vj >= self.theta: spikes[j] = spikes.get(j, 0) + 1; vj -= self.theta\n",
        "            v[j] = vj\n",
        "        ranked = sorted(spikes.items(), key=lambda kv: (-kv[1], -v.get(kv[0], 0.0)))\n",
        "        winners = set(j for j,_ in ranked[:max(1, self.k_winners)])\n",
        "        gains = np.ones(vocab_size, dtype=np.float64)\n",
        "        seen = set(spikes.keys()) | set(v.keys())\n",
        "        for j in seen:\n",
        "            if 0 <= j < vocab_size: gains[j] = self.gain_up if j in winners else self.gain_down\n",
        "        return gains\n",
        "\n",
        "# --- 9. Hebbian Layer (Oja) ---\n",
        "@dataclass\n",
        "class OjaStepOut:\n",
        "    y: np.ndarray; residual_ema: float; grew: bool\n",
        "class OjaLayer:\n",
        "    def __init__(self, dim: int, n_components: int = 8, lr: float = 5e-4, mode: str = \"nonlinear\",\n",
        "                 *, max_components: int = 64, lateral_beta: float = 0.05,\n",
        "                 grow_threshold: float = 0.35, ema: float = 0.01, grow_cooldown: int = 100,\n",
        "                 seed: Optional[int] = 1337):\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self.dim = int(dim); self.lr = float(lr); self.mode = str(mode)\n",
        "        self.max_components = int(max_components); self.beta = float(lateral_beta)\n",
        "        self.grow_threshold = float(grow_threshold); self.ema = float(ema)\n",
        "        self.grow_cooldown = int(grow_cooldown); self.cooldown = 0\n",
        "        W0 = self.rng.normal(0, 0.1, (n_components, self.dim))\n",
        "        self.W = (W0.T / (np.linalg.norm(W0, axis=1) + 1e-12)).T\n",
        "        self.K = self.W.shape[0]; self.residual_ema = 0.0; self._steps = 0\n",
        "        print(f\"CREATED: OjaLayer (Hebbian Cortex) with {self.K} components, mode='{self.mode}'\")\n",
        "    def step(self, xw: np.ndarray) -> OjaStepOut:\n",
        "        x = np.asarray(xw, dtype=np.float64); y = self.W @ x; x_hat = self.W.T @ y\n",
        "        xn = float(np.dot(x, x) + 1e-12); explained = float(np.dot(x_hat, x_hat) / xn)\n",
        "        residual = float(1.0 - explained)\n",
        "        if self.mode == \"nonlinear\":\n",
        "            g = y ** 3; dW = (g[:, None] * x[None, :]) - self.W\n",
        "        else: # sanger\n",
        "            proj = np.zeros_like(x); dW = np.zeros_like(self.W)\n",
        "            for i in range(self.K):\n",
        "                proj = proj + y[i] * self.W[i]; dW[i] = y[i] * (x - proj)\n",
        "        YW = y @ self.W; cross = YW[None, :] - (y[:, None] * self.W)\n",
        "        dW -= self.beta * (y[:, None] * cross); self.W += self.lr * dW; self._renorm_rows()\n",
        "        self.residual_ema = (1.0 - self.ema) * self.residual_ema + self.ema * residual\n",
        "        grew, _ = self._maybe_grow(x, x_hat); self._steps += 1\n",
        "        return OjaStepOut(y=y, residual_ema=self.residual_ema, grew=grew)\n",
        "    def _renorm_rows(self): self.W = (self.W.T / (np.linalg.norm(self.W, axis=1) + 1e-12)).T\n",
        "    def _maybe_grow(self, x: np.ndarray, x_hat: np.ndarray) -> Tuple[bool, Optional[int]]:\n",
        "        if self.cooldown > 0: self.cooldown -= 1; return False, None\n",
        "        if self.K >= self.max_components: return False, None\n",
        "        if self.residual_ema < self.grow_threshold: return False, None\n",
        "        r = x - x_hat; nr = float(np.linalg.norm(r))\n",
        "        if nr > 1e-9: w_new = r / nr\n",
        "        else:\n",
        "            w_new = self.rng.normal(0, 0.1, size=self.dim)\n",
        "            w_new /= (np.linalg.norm(w_new) + 1e-12)\n",
        "        self.W = np.vstack([self.W, w_new]); self.K += 1\n",
        "        self.cooldown = self.grow_cooldown\n",
        "        print(f\"ðŸ§¬ OJA NEUROGENESIS: Residual high. Growing new component. K={self.K}\"); return True, self.K - 1\n",
        "    def state_dict(self) -> Dict: return {\"W\": self.W, \"residual_ema\": self.residual_ema, \"_steps\": self._steps}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.W = state[\"W\"]; self.K = state[\"W\"].shape[0]; self.residual_ema = state[\"residual_ema\"]; self._steps = state[\"_steps\"]\n",
        "\n",
        "# --- 10. \"Expert Neuron\": ExpertNLMSHead ---\n",
        "class ExpertNLMSHead:\n",
        "    def __init__(self, n_features: int, vocab_size: int,\n",
        "                 attention_config: Dict, mu: float = 0.1, epsilon: float = 1e-6,\n",
        "                 mu_decay: float = 0.9995, mu_min: float = 0.01, initial_bias: float = 0.0,\n",
        "                 guard_sign: bool = False, error_thresh: float = 0.08,\n",
        "                 arousal_band: Optional[tuple] = None):\n",
        "        self.n_features = n_features\n",
        "        self.w = np.zeros(self.n_features, dtype=np.float64)\n",
        "        self.mu_initial = mu\n",
        "        self.mu = mu\n",
        "        self.mu_decay = mu_decay\n",
        "        self.mu_min = mu_min\n",
        "        self.epsilon = epsilon\n",
        "        self.vocab_size = vocab_size\n",
        "        spiking_cfg = {k: v for k, v in attention_config.items() if k in ('decay', 'theta', 'k_winners', 'gain_up', 'gain_down')}\n",
        "        if not spiking_cfg:\n",
        "            spiking_cfg = {'decay': 0.7, 'theta': 1.0, 'k_winners': 5, 'gain_up': 1.5, 'gain_down': 0.6}\n",
        "        self.spiking_attention = SpikingAttention(**spiking_cfg)\n",
        "        multi_cfg = attention_config.get('multi_channel') if isinstance(attention_config, dict) else None\n",
        "        self.multi_attention = MultiChannelSpikingAttention(**multi_cfg) if multi_cfg else None\n",
        "        self.last_error = 0.0\n",
        "        self.last_output = 0.0\n",
        "        self.update_count = 0\n",
        "        self.total_error_sq = 0.0\n",
        "        self._lock = asyncio.Lock()\n",
        "        self.bias = initial_bias  # Add bias term for better learning\n",
        "        # Guard conditions from nlms.py\n",
        "        self.guard_sign = guard_sign  # Skip update if sign mismatch but error small\n",
        "        self.error_thresh = error_thresh  # Threshold for guard conditions\n",
        "        self.arousal_band = arousal_band  # (lo, hi) band for arousal-based skipping\n",
        "    def predict(self, x: np.ndarray) -> float:\n",
        "        return float(np.dot(self.w, x) + self.bias)\n",
        "    async def update(self, x: np.ndarray, y_true: float, token_ids: List[int],\n",
        "                     attention_bundle: Optional[Dict[str, Any]] = None) -> float:\n",
        "        async with self._lock:\n",
        "            y_hat = self.predict(x)\n",
        "            self.last_output = y_hat\n",
        "            error = y_true - y_hat\n",
        "            self.last_error = error\n",
        "            self.total_error_sq += error * error\n",
        "            self.update_count += 1\n",
        "\n",
        "            # Guard conditions from nlms.py - skip update if conditions met\n",
        "            if self.guard_sign:\n",
        "                # Skip if sign mismatch but error is small (prevents unnecessary updates)\n",
        "                if (y_hat > 0) != (y_true > 0) and abs(error) < self.error_thresh:\n",
        "                    return y_hat\n",
        "\n",
        "            if self.arousal_band is not None:\n",
        "                # Skip if target is in arousal band and error is small\n",
        "                lo, hi = self.arousal_band\n",
        "                if (lo <= y_true <= hi) and abs(error) < self.error_thresh:\n",
        "                    return y_hat\n",
        "\n",
        "            attention_gains = self.spiking_attention.compute_gains(token_ids, self.vocab_size)\n",
        "            avg_gain = 1.0\n",
        "            if attention_gains is not None and token_ids:\n",
        "                gains_for_seq = [attention_gains[token] for token in token_ids if 0 <= token < self.vocab_size]\n",
        "                if gains_for_seq: avg_gain = np.mean(gains_for_seq)\n",
        "\n",
        "            multi_mu_scalar = 1.0\n",
        "            if attention_bundle is not None and self.multi_attention is not None:\n",
        "                bundle_tokens = attention_bundle.get('token_ids', token_ids)\n",
        "                mc_result = self.multi_attention.compute(\n",
        "                    bundle_tokens,\n",
        "                    attention_bundle.get('amp'),\n",
        "                    attention_bundle.get('pitch'),\n",
        "                    attention_bundle.get('boundary'),\n",
        "                )\n",
        "                if mc_result:\n",
        "                    multi_mu_scalar = mc_result.get('mu_scalar', 1.0)\n",
        "\n",
        "            self.mu = max(self.mu_min, self.mu * self.mu_decay)\n",
        "            modulated_mu = self.mu * avg_gain * multi_mu_scalar\n",
        "\n",
        "            # Adaptive learning rate based on error magnitude (larger errors = faster learning)\n",
        "            error_magnitude = abs(error)\n",
        "            adaptive_factor = 1.0 + min(2.0, error_magnitude / 10.0)  # Boost LR for large errors\n",
        "            modulated_mu *= adaptive_factor\n",
        "\n",
        "            # Clip error to prevent extreme updates (but allow larger errors)\n",
        "            clipped_error = np.clip(error, -100.0, 100.0)\n",
        "\n",
        "            x_norm_sq = np.dot(x, x) + self.epsilon\n",
        "            step = (modulated_mu * clipped_error * x) / x_norm_sq\n",
        "\n",
        "            # Clip step size to prevent divergence (increased threshold)\n",
        "            step_norm = np.linalg.norm(step)\n",
        "            max_step_norm = 3.0  # Increased further to allow larger updates\n",
        "            if step_norm > max_step_norm:\n",
        "                step = step * (max_step_norm / step_norm)\n",
        "\n",
        "            self.w += step\n",
        "\n",
        "            # Update bias term with adaptive learning (more aggressive for large errors)\n",
        "            bias_learning_rate = 0.3 * adaptive_factor  # More aggressive bias learning\n",
        "            bias_step = modulated_mu * clipped_error * bias_learning_rate\n",
        "            self.bias += bias_step\n",
        "\n",
        "            # Clip weights to prevent unbounded growth\n",
        "            weight_norm = np.linalg.norm(self.w)\n",
        "            max_weight_norm = 100.0\n",
        "            if weight_norm > max_weight_norm:\n",
        "                self.w = self.w * (max_weight_norm / weight_norm)\n",
        "\n",
        "            # Clip bias to reasonable range\n",
        "            self.bias = np.clip(self.bias, -50.0, 50.0)\n",
        "\n",
        "            return y_hat\n",
        "    def get_rmse(self) -> float:\n",
        "        if self.update_count == 0: return float('inf')\n",
        "        return float(np.sqrt(self.total_error_sq / self.update_count))\n",
        "    def state_dict(self) -> Dict:\n",
        "        return {\"w\": self.w, \"bias\": self.bias, \"mu\": self.mu, \"update_count\": self.update_count}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.w = state[\"w\"]\n",
        "        self.bias = state.get(\"bias\", 0.0)\n",
        "        self.mu = state.get(\"mu\", self.mu_initial)\n",
        "        self.update_count = state.get(\"update_count\", 0)\n",
        "\n",
        "# --- 11. Liquid/MoE Components ---\n",
        "# Bandit-based gating for expert selection\n",
        "class BanditGating:\n",
        "    \"\"\"UCB-based bandit gating to track and select best-performing experts\"\"\"\n",
        "    def __init__(self, n_experts: int, exploration_factor: float = 2.0):\n",
        "        self.n_experts = n_experts\n",
        "        self.exploration_factor = exploration_factor\n",
        "        # Track rewards (negative errors) and counts for each expert\n",
        "        self.total_rewards = np.zeros(n_experts, dtype=np.float64)\n",
        "        self.selection_counts = np.ones(n_experts, dtype=np.float64)  # Start at 1 to avoid division by zero\n",
        "        self.total_selections = n_experts  # Total times any expert was selected\n",
        "\n",
        "    def update(self, expert_idx: int, error: float):\n",
        "        \"\"\"Update bandit statistics with expert performance\"\"\"\n",
        "        # Convert error to reward (lower error = higher reward)\n",
        "        reward = 1.0 / (1.0 + abs(error))  # Reward in [0, 1]\n",
        "        self.total_rewards[expert_idx] += reward\n",
        "        self.selection_counts[expert_idx] += 1.0\n",
        "        self.total_selections += 1\n",
        "\n",
        "    def get_ucb_scores(self) -> np.ndarray:\n",
        "        \"\"\"Compute UCB scores for all experts\"\"\"\n",
        "        # Average reward\n",
        "        avg_rewards = self.total_rewards / self.selection_counts\n",
        "\n",
        "        # Confidence bound\n",
        "        confidence = self.exploration_factor * np.sqrt(\n",
        "            np.log(self.total_selections + 1) / self.selection_counts\n",
        "        )\n",
        "\n",
        "        # UCB = average reward + confidence bound\n",
        "        ucb_scores = avg_rewards + confidence\n",
        "        return ucb_scores\n",
        "\n",
        "    def select_top_k(self, k: int, base_gates: np.ndarray) -> tuple:\n",
        "        \"\"\"Select top-k experts using UCB scores, modulated by base gates\"\"\"\n",
        "        ucb_scores = self.get_ucb_scores()\n",
        "\n",
        "        # Combine UCB scores with base gates (weighted combination)\n",
        "        # UCB provides exploration/exploitation, gates provide input-specific routing\n",
        "        combined_scores = 0.7 * base_gates + 0.3 * ucb_scores\n",
        "\n",
        "        # Select top-k\n",
        "        topk_idx = np.argsort(combined_scores)[-k:][::-1]\n",
        "\n",
        "        # Normalize gates\n",
        "        topk_gates = combined_scores[topk_idx]\n",
        "        topk_gates = np.maximum(topk_gates, 0.0)  # Ensure non-negative\n",
        "        gate_sum = np.sum(topk_gates)\n",
        "        if gate_sum > 0:\n",
        "            topk_gates = topk_gates / gate_sum\n",
        "        else:\n",
        "            topk_gates = np.ones(k) / k  # Uniform if all zero\n",
        "\n",
        "        return topk_idx, topk_gates\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset bandit statistics\"\"\"\n",
        "        self.total_rewards.fill(0.0)\n",
        "        self.selection_counts.fill(1.0)\n",
        "        self.total_selections = self.n_experts\n",
        "\n",
        "@dataclass\n",
        "class LiquidCell:\n",
        "    in_dim: int; hidden_dim: int; dt: float = 0.02\n",
        "    tau_min: float = 0.02; tau_max: float = 2.0\n",
        "    rng: np.random.Generator = field(default_factory=lambda: np.random.default_rng(1337))\n",
        "    W: np.ndarray = field(init=False); U: np.ndarray = field(init=False)\n",
        "    b: np.ndarray = field(init=False); V: np.ndarray = field(init=False)\n",
        "    c: np.ndarray = field(init=False); h: np.ndarray = field(init=False)\n",
        "    def __post_init__(self):\n",
        "        self.W = self.rng.normal(0, np.sqrt(2.0/(self.hidden_dim+self.hidden_dim)), (self.hidden_dim, self.hidden_dim))\n",
        "        self.U = self.rng.normal(0, np.sqrt(2.0/(self.in_dim+self.hidden_dim)), (self.hidden_dim, self.in_dim))\n",
        "        self.b = np.zeros((self.hidden_dim,), dtype=np.float64)\n",
        "        self.V = self.rng.normal(0, np.sqrt(2.0/(self.in_dim+self.hidden_dim)), (self.hidden_dim, self.in_dim))\n",
        "        self.c = self.rng.normal(0, 0.1, (self.hidden_dim,))\n",
        "        self.h = np.zeros((self.hidden_dim,), dtype=np.float64)\n",
        "    def reset(self): self.h[:] = 0.0\n",
        "    def step(self, x: np.ndarray, energy: Optional[EnergyMeter] = None) -> np.ndarray:\n",
        "        x = np.asarray(x, dtype=np.float64).reshape(-1)\n",
        "        vx = self.V @ x + self.c; tau = self.tau_min + softplus(vx)\n",
        "        tau = np.minimum(tau, self.tau_max)\n",
        "        Wh = self.W @ self.h; Ux = self.U @ x\n",
        "        a = tanh(Wh + Ux + self.b); dh = - self.h / np.maximum(tau, 1e-6) + a\n",
        "        self.h = self.h + self.dt * dh\n",
        "        if energy is not None: energy.add_macs((self.hidden_dim*self.hidden_dim) + (self.hidden_dim*self.in_dim))\n",
        "        return self.h.copy()\n",
        "    def state_dict(self) -> Dict: return {\"W\": self.W, \"U\": self.U, \"b\": self.b, \"V\": self.V, \"c\": self.c, \"h\": self.h}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.W = state[\"W\"]; self.U = state[\"U\"]; self.b = state[\"b\"]\n",
        "        self.V = state[\"V\"]; self.c = state[\"c\"]; self.h = state[\"h\"]\n",
        "@dataclass\n",
        "class LiquidGatingNetwork:\n",
        "    in_dim: int; hidden_dim: int; n_experts: int\n",
        "    top_k: int = 2; temperature: float = 1.0\n",
        "    usage_smoothing: float = 0.99; bias_lr: float = 0.01\n",
        "    usage_beta: float = 0.5\n",
        "    cell: LiquidCell = field(init=False); Wg: np.ndarray = field(init=False)\n",
        "    bg: np.ndarray = field(init=False); usage_ma: np.ndarray = field(init=False)\n",
        "    rng: np.random.Generator = field(default_factory=lambda: np.random.default_rng(2025))\n",
        "    energy: EnergyMeter = field(default_factory=EnergyMeter)\n",
        "    def __post_init__(self):\n",
        "        self.cell = LiquidCell(self.in_dim, self.hidden_dim, rng=self.rng)\n",
        "        self.Wg = self.rng.normal(0, np.sqrt(2.0/(self.hidden_dim+self.n_experts)), (self.n_experts, self.hidden_dim))\n",
        "        self.bg = np.zeros((self.n_experts,), dtype=np.float64)\n",
        "        self.usage_ma = np.zeros((self.n_experts,), dtype=np.float64)\n",
        "        self._lock = asyncio.Lock()\n",
        "    async def forward(self, x: np.ndarray, attn_gain: float = 1.0) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        async with self._lock:\n",
        "            h = self.cell.step(x, self.energy)\n",
        "            logits = (self.Wg @ h) + self.bg\n",
        "            logits = self._apply_usage_bias(logits)\n",
        "            temp = max(0.2, self.temperature / max(1e-6, attn_gain))\n",
        "            probs = softmax(logits, temp=temp)\n",
        "            k = max(1, min(self.top_k, self.n_experts))\n",
        "            topk_idx = np.argpartition(probs, -k)[-k:]\n",
        "            topk_probs = probs[topk_idx]\n",
        "            if topk_probs.sum() <= 1e-12: gates = np.ones_like(topk_probs) / len(topk_probs)\n",
        "            else: gates = topk_probs / topk_probs.sum()\n",
        "            out = np.zeros_like(probs); out[topk_idx] = gates\n",
        "            eps = 0.01\n",
        "            if self.n_experts > 0 and eps > 0:\n",
        "                j = int(np.argmin(self.usage_ma)); out = (1.0 - eps) * out; out[j] += eps\n",
        "            self.usage_ma = self.usage_smoothing * self.usage_ma + (1.0 - self.usage_smoothing) * out\n",
        "            # Track last winners for dopamine reward (from liquidmoe.py)\n",
        "            self.last_winners = topk_idx\n",
        "            return out, topk_idx, probs\n",
        "    def _apply_usage_bias(self, logits: np.ndarray) -> np.ndarray:\n",
        "        eps = 1e-6; target = 1.0 / self.n_experts\n",
        "        inv_usage = target / (self.usage_ma + eps)\n",
        "        return logits + self.usage_beta * np.log(inv_usage)\n",
        "    async def apply_endocrine(self, *, cortisol: float = 0.0, gh: float = 0.0,\n",
        "                             thyroid: float = 1.0, dopamine: float = 0.0, eps: Optional[float] = None) -> None:\n",
        "        \"\"\"Apply endocrine modulation to gating network (from liquidmoe.py)\"\"\"\n",
        "        async with self._lock:\n",
        "            # Temperature â†‘ with cortisol (stress) â€” clamp for stability\n",
        "            self.temperature = float(np.clip(self.temperature * (1.0 + 0.30 * cortisol), 0.5, 2.5))\n",
        "\n",
        "            # Bias LR scales with thyroid (metabolic rate around 1.0 baseline)\n",
        "            self.bias_lr = float(np.clip(self.bias_lr * (1.0 + 0.40 * (thyroid - 1.0)), 1e-4, 0.1))\n",
        "\n",
        "            # Top-K capacity expands with GH (growth hormone), but never beyond n_experts\n",
        "            base_top_k = getattr(self, 'base_top_k', self.top_k)\n",
        "            self.base_top_k = base_top_k\n",
        "            self.top_k = int(np.clip(round(base_top_k * (1.0 + 0.20 * gh)), 1, self.n_experts))\n",
        "\n",
        "            # Dopamine: nudge most recent winners' biases (reward)\n",
        "            if dopamine > 0 and hasattr(self, 'last_winners') and self.last_winners is not None:\n",
        "                self.bg[self.last_winners] += 0.10 * float(dopamine)\n",
        "\n",
        "            # Optional: exploration epsilon override\n",
        "            if eps is not None:\n",
        "                self.eps = float(np.clip(eps, 0.0, 0.05))\n",
        "    async def nudge_for_load_balance(self) -> None:\n",
        "        async with self._lock:\n",
        "            if self.n_experts <= 0: return\n",
        "            target = 1.0 / float(self.n_experts); delta = target - self.usage_ma\n",
        "            self.bg += self.bias_lr * delta\n",
        "    def reset(self): self.cell.reset(); self.usage_ma[:] = 0.0; self.energy.reset()\n",
        "    def state_dict(self) -> Dict:\n",
        "        return {\"cell\": self.cell.state_dict(), \"Wg\": self.Wg, \"bg\": self.bg, \"usage_ma\": self.usage_ma}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.cell.load_state_dict(state[\"cell\"]); self.Wg = state[\"Wg\"]; self.bg = state[\"bg\"]; self.usage_ma = state[\"usage_ma\"]\n",
        "class NLMSExpertAdapter:\n",
        "    def __init__(self, neuron: ExpertNLMSHead): self.neuron = neuron\n",
        "    def predict(self, x: np.ndarray) -> float: return self.neuron.predict(x)\n",
        "    async def update(self, x: np.ndarray, y_true: float, token_ids: List[int],\n",
        "                     attention_bundle: Optional[Dict[str, Any]] = None) -> float:\n",
        "        return await self.neuron.update(x, y_true, token_ids, attention_bundle)\n",
        "    def state_dict(self) -> Dict: return self.neuron.state_dict()\n",
        "    def load_state_dict(self, state: Dict): self.neuron.load_state_dict(state)\n",
        "@dataclass\n",
        "class LiquidMoERouter:\n",
        "    experts: Dict[str, NLMSExpertAdapter]\n",
        "    in_dim: int; hidden_dim: int; top_k: int = 2\n",
        "    temperature: float = 1.0\n",
        "    gating: LiquidGatingNetwork = field(init=False)\n",
        "    bandit: BanditGating = field(init=False)\n",
        "    names: List[str] = field(init=False)\n",
        "    energy: EnergyMeter = field(default_factory=EnergyMeter)\n",
        "    use_bandit: bool = True  # Enable bandit gating\n",
        "    def __post_init__(self):\n",
        "        self.names = list(self.experts.keys())\n",
        "        self.gating = LiquidGatingNetwork(\n",
        "            in_dim=self.in_dim, hidden_dim=self.hidden_dim,\n",
        "            n_experts=len(self.names), top_k=self.top_k,\n",
        "            temperature=self.temperature,\n",
        "        )\n",
        "        self.bandit = BanditGating(n_experts=len(self.names), exploration_factor=2.0)\n",
        "    async def route(self, x: np.ndarray, attn_gain: float = 1.0) -> Dict[str, any]:\n",
        "        gates_sparse, topk_idx_base, probs = await self.gating.forward(x, attn_gain=attn_gain)\n",
        "\n",
        "        # Use bandit gating if enabled\n",
        "        if self.use_bandit:\n",
        "            # Convert sparse gates to dense for bandit\n",
        "            gates_dense = np.zeros(len(self.names), dtype=np.float64)\n",
        "            for i, idx in enumerate(topk_idx_base):\n",
        "                gates_dense[int(idx)] = float(gates_sparse[i])\n",
        "\n",
        "            # Get bandit-selected experts\n",
        "            topk_idx, topk_gates = self.bandit.select_top_k(self.top_k, gates_dense)\n",
        "\n",
        "            # Update gates_sparse and topk_idx\n",
        "            gates_sparse = topk_gates\n",
        "            topk_idx = topk_idx\n",
        "        else:\n",
        "            topk_idx = topk_idx_base\n",
        "\n",
        "        chosen = [(self.names[i], float(gates_sparse[j])) for j, i in enumerate(topk_idx)]\n",
        "        y = 0.0; per_expert: Dict[str, Dict[str, float]] = {}\n",
        "        for j, i in enumerate(topk_idx):\n",
        "            name = self.names[int(i)]; gate = float(gates_sparse[j])\n",
        "            pred = float(self.experts[name].predict(x)); y += gate * pred\n",
        "            self.energy.add_macs(self.in_dim); per_expert[name] = {\"gate\": gate, \"pred\": pred}\n",
        "        return {'y_hat': float(y), 'topk': chosen, 'probs': probs, 'per_expert': per_expert,\n",
        "            'energy_j': self.energy.total_j + self.gating.energy.total_j}\n",
        "    async def learn(self, x: np.ndarray, token_ids: List[int], y_true: float,\n",
        "                    attn_gain: float = 1.0, attention_bundle: Optional[Dict[str, Any]] = None) -> Dict[str, any]:\n",
        "        out = await self.route(x, attn_gain=attn_gain); tasks = []\n",
        "        expert_errors = {}  # Track errors for bandit updates\n",
        "\n",
        "        for name, info in out['per_expert'].items():\n",
        "            gate = float(info['gate']);\n",
        "            if gate <= 0.0: continue\n",
        "            target = float(y_true)\n",
        "            pred = float(info['pred'])\n",
        "            error = abs(target - pred)\n",
        "            expert_errors[name] = error\n",
        "            tasks.append(self.experts[name].update(x, target, token_ids, attention_bundle))\n",
        "\n",
        "        await asyncio.gather(*tasks)\n",
        "\n",
        "        # Update bandit with expert performance\n",
        "        if self.use_bandit:\n",
        "            for name, error in expert_errors.items():\n",
        "                if name in self.names:\n",
        "                    expert_idx = self.names.index(name)\n",
        "                    self.bandit.update(expert_idx, error)\n",
        "\n",
        "        await self.gating.nudge_for_load_balance(); return out\n",
        "    def reset(self):\n",
        "        self.gating.reset()\n",
        "        self.energy.reset()\n",
        "        if self.use_bandit:\n",
        "            self.bandit.reset()\n",
        "    def state_dict(self) -> Dict:\n",
        "        expert_states = {name: expert.state_dict() for name, expert in self.experts.items()}\n",
        "        bandit_state = {\n",
        "            \"total_rewards\": self.bandit.total_rewards.tolist(),\n",
        "            \"selection_counts\": self.bandit.selection_counts.tolist(),\n",
        "            \"total_selections\": self.bandit.total_selections\n",
        "        } if self.use_bandit else None\n",
        "        return {\"gating\": self.gating.state_dict(), \"experts\": expert_states, \"bandit\": bandit_state}\n",
        "    def load_state_dict(self, state: Dict):\n",
        "        self.gating.load_state_dict(state[\"gating\"])\n",
        "        for name, expert_state in state[\"experts\"].items():\n",
        "            if name in self.experts: self.experts[name].load_state_dict(expert_state)\n",
        "        if self.use_bandit and \"bandit\" in state and state[\"bandit\"]:\n",
        "            bandit_state = state[\"bandit\"]\n",
        "            self.bandit.total_rewards = np.array(bandit_state[\"total_rewards\"])\n",
        "            self.bandit.selection_counts = np.array(bandit_state[\"selection_counts\"])\n",
        "            self.bandit.total_selections = bandit_state[\"total_selections\"]\n",
        "\n",
        "# --- 12. \"Temporal Mind\" ---\n",
        "class TemporalMemoryInterpolator:\n",
        "    def __init__(self, epsilon: float = 1e-12):\n",
        "        self.epsilon = epsilon\n",
        "        print(\"CREATED: TemporalMemoryInterpolator (Aura 7.0 Hippocampus)\")\n",
        "    def interpolate(self, M0: np.ndarray, M1: np.ndarray, t: float,\n",
        "                    mode: Literal['linear', 'fourier', 'hilbert', 'hamiltonian'] = 'hilbert'\n",
        "                   ) -> np.ndarray:\n",
        "        alpha = np.clip(t, 0.0, 1.0)\n",
        "        if mode == 'linear': return (1.0 - alpha) * M0 + alpha * M1\n",
        "        elif mode == 'fourier':\n",
        "            F0 = np.fft.fft(M0); F1 = np.fft.fft(M1)\n",
        "            F_interp = (1.0 - alpha) * F0 + alpha * F1\n",
        "            return np.real(np.fft.ifft(F_interp))\n",
        "        A0 = hilbert(M0, axis=0); A1 = hilbert(M1, axis=0)\n",
        "        if mode == 'hilbert':\n",
        "            A_interp = (1.0 - alpha) * A0 + alpha * A1\n",
        "            return np.real(A_interp)\n",
        "        elif mode == 'hamiltonian':\n",
        "            print(\"WARNING: Hamiltonian mode is computationally expensive.\")\n",
        "            A_diff = (A1 - A0).astype(np.complex128)\n",
        "            H_num = np.outer(A_diff, A_diff.T.conj())\n",
        "            H_den = np.linalg.norm(A_diff)**2 + self.epsilon\n",
        "            H = H_num / H_den; U = expm(-1j * H * alpha)\n",
        "            A_interp = U @ A0; return np.real(A_interp)\n",
        "        else: raise ValueError(f\"Unknown interpolation mode: {mode}\")\n",
        "\n",
        "# --- 13. CNS & ThalamicRouter (Trained) ---\n",
        "class ConsciousnessLevel(Enum):\n",
        "    DEEP_SLEEP = 0; ASLEEP = 1; ALERT = 2; FOCUSED = 3; HYPERVIGILANT = 4\n",
        "class CentralNervousSystem:\n",
        "    def __init__(self):\n",
        "        self.consciousness_level = ConsciousnessLevel.ALERT\n",
        "        self.stress_level = 0.0 # 'cortisol'\n",
        "        self.consolidation_factor = 1.0 # Reduces impact of errors after dreaming\n",
        "        print(\"CREATED: CentralNervousSystem (CNS)\")\n",
        "    def set_consciousness(self, level: ConsciousnessLevel):\n",
        "        if self.consciousness_level != level:\n",
        "            self.consciousness_level = level; print(f\"CNS: Consciousness set to {level.name}\")\n",
        "    def update_stress(self, error: float):\n",
        "        new_stress = abs(error) * 1.5 * self.consolidation_factor\n",
        "        self.stress_level = (self.stress_level * 0.5) + (new_stress * 0.5)\n",
        "        self.stress_level = max(0.0, self.stress_level - 0.1)\n",
        "        if self.stress_level > 1.0: self.set_consciousness(ConsciousnessLevel.HYPERVIGILANT)\n",
        "        else: self.set_consciousness(ConsciousnessLevel.ALERT)\n",
        "    def apply_consolidation(self, factor: float = 0.7):\n",
        "        \"\"\"Apply memory consolidation effect that reduces impact of future errors\"\"\"\n",
        "        self.consolidation_factor = factor\n",
        "\n",
        "    def get_endocrine_levels(self) -> Dict[str, float]:\n",
        "        \"\"\"Compute endocrine hormone levels from CNS state (for liquidmoe.py integration)\"\"\"\n",
        "        # Cortisol: stress level (0-1 maps to 0-2)\n",
        "        cortisol = min(2.0, self.stress_level * 2.0)\n",
        "\n",
        "        # Growth Hormone (GH): higher when learning (low stress, alert)\n",
        "        gh = 0.5 if self.consciousness_level == ConsciousnessLevel.ALERT else 0.0\n",
        "\n",
        "        # Thyroid: metabolic rate (higher when alert, lower when stressed)\n",
        "        thyroid = 1.0 - (self.stress_level * 0.3)  # 1.0 baseline, down to 0.7 when stressed\n",
        "\n",
        "        # Dopamine: reward signal (higher when stress is low and consciousness is alert)\n",
        "        dopamine = max(0.0, 1.0 - self.stress_level) if self.consciousness_level == ConsciousnessLevel.ALERT else 0.0\n",
        "\n",
        "        return {\n",
        "            'cortisol': cortisol,\n",
        "            'gh': gh,\n",
        "            'thyroid': thyroid,\n",
        "            'dopamine': dopamine\n",
        "        }\n",
        "class TrainedThalamicRouter:\n",
        "    \"\"\"The 'School' - runs the offline-trained PyTorch model\"\"\"\n",
        "    def __init__(self, model_path: str, label_maps: Dict, feature_gen: FeatureGenerator):\n",
        "        self.label_maps = label_maps\n",
        "        self.emotion_map = label_maps.get('emotion', {})\n",
        "        self.intent_map = label_maps.get('intent', {})\n",
        "        self.emotion_labels_inv = {v: k for k, v in self.emotion_map.items()}\n",
        "        self.feature_gen = feature_gen; self.model = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        try:\n",
        "            self.model = MultiTaskHead(\n",
        "                feature_gen.TOTAL_FEATURES,\n",
        "                len(self.emotion_map), len(self.intent_map), len(self.emotion_map) # Mock tone\n",
        "            ).to(self.device)\n",
        "            self.model.load_state_dict(torch.load(model_path))\n",
        "            self.model.eval()\n",
        "            print(f\"CREATED: TrainedThalamicRouter (Loaded from {model_path})\")\n",
        "        except Exception as e:\n",
        "            print(f\"--- âŒ ERROR: Failed to load ThalamicRouter model. {e} ---\")\n",
        "\n",
        "    def get_target_signals(self, query: str, verbose: bool = True) -> dict:\n",
        "        if not self.model: return {'emotion': 0.0, 'intent': 0.0}\n",
        "        record = {\"text\": query, \"plutchik\": {\"primary\": \"neutral\"}}\n",
        "        # --- THE FIX: We must use use_emotion_sine=False ---\n",
        "        sbert_vec = self.feature_gen.sbert_model.encode(query, normalize_embeddings=True)\n",
        "        x_raw = self.feature_gen.build_features(record, sbert_vec, use_emotion_sine=False)\n",
        "        x_tensor = torch.tensor(x_raw, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            emo_logits, intent_logits, _ = self.model(x_tensor)\n",
        "            emo_pred_index = emo_logits.argmax(dim=1).item()\n",
        "            intent_pred_index = intent_logits.argmax(dim=1).item()\n",
        "        pred_label = self.emotion_labels_inv.get(emo_pred_index, 'neutral')\n",
        "        signals = {'emotion': float(emo_pred_index), 'intent': float(intent_pred_index)}\n",
        "        if verbose:\n",
        "            print(f\"Thalamus Predicted: '{pred_label}' (Index: {emo_pred_index})\")\n",
        "        return signals\n",
        "\n",
        "# --- 14. The Final IBNN (Aura 7.0 - Hebbian-MoE-Temporal) ---\n",
        "class IntegratedBioNeuralNetwork:\n",
        "    \"\"\"\n",
        "    Aura 7.0: Integrates all components into a persistent,\n",
        "    unsupervised-learning, and time-aware architecture.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_experts: int = 15, hebbian_components: int = 64,\n",
        "                 llm_model_name: str = \"meta-llama/Llama-3.2-3B-Instruct\"):\n",
        "        print(\"--- ðŸ§  Initializing Aura 7.0 (Hebbian-MoE-Temporal) ---\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"   -> GPU: {torch.cuda.get_device_name(0)}, VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
        "            maybe_empty_cuda_cache(\"startup\", min_free_ratio=0.05)\n",
        "        self.feature_gen = FeatureGenerator()\n",
        "        self.response_gen = ResponseGenerator(llm_model_name)\n",
        "        self.cns = CentralNervousSystem()\n",
        "        self.interpolator = TemporalMemoryInterpolator()\n",
        "        self.raw_feature_dim = self.feature_gen.TOTAL_FEATURES\n",
        "        self.vocab_size = self.feature_gen.vocab_size\n",
        "        self.abstract_feature_dim = hebbian_components\n",
        "\n",
        "        self.whitener: OptimizedWhitener = None\n",
        "        self.hippocampus: OjaLayer = None # Hebbian Cortex\n",
        "        self.cortex: LiquidMoERouter = None # MoE Cortex\n",
        "        self.router: Optional[TrainedThalamicRouter] = None\n",
        "        self.n_experts = n_experts\n",
        "\n",
        "        self.education_dir = SAVE_DIR # Use global\n",
        "        os.makedirs(self.education_dir, exist_ok=True)\n",
        "        print(\"--- Aura 7.0 Brain Initialized (Awaiting Education) ---\")\n",
        "\n",
        "    def _create_brain_layers(self, hebbian_k: int):\n",
        "        \"\"\"Dynamically creates the brain layers based on the Hebbian cortex size.\"\"\"\n",
        "        self.abstract_feature_dim = hebbian_k\n",
        "        print(f\"--- ðŸ§  Building Dynamic Brain Layers ---\")\n",
        "        print(f\"   -> Hebbian Cortex (Oja) K = {hebbian_k}\")\n",
        "\n",
        "        self.hippocampus = OjaLayer(\n",
        "            dim=self.raw_feature_dim,\n",
        "            n_components=hebbian_k,\n",
        "            mode='nonlinear', lr=5e-4, max_components=128, grow_threshold=0.3\n",
        "        )\n",
        "        self.whitener = OptimizedWhitener(dim=self.raw_feature_dim)\n",
        "\n",
        "        experts: Dict[str, NLMSExpertAdapter] = {}\n",
        "        attention_config = {\n",
        "            'decay': 0.7,\n",
        "            'theta': 1.0,\n",
        "            'k_winners': 3,\n",
        "            'gain_up': 1.5,\n",
        "            'gain_down': 0.7,\n",
        "            'multi_channel': {\n",
        "                'k_winners': 5,\n",
        "                'w_amp': 1.0,\n",
        "                'w_pitch': 1.4,\n",
        "                'w_bound': 0.8,\n",
        "                'gain_up': 2.0,\n",
        "                'gain_down': 0.5,\n",
        "                'use_stdp': True,\n",
        "                'smoothing': 1,\n",
        "            }\n",
        "        }\n",
        "        num_emotions = len(GOEMOTIONS_LABELS)\n",
        "        emotion_range_per_expert = num_emotions / self.n_experts\n",
        "\n",
        "        for i in range(self.n_experts):\n",
        "            name = f\"expert__{i}\"\n",
        "            # Initialize bias toward expert's emotion range (0-27 for GoEmotions)\n",
        "            target_emotion_idx = i * emotion_range_per_expert + emotion_range_per_expert / 2\n",
        "            head = ExpertNLMSHead(\n",
        "                n_features=self.abstract_feature_dim,\n",
        "                vocab_size=self.vocab_size,\n",
        "                attention_config=attention_config,\n",
        "                mu=0.5,  # Even higher learning rate for faster convergence\n",
        "                mu_decay=0.99995,  # Very slow decay to maintain learning longer\n",
        "                mu_min=0.1,  # Higher minimum learning rate\n",
        "                initial_bias=target_emotion_idx  # Initialize bias to target range\n",
        "            )\n",
        "            # Initialize weights with larger random values for better coverage\n",
        "            head.w = np.random.normal(0, 1.0, self.abstract_feature_dim)\n",
        "            # Ensure bias is actually set (double-check)\n",
        "            head.bias = float(target_emotion_idx)\n",
        "            experts[name] = NLMSExpertAdapter(neuron=head)\n",
        "\n",
        "        self.cortex = LiquidMoERouter(\n",
        "            experts=experts, in_dim=self.abstract_feature_dim, # Use K\n",
        "            hidden_dim=128, top_k=3\n",
        "        )\n",
        "        print(f\"--- ðŸ§  Dynamic Brain Layers Created ---\")\n",
        "\n",
        "    async def educate_brain(self):\n",
        "        \"\"\"\n",
        "        Runs the 'School' pipeline to pre-train all components.\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"\\n--- ðŸŽ“ STARTING OFFLINE EDUCATION (GoEmotions) ---\")\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        # 1. Load GoEmotions\n",
        "        print(\"Loading 'google-research-datasets/go_emotions'...\")\n",
        "        dataset = load_dataset(\"google-research-datasets/go_emotions\", split='train')\n",
        "        dataset = dataset.shuffle(seed=42).select(range(30000))\n",
        "        all_texts = dataset['text']\n",
        "\n",
        "        # 2. Precompute SBERT\n",
        "        print(f\"Pre-computing SBERT embeddings for {len(all_texts)} texts...\")\n",
        "        sbert_embeddings = await asyncio.to_thread(\n",
        "            self.feature_gen.sbert_model.encode,\n",
        "            all_texts, normalize_embeddings=True, batch_size=256\n",
        "        )\n",
        "\n",
        "        # 3. Create Label Maps\n",
        "        emotion_labels = GOEMOTIONS_LABELS\n",
        "        intent_labels = [\"question\", \"statement\", \"exclamation\", \"request\", \"none\"]\n",
        "        tone_labels = emotion_labels # Mock\n",
        "        label_maps = {\n",
        "            'emotion': {label: idx for idx, label in enumerate(emotion_labels)},\n",
        "            'intent': {label: idx for idx, label in enumerate(intent_labels)},\n",
        "            'tone': {label: idx for idx, label in enumerate(tone_labels)},\n",
        "        }\n",
        "\n",
        "        # 4. Build Features\n",
        "        print(\"Building features...\")\n",
        "        X_features, y_emotion, y_intent, y_tone = [], [], [], []\n",
        "        X_features_hebbian_raw = [] # For Oja training\n",
        "\n",
        "        for i, record in enumerate(dataset):\n",
        "            primary_emotion = 'neutral'\n",
        "            label_indices = record['labels']\n",
        "            if label_indices:\n",
        "                for idx in label_indices:\n",
        "                    if 0 <= idx < len(GOEMOTIONS_LABELS):\n",
        "                        label_name = GOEMOTIONS_LABELS[idx]\n",
        "                        if label_name != 'neutral':\n",
        "                            primary_emotion = label_name; break\n",
        "\n",
        "            mock_record = {\n",
        "                \"text\": record['text'],\n",
        "                \"plutchik\": {\"primary\": primary_emotion, \"intensity\": 1.0},\n",
        "                \"intent\": \"question\" if \"?\" in record['text'] else \"statement\",\n",
        "                \"tone\": primary_emotion\n",
        "            }\n",
        "\n",
        "            # --- THE FIX ---\n",
        "            # Features for Thalamus (teacher) -> NO emotional sine wave (no cheating)\n",
        "            X_features.append(self.feature_gen.build_features(mock_record, sbert_embeddings[i], use_emotion_sine=False))\n",
        "            # Features for Hebbian (unsupervised) -> YES emotional sine wave (part of context)\n",
        "            X_features_hebbian_raw.append(self.feature_gen.build_features(mock_record, sbert_embeddings[i], use_emotion_sine=True))\n",
        "            # --- END FIX ---\n",
        "\n",
        "            y_emotion.append(label_maps['emotion'].get(primary_emotion, GOEMOTIONS_MAP['neutral']))\n",
        "            y_intent.append(label_maps['intent'].get(mock_record['intent'], 1))\n",
        "            y_tone.append(label_maps['tone'].get(primary_emotion, GOEMOTIONS_MAP['neutral']))\n",
        "\n",
        "        X_train_np = np.stack(X_features)\n",
        "        y_emotion_np = np.array(y_emotion)\n",
        "\n",
        "        indices = np.arange(len(X_train_np))\n",
        "        X_train_split, X_test_split, y_emotion_train_split, y_emotion_test_split, \\\n",
        "        y_intent_train_split, y_intent_test_split, y_tone_train_split, y_tone_test_split = \\\n",
        "            train_test_split(X_train_np, y_emotion_np, y_intent, y_tone, test_size=0.2, random_state=42, stratify=y_emotion_np)\n",
        "\n",
        "        X_train_torch = torch.tensor(X_train_split, dtype=torch.float32).to(device)\n",
        "        y_emotion_train_torch = torch.tensor(y_emotion_train_split, dtype=torch.long).to(device)\n",
        "        y_intent_train_torch = torch.tensor(y_intent_train_split, dtype=torch.long).to(device)\n",
        "        y_tone_train_torch = torch.tensor(y_tone_train_split, dtype=torch.long).to(device)\n",
        "\n",
        "        X_test_torch = torch.tensor(X_test_split, dtype=torch.float32).to(device)\n",
        "        y_emotion_test_torch = torch.tensor(y_emotion_test_split, dtype=torch.long).to(device)\n",
        "        y_intent_test_torch = torch.tensor(y_intent_test_split, dtype=torch.long).to(device)\n",
        "        y_tone_test_torch = torch.tensor(y_tone_test_split, dtype=torch.long).to(device)\n",
        "\n",
        "        # --- 5. Train the \"Hebbian Cortex\" (OjaLayer) ---\n",
        "        print(\"Training Hebbian Cortex (OjaLayer) on whitened data...\")\n",
        "        self._create_brain_layers(hebbian_k=self.abstract_feature_dim)\n",
        "\n",
        "        # Whiten the *full-context* features for Hebbian learning\n",
        "        X_train_np_hebbian = np.stack(X_features_hebbian_raw)\n",
        "        X_features_whitened = np.array([self.feature_gen.whitener.transform(x) for x in X_train_np_hebbian])\n",
        "\n",
        "        for x_w in X_features_whitened:\n",
        "             self.hippocampus.step(x_w)\n",
        "\n",
        "        final_k = self.hippocampus.K\n",
        "        if final_k != self.abstract_feature_dim:\n",
        "            print(f\"Hebbian Cortex grew from {self.abstract_feature_dim} to {final_k}. Rebuilding MoE...\")\n",
        "            self._create_brain_layers(hebbian_k=final_k)\n",
        "\n",
        "        print(f\"   -> Hebbian Cortex (OjaLayer) training complete. Final K={final_k}\")\n",
        "\n",
        "        # --- 6. Train the \"Thalamus\" (MultiTaskHead) ---\n",
        "        print(f\"Training MultiTask ThalamicRouter...\")\n",
        "        class_weights_emotion = compute_class_weight('balanced', classes=np.unique(y_emotion_train_split), y=y_emotion_train_split)\n",
        "        class_weights_emotion = torch.tensor(class_weights_emotion, dtype=torch.float32).to(device)\n",
        "\n",
        "        thalamus_model = MultiTaskHead(\n",
        "            self.feature_gen.TOTAL_FEATURES,\n",
        "            len(label_maps['emotion']), len(label_maps['intent']), len(label_maps['tone'])\n",
        "        ).to(device)\n",
        "\n",
        "        batch_size = 1024\n",
        "        num_epochs = 500\n",
        "        initial_lr = 3e-4\n",
        "\n",
        "        optimizer = optim.AdamW(thalamus_model.parameters(), lr=initial_lr, weight_decay=1e-4)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "        criterion_emotion = nn.CrossEntropyLoss(weight=class_weights_emotion)\n",
        "        criterion_intent = nn.CrossEntropyLoss()\n",
        "        criterion_tone = nn.CrossEntropyLoss(weight=class_weights_emotion)\n",
        "\n",
        "        train_dataset = torch.utils.data.TensorDataset(\n",
        "            X_train_torch, y_emotion_train_torch, y_intent_train_torch, y_tone_train_torch\n",
        "        )\n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        epochs_no_improve = 0\n",
        "        patience = 8\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            thalamus_model.train()\n",
        "            epoch_train_loss = 0.0\n",
        "            num_batches = 0\n",
        "\n",
        "            for batch_x, batch_emo, batch_intent, batch_tone in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                emo_out, intent_out, tone_out = thalamus_model(batch_x)\n",
        "                loss = (1.0 * criterion_emotion(emo_out, batch_emo) +\n",
        "                        0.5 * criterion_intent(intent_out, batch_intent) +\n",
        "                        0.5 * criterion_tone(tone_out, batch_tone))\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(thalamus_model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "                epoch_train_loss += loss.item()\n",
        "                num_batches += 1\n",
        "\n",
        "            avg_train_loss = epoch_train_loss / num_batches\n",
        "\n",
        "            thalamus_model.eval()\n",
        "            with torch.no_grad():\n",
        "                emo_val, intent_val, tone_val = thalamus_model(X_test_torch)\n",
        "                val_loss = (1.0 * criterion_emotion(emo_val, y_emotion_test_torch) +\n",
        "                            0.5 * criterion_intent(intent_val, y_intent_test_torch) +\n",
        "                            0.5 * criterion_tone(tone_val, y_tone_test_torch))\n",
        "\n",
        "            scheduler.step(val_loss)\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "            print(f\"Epoch {epoch+1:02d}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss.item():.4f} | LR: {current_lr:.6f}\")\n",
        "\n",
        "            # Clear GPU cache only if VRAM gets tight\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                maybe_empty_cuda_cache(f\"thalamus training epoch {epoch+1}\", min_free_ratio=0.08)\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                epochs_no_improve = 0\n",
        "                thalamus_path = os.path.join(self.education_dir, \"thalamic_router_multitask.pt\")\n",
        "                torch.save(thalamus_model.state_dict(), thalamus_path)\n",
        "                print(f\"   -> New best model saved to {thalamus_path}\")\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "                if epochs_no_improve >= patience:\n",
        "                    print(f\"   -> Early stopping on epoch {epoch+1}.\")\n",
        "                    break\n",
        "\n",
        "        # --- 7. \"Mind Upload\" - Initialize Router ---\n",
        "        self.router = TrainedThalamicRouter(thalamus_path, label_maps, self.feature_gen)\n",
        "\n",
        "        # --- 8. Warm-up MoE Experts ---\n",
        "        print(\"Warming up MoE experts on training data...\")\n",
        "        warmup_sweeps = 3\n",
        "        warmup_samples = min(2000, len(dataset))\n",
        "        warmup_val_samples = min(500, len(dataset))\n",
        "        warmup_val_indices = np.random.choice(len(dataset), warmup_val_samples, replace=False)\n",
        "\n",
        "        for sweep in range(warmup_sweeps):\n",
        "            print(f\"   --> Warm-up sweep {sweep+1}/{warmup_sweeps}\")\n",
        "            warmup_indices = np.random.choice(len(dataset), warmup_samples, replace=False)\n",
        "            errors = []\n",
        "            predictions = []\n",
        "            targets = []\n",
        "            for i, idx in enumerate(warmup_indices):\n",
        "                record = dataset[int(idx)]\n",
        "                query_text = record['text']\n",
        "\n",
        "                target_signals = self.router.get_target_signals(query_text, verbose=False)\n",
        "                y_true_emotion_idx = target_signals['emotion']\n",
        "                y_true_emotion_label = self.router.emotion_labels_inv.get(y_true_emotion_idx, 'neutral')\n",
        "\n",
        "                x_raw, token_ids, attention_bundle = self.feature_gen.generate_for_query(query_text, thalamus_prediction=y_true_emotion_label)\n",
        "                xw = self.feature_gen.whitener.transform(x_raw)\n",
        "                oja_out = self.hippocampus.step(xw)\n",
        "                y_abstract = oja_out.y\n",
        "\n",
        "                target_for_moe = float(y_true_emotion_idx)\n",
        "                out = await self.cortex.learn(x=y_abstract, token_ids=token_ids, y_true=target_for_moe, attention_bundle=attention_bundle)\n",
        "\n",
        "                pred = out['y_hat']\n",
        "                _, discrete_pred = quantize_moe_prediction(pred, NUM_GOEMOTIONS)\n",
        "                error = abs(target_for_moe - discrete_pred)\n",
        "                errors.append(error)\n",
        "                predictions.append(discrete_pred)\n",
        "                targets.append(target_for_moe)\n",
        "\n",
        "                if (i + 1) % 200 == 0:\n",
        "                    avg_error = np.mean(errors[-200:])\n",
        "                    avg_pred = np.mean(predictions[-200:]) if predictions else 0.0\n",
        "                    avg_target = np.mean(targets[-200:]) if targets else 0.0\n",
        "                    print(f\"      Sweep {sweep+1} Progress {i+1}/{warmup_samples}: Error={avg_error:.2f}, Pred={avg_pred:.2f}, Target={avg_target:.2f}\")\n",
        "\n",
        "            sweep_mae = np.mean(errors) if errors else float('inf')\n",
        "            sweep_rmse = np.sqrt(np.mean([e*e for e in errors])) if errors else float('inf')\n",
        "            sweep_corr = np.corrcoef(predictions, targets)[0, 1] if len(predictions) > 1 else 0.0\n",
        "            print(f\"   -> Sweep {sweep+1} metrics: MAE={sweep_mae:.2f}, RMSE={sweep_rmse:.2f}, Corr={sweep_corr:.3f}\")\n",
        "\n",
        "            await self._evaluate_moe_subset(\n",
        "                dataset,\n",
        "                warmup_val_indices,\n",
        "                description=f\"Validation after sweep {sweep+1}\"\n",
        "            )\n",
        "\n",
        "        print(f\"   -> MoE experts warmed up with {warmup_sweeps} sweeps ({warmup_samples} samples each)\")\n",
        "        await self._evaluate_moe_subset(\n",
        "            dataset,\n",
        "            warmup_val_indices,\n",
        "            description=\"Final warm-up validation\"\n",
        "        )\n",
        "\n",
        "        print(\"--- ðŸŽ“ OFFLINE EDUCATION COMPLETE ---\")\n",
        "\n",
        "    async def _evaluate_moe_subset(self, dataset, indices, description: str = \"Validation\"):\n",
        "        if indices is None or len(indices) == 0:\n",
        "            return\n",
        "        if not self.router or not self.cortex:\n",
        "            print(f\"[WARN] Cannot run {description}; router or cortex missing.\")\n",
        "            return\n",
        "        errors = []\n",
        "        predictions = []\n",
        "        targets = []\n",
        "        for idx in indices:\n",
        "            record = dataset[int(idx)]\n",
        "            query_text = record.get('text', '')\n",
        "            if not query_text:\n",
        "                continue\n",
        "            target_signals = self.router.get_target_signals(query_text, verbose=False)\n",
        "            y_true_emotion_idx = target_signals['emotion']\n",
        "            y_true_emotion_label = self.router.emotion_labels_inv.get(y_true_emotion_idx, 'neutral')\n",
        "\n",
        "            x_raw, token_ids, attention_bundle = self.feature_gen.generate_for_query(query_text, thalamus_prediction=y_true_emotion_label)\n",
        "            xw = self.feature_gen.whitener.transform(x_raw)\n",
        "            oja_out = self.hippocampus.step(xw)\n",
        "            y_abstract = oja_out.y\n",
        "\n",
        "            out = await self.cortex.route(x=y_abstract, attn_gain=1.0)\n",
        "            pred = out['y_hat']\n",
        "            _, discrete_pred = quantize_moe_prediction(pred, NUM_GOEMOTIONS)\n",
        "            target_val = float(y_true_emotion_idx)\n",
        "            error = abs(target_val - discrete_pred)\n",
        "            errors.append(error)\n",
        "            predictions.append(discrete_pred)\n",
        "            targets.append(target_val)\n",
        "        if not errors:\n",
        "            return\n",
        "        mae = np.mean(errors)\n",
        "        rmse = np.sqrt(np.mean([e*e for e in errors]))\n",
        "        corr = np.corrcoef(predictions, targets)[0, 1] if len(predictions) > 1 else 0.0\n",
        "        print(f\"   -> {description}: MAE={mae:.2f}, RMSE={rmse:.2f}, Corr={corr:.3f}\")\n",
        "\n",
        "    async def process_query(self, query: str, update_stress: bool = True) -> str:\n",
        "        print(f\"\\n--- â˜€ï¸ PROCESSING QUERY (Aura 7.0): '{query}' ---\")\n",
        "        if not self.router: return \"I am uneducated. Please run `await aura.educate_brain()`.\"\n",
        "\n",
        "        # 1. \"Thalamus\" (Educated) predicts the target emotion\n",
        "        target_signals = self.router.get_target_signals(query)\n",
        "        y_true_emotion_idx = target_signals['emotion']\n",
        "        y_true_emotion_label = self.router.emotion_labels_inv.get(y_true_emotion_idx, 'neutral')\n",
        "\n",
        "        # 2. \"Ears\" -> \"Hebbian Cortex\"\n",
        "        # The Hebbian layer's feature vector *includes* the \"correct\" emotional sine wave\n",
        "        # This is now part of the \"context\" for the MoE\n",
        "        x_raw, token_ids, attention_bundle = self.feature_gen.generate_for_query(query, thalamus_prediction=y_true_emotion_label)\n",
        "        xw = self.feature_gen.whitener.transform(x_raw)\n",
        "        oja_out = self.hippocampus.step(xw)\n",
        "        y_abstract = oja_out.y\n",
        "\n",
        "        # 3. \"MoE Cortex\" (Online Learning)\n",
        "        # The MoE experts learn to map the abstract engram to the Thalamus's target index\n",
        "        target_for_moe = float(y_true_emotion_idx)\n",
        "\n",
        "        out = await self.cortex.learn(\n",
        "            x=y_abstract, token_ids=token_ids, y_true=target_for_moe, attention_bundle=attention_bundle\n",
        "        )\n",
        "\n",
        "        # 4. \"CNS\" (Feeling)\n",
        "        raw_prediction = out['y_hat']\n",
        "        moe_idx, discrete_prediction = quantize_moe_prediction(raw_prediction, NUM_GOEMOTIONS)\n",
        "        prediction_error = target_for_moe - discrete_prediction\n",
        "        if update_stress:\n",
        "            self.cns.update_stress(prediction_error)\n",
        "            # Apply endocrine modulation to gating network (from liquidmoe.py)\n",
        "            endocrine_levels = self.cns.get_endocrine_levels()\n",
        "            await self.cortex.gating.apply_endocrine(**endocrine_levels)\n",
        "\n",
        "        print(f\"Hebbian (Oja) Residual: {oja_out.residual_ema:.3f} (Grew: {oja_out.grew})\")\n",
        "        print(f\"MoE Prediction: idx={moe_idx} (raw={raw_prediction:.2f}), Target: {int(target_for_moe)}, Error: {abs(prediction_error):.2f}\")\n",
        "\n",
        "        # Diagnostic: Show top expert contributions\n",
        "        if 'topk' in out and len(out['topk']) > 0:\n",
        "            top_expert = out['topk'][0]\n",
        "            expert_name, expert_gate = top_expert\n",
        "            expert_neuron = self.cortex.experts[expert_name].neuron\n",
        "            expert_rmse = expert_neuron.get_rmse()\n",
        "            expert_lr = expert_neuron.mu\n",
        "            print(f\"   -> Top Expert: {expert_name} (gate={expert_gate:.3f}, RMSE={expert_rmse:.2f}, LR={expert_lr:.4f})\")\n",
        "\n",
        "        # 5. \"Mouth\" speaks\n",
        "        final_brain_state = {\n",
        "            'cns_state': self.cns.consciousness_level,\n",
        "            'stress_level': self.cns.stress_level,\n",
        "        }\n",
        "        response = await self.response_gen.generate_response(query, final_brain_state)\n",
        "        self.last_run_final_stress = self.cns.stress_level\n",
        "        return response\n",
        "\n",
        "    def get_moe_statistics(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get diagnostic statistics about MoE experts\"\"\"\n",
        "        stats = {\n",
        "            'expert_count': len(self.cortex.experts),\n",
        "            'experts': {}\n",
        "        }\n",
        "        for name, expert_adapter in self.cortex.experts.items():\n",
        "            neuron = expert_adapter.neuron\n",
        "            stats['experts'][name] = {\n",
        "                'rmse': neuron.get_rmse(),\n",
        "                'learning_rate': neuron.mu,\n",
        "                'update_count': neuron.update_count,\n",
        "                'last_error': neuron.last_error\n",
        "            }\n",
        "        return stats\n",
        "\n",
        "    def _get_brain_state_vector(self) -> np.ndarray:\n",
        "        all_weights = []\n",
        "        all_weights.append(self.feature_gen.whitener.mu.flatten())\n",
        "        all_weights.append(self.feature_gen.whitener.var.flatten())\n",
        "        all_weights.append(self.hippocampus.W.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.W.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.U.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.b.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.V.flatten())\n",
        "        all_weights.append(self.cortex.gating.cell.c.flatten())\n",
        "        all_weights.append(self.cortex.gating.Wg.flatten())\n",
        "        all_weights.append(self.cortex.gating.bg.flatten())\n",
        "        for expert in self.cortex.experts.values():\n",
        "            all_weights.append(expert.neuron.w.flatten())\n",
        "        return np.concatenate(all_weights)\n",
        "\n",
        "    def _load_brain_state_vector(self, M: np.ndarray):\n",
        "        print(\"--- ðŸ§  Loading brain state from vector... ---\")\n",
        "        idx = 0\n",
        "        def _load(target_array: np.ndarray) -> int:\n",
        "            nonlocal idx\n",
        "            n = target_array.size\n",
        "            try:\n",
        "                target_array[:] = M[idx : idx + n].reshape(target_array.shape)\n",
        "            except ValueError:\n",
        "                print(f\"!! Shape mismatch during load. Target: {target_array.shape}, Got: {M[idx : idx + n].shape}\")\n",
        "                min_n = min(target_array.size, M[idx:].size)\n",
        "                if min_n == 0: return idx\n",
        "                target_flat = target_array.flat; source_flat = M[idx:].flat\n",
        "                for i in range(min_n): target_flat[i] = source_flat[i]\n",
        "                n = min_n\n",
        "            return idx + n\n",
        "        try:\n",
        "            idx = _load(self.feature_gen.whitener.mu)\n",
        "            idx = _load(self.feature_gen.whitener.var)\n",
        "            idx = _load(self.hippocampus.W)\n",
        "            idx = _load(self.cortex.gating.cell.W)\n",
        "            idx = _load(self.cortex.gating.cell.U)\n",
        "            idx = _load(self.cortex.gating.cell.b)\n",
        "            idx = _load(self.cortex.gating.cell.V)\n",
        "            idx = _load(self.cortex.gating.cell.c)\n",
        "            idx = _load(self.cortex.gating.Wg)\n",
        "            idx = _load(self.cortex.gating.bg)\n",
        "            for expert in self.cortex.experts.values():\n",
        "                idx = _load(expert.neuron.w)\n",
        "            print(f\"--- ðŸ§  Brain state loaded successfully. Total params: {idx} ---\")\n",
        "        except Exception as e:\n",
        "            print(f\"--- âŒ ERROR: Failed to load brain state vector. {e} ---\")\n",
        "\n",
        "    async def save_keyframe(self, name: str):\n",
        "        path = os.path.join(self.education_dir, f\"keyframe_{name}_{int(time.time())}.npy\")\n",
        "        print(f\"\\n--- ðŸ’¾ Saving keyframe to {path} ---\")\n",
        "        M = self._get_brain_state_vector()\n",
        "        await asyncio.to_thread(np.save, path, M)\n",
        "        print(\"--- ðŸ’¾ Keyframe save complete ---\")\n",
        "\n",
        "    async def run_sleep_cycle(self, keyframe1_name: str, keyframe2_name: str):\n",
        "        \"\"\"\n",
        "        Implements \"Dream Recall\" from the paper.\n",
        "        Consolidates memories and reduces stress through dream interpolation.\n",
        "        \"\"\"\n",
        "        print(f\"\\n--- ðŸ’¤ RUNNING SLEEP CYCLE (Dreaming) ---\")\n",
        "        print(f\"Loading keyframes: {keyframe1_name} and {keyframe2_name}\")\n",
        "        try:\n",
        "            M0_path = sorted(glob.glob(os.path.join(self.education_dir, f\"keyframe_{keyframe1_name}*.npy\")))[-1]\n",
        "            M1_path = sorted(glob.glob(os.path.join(self.education_dir, f\"keyframe_{keyframe2_name}*.npy\")))[-1]\n",
        "            M0 = np.load(M0_path)\n",
        "            M1 = np.load(M1_path)\n",
        "        except Exception as e:\n",
        "            print(f\"--- âŒ ERROR: Could not load keyframes for dreaming. {e} ---\"); return\n",
        "\n",
        "        current_brain_shape = self._get_brain_state_vector().shape\n",
        "        if M0.shape != M1.shape or M0.shape != current_brain_shape:\n",
        "            print(f\"--- âŒ ERROR: Keyframe dimension mismatch. Cannot interpolate. ---\")\n",
        "            print(f\"M0: {M0.shape}, M1: {M1.shape}, Current: {current_brain_shape}\"); return\n",
        "\n",
        "        stress_before_dream = self.cns.stress_level\n",
        "\n",
        "        print(\"...Interpolating dream state using Hilbert (phase-aware) interpolation...\")\n",
        "        # Use multiple interpolation points for richer consolidation\n",
        "        interpolation_points = [0.25, 0.5, 0.75]\n",
        "        M_dreams = []\n",
        "        for t in interpolation_points:\n",
        "            M_dream = self.interpolator.interpolate(M0, M1, t=t, mode='hilbert')\n",
        "            M_dreams.append(M_dream)\n",
        "\n",
        "        # Average the interpolated states for smoother consolidation\n",
        "        M_consolidated = np.mean(M_dreams, axis=0)\n",
        "        self._load_brain_state_vector(M_consolidated)\n",
        "\n",
        "        print(\"...Consolidating dream state (multiple interpolation points)...\")\n",
        "        # Process multiple dream queries for better consolidation\n",
        "        dream_queries = [\"... (dreaming) ...\", \"... (memory consolidation) ...\", \"... (neural replay) ...\"]\n",
        "        for dream_query in dream_queries:\n",
        "            await self.process_query(dream_query, update_stress=False)\n",
        "\n",
        "        stress_after_consolidation = self.cns.stress_level\n",
        "        stress_reduction_factor = 0.25\n",
        "        stress_reduction = max(0.0, stress_before_dream * stress_reduction_factor)\n",
        "        self.cns.stress_level = max(0.0, stress_after_consolidation - stress_reduction)\n",
        "\n",
        "        self.cns.apply_consolidation(factor=0.7)\n",
        "\n",
        "        if self.cns.stress_level < 1.0:\n",
        "            self.cns.set_consciousness(ConsciousnessLevel.ALERT)\n",
        "\n",
        "        print(f\"--- ðŸ’¤ SLEEP CYCLE COMPLETE (Stress reduced by {stress_reduction:.4f}, from {stress_before_dream:.4f} to {self.cns.stress_level:.4f}, consolidation factor: {self.cns.consolidation_factor:.2f}) ---\")\n",
        "\n",
        "# --- 15. PyTorch Models (for the \"School\") ---\n",
        "class LinearTorchModel(nn.Module):\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, input_dim: int, num_classes: int):\n",
        "        super().__init__(); self.fc = nn.Linear(input_dim, num_classes)\n",
        "    def forward(self, x): return self.fc(x)\n",
        "\n",
        "\n",
        "\n",
        "print(\"âœ… Cell 55: All Aura 7.0 classes defined.\")\n",
        "class MultiTaskHead(nn.Module):\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, input_dim: int, num_emotions: int, num_intents: int, num_tones: int):\n",
        "        super().__init__()\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.LayerNorm(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.15)\n",
        "        )\n",
        "        self.emotion_head = nn.Linear(512, num_emotions)\n",
        "        self.intent_head = nn.Linear(512, num_intents)\n",
        "        self.tone_head = nn.Linear(512, num_tones)\n",
        "    def forward(self, x):\n",
        "        h = self.shared(x)\n",
        "        return self.emotion_head(h), self.intent_head(h), self.tone_head(h)\n",
        "\n",
        "def multitask_loss(emotion_out, emotion_y, intent_out, intent_y, tone_out, tone_y,\n",
        "                  criterion_emotion, criterion_intent, criterion_tone):\n",
        "    \"\"\" - Modified for weighted loss\"\"\"\n",
        "    loss = (1.0 * criterion_emotion(emotion_out, emotion_y) +\n",
        "            0.5 * criterion_intent(intent_out, intent_y) +\n",
        "            0.5 * criterion_tone(tone_out, tone_y))\n",
        "    return loss\n",
        "\n",
        "print(\"âœ… Cell 55: All Aura 7.0 classes defined.\")\n",
        "\n",
        "# --- This is the test cell for Aura 7.0 ---\n",
        "# It must be run in a cell *after* Cell 55\n",
        "\n",
        "# --- 1. Define Global Save Paths ---\n",
        "SAVE_DIR = \"/content/drive/MyDrive/aura_education_v7_final\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "THALAMUS_PATH = os.path.join(SAVE_DIR, \"thalamic_router_multitask.pt\")\n",
        "LABEL_MAPS_PATH = os.path.join(SAVE_DIR, \"aura_7_label_maps.json\")\n",
        "\n",
        "# --- 2. The Main Async Test Loop ---\n",
        "async def main_test_loop():\n",
        "\n",
        "    # --- 3. INITIALIZE AND EDUCATE ---\n",
        "    print(\"--- ðŸ§  Initializing Aura 7.0 (Loading LLMs with Unsloth...) ---\")\n",
        "    aura = IntegratedBioNeuralNetwork(\n",
        "        n_experts=15,\n",
        "        hebbian_components=64, # Initial size\n",
        "        llm_model_name=\"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "    )\n",
        "    print(\"--- Aura LLM Components Loaded ---\")\n",
        "\n",
        "    # Run the \"School\"\n",
        "    await aura.educate_brain() # This will train on go_emotions\n",
        "\n",
        "    # --- 4. TEST 1: (PRE-TRAINED, \"happy\") ---\n",
        "    print(\"\\n\\n--- ðŸ—£ï¸ TEST 1: Educated Brain, 'Happy' Query ---\")\n",
        "    response_1 = await aura.process_query(\"I am so happy and full of joy!\")\n",
        "    print(f\"\\nFINAL AURA RESPONSE (Happy): {response_1}\")\n",
        "    await aura.save_keyframe(\"happy\") # Save this brain state\n",
        "    day_1_stress = aura.last_run_final_stress\n",
        "\n",
        "    # --- 5. TEST 2: (PRE-TRAINED, \"scared\") ---\n",
        "    print(\"\\n\\n--- ðŸ—£ï¸ TEST 2: Educated Brain, 'Scared' Query ---\")\n",
        "    response_2 = await aura.process_query(\"I am feeling very scared\")\n",
        "    print(f\"\\nFINAL AURA RESPONSE (Scared): {response_2}\")\n",
        "    await aura.save_keyframe(\"scared\") # Save this brain state\n",
        "    day_2_stress = aura.last_run_final_stress\n",
        "\n",
        "    # --- 6. \"DREAM\" CYCLE ---\n",
        "    await aura.run_sleep_cycle(keyframe1_name=\"happy\", keyframe2_name=\"scared\")\n",
        "\n",
        "    # --- 7. TEST 3: (POST-DREAM, \"scared\") ---\n",
        "    print(\"\\n\\n--- ðŸ—£ï¸ TEST 3: Post-Dream Brain, 'Scared' Query (Day 3) ---\")\n",
        "    response_3 = await aura.process_query(\"I am feeling very scared\")\n",
        "    print(f\"\\nFINAL AURA RESPONSE (Scared, Day 3): {response_3}\")\n",
        "    day_3_stress = aura.last_run_final_stress\n",
        "\n",
        "    # --- 8. VERIFICATION ---\n",
        "    print(\"\\n\\n--- ðŸ”¬ TEMPORAL LEARNING VERIFICATION ---\")\n",
        "    print(f\"Day 2 Final Stress (on 'scared'): {day_2_stress:.4f}\")\n",
        "    print(f\"Day 3 Final Stress (on 'scared'): {day_3_stress:.4f}\")\n",
        "\n",
        "    if day_3_stress < (day_2_stress * 0.95): # Look for any reduction\n",
        "        print(\"âœ… SUCCESS: The 'dream' cycle helped process the fear! Stress is lower.\")\n",
        "    else:\n",
        "        print(\"âŒ NEUTRAL/FAILURE: The dream cycle did not reduce stress.\")\n",
        "\n",
        "# --- Benchmark Test Suite for Standard Datasets ---\n",
        "# Optimized for 22GB VRAM (L4 GPU):\n",
        "# - Increased batch sizes (64->256 for training, 64->256 for SBERT)\n",
        "# - Larger datasets (15K->30K for GoEmotions, 5K->20K for MNIST, 3K->10K for CIFAR-10)\n",
        "# - More experts (10->15) for better capacity\n",
        "# - More warm-up samples (500->2000) for better MoE learning\n",
        "# - Periodic GPU cache clearing to prevent OOM\n",
        "\n",
        "class ImageFeatureGenerator:\n",
        "    \"\"\"Feature generator for image datasets like MNIST\"\"\"\n",
        "    def __init__(self, image_size: int = 28):\n",
        "        self.image_size = image_size\n",
        "        self.feature_dim = image_size * image_size\n",
        "        print(f\"CREATED: ImageFeatureGenerator for {image_size}x{image_size} images\")\n",
        "\n",
        "    def extract_features(self, image: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Extract features from image (flatten and normalize)\"\"\"\n",
        "        if len(image.shape) > 1:\n",
        "            image = image.flatten()\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "        return image\n",
        "\n",
        "class SimplifiedAuraForBenchmark:\n",
        "    \"\"\"Simplified Aura system for benchmark testing on standard datasets\"\"\"\n",
        "    def __init__(self, n_experts: int = 10, hebbian_components: int = 64,\n",
        "                 feature_dim: int = 784, num_classes: int = 10):\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.abstract_feature_dim = hebbian_components\n",
        "        self.n_experts = n_experts\n",
        "\n",
        "        self.whitener = OptimizedWhitener(dim=feature_dim)\n",
        "        self.hippocampus = OjaLayer(\n",
        "            dim=feature_dim,\n",
        "            n_components=hebbian_components,\n",
        "            mode='nonlinear', lr=5e-4, max_components=128, grow_threshold=0.3\n",
        "        )\n",
        "\n",
        "        self.cortex = None\n",
        "\n",
        "    def _create_experts(self, hebbian_k: int):\n",
        "        \"\"\"Create MoE experts with the correct dimension\"\"\"\n",
        "        experts: Dict[str, NLMSExpertAdapter] = {}\n",
        "        attention_config = {\n",
        "            'decay': 0.7,\n",
        "            'theta': 1.0,\n",
        "            'k_winners': 3,\n",
        "            'gain_up': 1.5,\n",
        "            'gain_down': 0.7,\n",
        "            'multi_channel': {\n",
        "                'k_winners': 5,\n",
        "                'w_amp': 1.0,\n",
        "                'w_pitch': 1.4,\n",
        "                'w_bound': 0.8,\n",
        "                'gain_up': 2.0,\n",
        "                'gain_down': 0.5,\n",
        "                'use_stdp': True,\n",
        "                'smoothing': 1,\n",
        "            }\n",
        "        }\n",
        "        for i in range(self.n_experts):\n",
        "            name = f\"expert__{i}\"\n",
        "            # Initialize with bias toward middle of class range (0-9 for MNIST/CIFAR)\n",
        "            target_class_idx = (i + 0.5) * (10.0 / self.n_experts)\n",
        "            head = ExpertNLMSHead(\n",
        "                n_features=hebbian_k,\n",
        "                vocab_size=1000,\n",
        "                attention_config=attention_config,\n",
        "                mu=0.5,  # Even higher learning rate\n",
        "                mu_decay=0.99995,  # Very slow decay\n",
        "                mu_min=0.1,  # Higher minimum\n",
        "                initial_bias=target_class_idx  # Initialize bias to target range\n",
        "            )\n",
        "            # Initialize weights with larger random values\n",
        "            head.w = np.random.normal(0, 1.0, hebbian_k)\n",
        "            # Ensure bias is actually set\n",
        "            head.bias = float(target_class_idx)\n",
        "            experts[name] = NLMSExpertAdapter(neuron=head)\n",
        "\n",
        "        self.cortex = LiquidMoERouter(\n",
        "            experts=experts, in_dim=hebbian_k,\n",
        "            hidden_dim=128, top_k=3\n",
        "        )\n",
        "        self.abstract_feature_dim = hebbian_k\n",
        "\n",
        "    async def train_and_evaluate(self, X_train: np.ndarray, y_train: np.ndarray,\n",
        "                                 X_test: np.ndarray, y_test: np.ndarray,\n",
        "                                 epochs: int = 5) -> Dict[str, float]:\n",
        "        \"\"\"Train on dataset and return evaluation metrics\"\"\"\n",
        "        print(f\"Training on {len(X_train)} samples, testing on {len(X_test)} samples...\")\n",
        "\n",
        "        # Train Hebbian layer\n",
        "        print(\"Training Hebbian Cortex (OjaLayer)...\")\n",
        "        X_train_whitened = np.array([self.whitener.transform(x) for x in X_train])\n",
        "        for x_w in X_train_whitened:\n",
        "            self.hippocampus.step(x_w)\n",
        "\n",
        "        # Get final K after potential growth\n",
        "        final_k = self.hippocampus.K\n",
        "        print(f\"Hebbian Cortex final K: {final_k}\")\n",
        "\n",
        "        # Create experts with correct dimension\n",
        "        self._create_experts(final_k)\n",
        "\n",
        "        # Warm-up MoE experts\n",
        "        print(\"Warming up MoE experts...\")\n",
        "        warmup_samples = min(2000, len(X_train))\n",
        "        val_indices = np.random.choice(len(X_test), min(500, len(X_test)), replace=False)\n",
        "        errors = []\n",
        "        for sweep in range(epochs):\n",
        "            print(f\"  Warm-up sweep {sweep+1}/{epochs}\")\n",
        "            epoch_errors = []\n",
        "            indices = np.random.permutation(len(X_train))\n",
        "            for idx in indices[:warmup_samples]:\n",
        "                x = X_train[idx]\n",
        "                y_true = float(y_train[idx])\n",
        "\n",
        "                x_w = self.whitener.transform(x)\n",
        "                oja_out = self.hippocampus.step(x_w)\n",
        "                y_abstract = oja_out.y\n",
        "\n",
        "                token_ids = list(range(min(10, len(x))))\n",
        "                if self.cortex is None:\n",
        "                    raise RuntimeError(\"Cortex not initialized. Call _create_experts() first.\")\n",
        "                out = await self.cortex.learn(x=y_abstract, token_ids=token_ids, y_true=y_true)\n",
        "\n",
        "                pred = out['y_hat']\n",
        "                _, discrete_pred = quantize_moe_prediction(pred, self.num_classes)\n",
        "                error = abs(y_true - discrete_pred)\n",
        "                epoch_errors.append(error)\n",
        "\n",
        "            avg_error = np.mean(epoch_errors)\n",
        "            errors.append(avg_error)\n",
        "            print(f\"    Sweep {sweep+1}: Avg Error = {avg_error:.4f}\")\n",
        "\n",
        "            # Validation on held-out test samples\n",
        "            val_errors = []\n",
        "            val_predictions = []\n",
        "            val_targets = []\n",
        "            for vidx in val_indices:\n",
        "                x_val = X_test[int(vidx)]\n",
        "                y_val = float(y_test[int(vidx)])\n",
        "                x_vw = self.whitener.transform(x_val)\n",
        "                oja_out = self.hippocampus.step(x_vw)\n",
        "                y_abs = oja_out.y\n",
        "                token_ids = list(range(min(10, len(x_val))))\n",
        "                out = await self.cortex.route(x=y_abs, attn_gain=1.0)\n",
        "                pred_val = out['y_hat']\n",
        "                _, discrete_val = quantize_moe_prediction(pred_val, self.num_classes)\n",
        "                val_errors.append(abs(y_val - discrete_val))\n",
        "                val_predictions.append(discrete_val)\n",
        "                val_targets.append(y_val)\n",
        "            if val_errors:\n",
        "                val_mae = np.mean(val_errors)\n",
        "                val_rmse = np.sqrt(np.mean([e*e for e in val_errors]))\n",
        "                val_corr = np.corrcoef(val_predictions, val_targets)[0, 1] if len(val_predictions) > 1 else 0.0\n",
        "                print(f\"    Validation -> MAE={val_mae:.4f}, RMSE={val_rmse:.4f}, Corr={val_corr:.3f}\")\n",
        "\n",
        "        # Evaluate on test set\n",
        "        print(\"Evaluating on test set...\")\n",
        "        test_predictions = []\n",
        "        test_targets = []\n",
        "        test_errors = []\n",
        "\n",
        "        for i in range(min(2000, len(X_test))):\n",
        "            x = X_test[i]\n",
        "            y_true = float(y_test[i])\n",
        "\n",
        "            x_w = self.whitener.transform(x)\n",
        "            oja_out = self.hippocampus.step(x_w)\n",
        "            y_abstract = oja_out.y\n",
        "\n",
        "            token_ids = list(range(min(10, len(x))))\n",
        "            if self.cortex is None:\n",
        "                raise RuntimeError(\"Cortex not initialized. Call _create_experts() first.\")\n",
        "            out = await self.cortex.route(x=y_abstract, attn_gain=1.0)\n",
        "\n",
        "            pred = out['y_hat']\n",
        "            pred_idx, discrete_pred = quantize_moe_prediction(pred, self.num_classes)\n",
        "            error = abs(y_true - discrete_pred)\n",
        "\n",
        "            test_predictions.append(discrete_pred)\n",
        "            test_targets.append(y_true)\n",
        "            test_errors.append(error)\n",
        "\n",
        "        mae = np.mean(test_errors)\n",
        "        rmse = np.sqrt(np.mean([e*e for e in test_errors]))\n",
        "\n",
        "        # Calculate accuracy (rounded and clipped predictions)\n",
        "        rounded_preds = np.round(test_predictions)\n",
        "        # Clip to valid class range [0, num_classes-1]\n",
        "        rounded_preds = np.clip(rounded_preds, 0, self.num_classes - 1).astype(int)\n",
        "        test_targets_int = np.array(test_targets, dtype=int)\n",
        "        accuracy = np.mean(rounded_preds == test_targets_int)\n",
        "\n",
        "        correlation = np.corrcoef(test_predictions, test_targets)[0, 1] if len(test_predictions) > 1 else 0.0\n",
        "\n",
        "        return {\n",
        "            'mae': mae,\n",
        "            'rmse': rmse,\n",
        "            'accuracy': accuracy,\n",
        "            'correlation': correlation,\n",
        "            'final_train_error': errors[-1] if errors else float('inf')\n",
        "        }\n",
        "\n",
        "class NewsPatternAnalyzer:\n",
        "    \"\"\"Tracks topic/entity trends over rolling windows for news ingestion.\"\"\"\n",
        "    def __init__(self, max_history: int = 200):\n",
        "        self.topic_history = defaultdict(lambda: deque(maxlen=max_history))\n",
        "\n",
        "    def update_from_article(self, article: Dict[str, Any], prediction: int, discrete_value: float):\n",
        "        topic = article.get('topic') or article.get('category') or 'general'\n",
        "        entry = {\n",
        "            'timestamp': article.get('timestamp', time.time()),\n",
        "            'prediction': int(prediction),\n",
        "            'value': float(discrete_value),\n",
        "            'headline': article.get('headline', '')[:120]\n",
        "        }\n",
        "        self.topic_history[topic].append(entry)\n",
        "\n",
        "    def summarize_topic(self, topic: str = 'general') -> Dict[str, Any]:\n",
        "        history = list(self.topic_history.get(topic, []))\n",
        "        if not history:\n",
        "            return {}\n",
        "        values = [item['value'] for item in history]\n",
        "        predictions = [item['prediction'] for item in history]\n",
        "        return {\n",
        "            'topic': topic,\n",
        "            'sample_count': len(history),\n",
        "            'avg_value': float(np.mean(values)),\n",
        "            'latest_prediction': predictions[-1],\n",
        "            'latest_headline': history[-1].get('headline', '')\n",
        "        }\n",
        "\n",
        "class HistoricalTimelineAnalyzer:\n",
        "    \"\"\"Maintains per-entity timelines for pattern matching.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.timelines = defaultdict(list)\n",
        "\n",
        "    def register_entity(self, entity: str, events: List[Dict[str, Any]]):\n",
        "        normalized = []\n",
        "        for event in events:\n",
        "            normalized.append({\n",
        "                'timestamp': event.get('timestamp', time.time()),\n",
        "                'summary': event.get('summary', ''),\n",
        "                'sentiment': event.get('sentiment', 0.0)\n",
        "            })\n",
        "        self.timelines[entity].extend(normalized)\n",
        "\n",
        "    def compare_pattern(self, query: str, window: int = 5) -> Dict[str, Any]:\n",
        "        tokens = query.lower().split()\n",
        "        entity = tokens[0] if tokens else 'unknown'\n",
        "        events = self.timelines.get(entity)\n",
        "        if not events:\n",
        "            return {}\n",
        "        recent = events[-window:]\n",
        "        avg_sentiment = float(np.mean([e.get('sentiment', 0.0) for e in recent]))\n",
        "        return {\n",
        "            'entity': entity,\n",
        "            'samples_compared': len(recent),\n",
        "            'avg_sentiment': avg_sentiment,\n",
        "            'recent_events': recent\n",
        "        }\n",
        "\n",
        "class NewsIngestionService:\n",
        "    \"\"\"Fetches/processes news batches and updates analyzers.\"\"\"\n",
        "    def __init__(self, pattern_analyzer: Optional[NewsPatternAnalyzer] = None):\n",
        "        self.pattern_analyzer = pattern_analyzer or NewsPatternAnalyzer()\n",
        "\n",
        "    async def fetch_latest_batch(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Placeholder for real API calls.\"\"\"\n",
        "        print(\"âš ï¸ fetch_latest_batch is not implemented; returning empty batch.\")\n",
        "        return []\n",
        "\n",
        "    async def process_articles(self, aura: IntegratedBioNeuralNetwork, articles: List[Dict[str, Any]]):\n",
        "        processed = []\n",
        "        for article in articles:\n",
        "            text = article.get('text') or article.get('headline') or ''\n",
        "            if not text:\n",
        "                continue\n",
        "            target_signals = aura.router.get_target_signals(text, verbose=False)\n",
        "            target_idx = float(target_signals['emotion'])\n",
        "            thalamus_label = aura.router.emotion_labels_inv.get(int(target_idx), 'neutral')\n",
        "\n",
        "            x_raw, token_ids, attention_bundle = aura.feature_gen.generate_for_query(text, thalamus_prediction=thalamus_label)\n",
        "            xw = aura.feature_gen.whitener.transform(x_raw)\n",
        "            oja_out = aura.hippocampus.step(xw)\n",
        "            y_abstract = oja_out.y\n",
        "\n",
        "            out = await aura.cortex.learn(\n",
        "                x=y_abstract,\n",
        "                token_ids=token_ids,\n",
        "                y_true=target_idx,\n",
        "                attention_bundle=attention_bundle\n",
        "            )\n",
        "            pred_idx, discrete_pred = quantize_moe_prediction(out['y_hat'], NUM_GOEMOTIONS)\n",
        "            article_result = {\n",
        "                'article': article,\n",
        "                'prediction_idx': pred_idx,\n",
        "                'prediction_value': discrete_pred\n",
        "            }\n",
        "            processed.append(article_result)\n",
        "            if self.pattern_analyzer:\n",
        "                self.pattern_analyzer.update_from_article(article, pred_idx, discrete_pred)\n",
        "        return processed\n",
        "\n",
        "async def test_mnist():\n",
        "    \"\"\"Test Aura on MNIST dataset\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"--- ðŸ§ª BENCHMARK TEST: MNIST Dataset ---\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    try:\n",
        "        from torchvision import datasets, transforms\n",
        "        from torch.utils.data import DataLoader\n",
        "\n",
        "        transform = transforms.Compose([transforms.ToTensor()])\n",
        "        mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "        mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "        # Convert to numpy (using more data with 22GB VRAM)\n",
        "        X_train = []\n",
        "        y_train = []\n",
        "        for i in range(min(20000, len(mnist_train))):\n",
        "            img, label = mnist_train[i]\n",
        "            X_train.append(img.numpy().flatten())\n",
        "            y_train.append(label)\n",
        "\n",
        "        X_test = []\n",
        "        y_test = []\n",
        "        for i in range(min(5000, len(mnist_test))):\n",
        "            img, label = mnist_test[i]\n",
        "            X_test.append(img.numpy().flatten())\n",
        "            y_test.append(label)\n",
        "\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "        X_test = np.array(X_test)\n",
        "        y_test = np.array(y_test)\n",
        "\n",
        "        print(f\"Loaded MNIST: {len(X_train)} train, {len(X_test)} test samples\")\n",
        "\n",
        "        aura_bench = SimplifiedAuraForBenchmark(\n",
        "            n_experts=15,\n",
        "            hebbian_components=64,\n",
        "            feature_dim=784,\n",
        "            num_classes=10\n",
        "        )\n",
        "\n",
        "        results = await aura_bench.train_and_evaluate(\n",
        "            X_train, y_train, X_test, y_test, epochs=5\n",
        "        )\n",
        "\n",
        "        print(\"\\n--- ðŸ“Š MNIST Results ---\")\n",
        "        print(f\"Test Accuracy: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)\")\n",
        "        print(f\"Test MAE: {results['mae']:.4f}\")\n",
        "        print(f\"Test RMSE: {results['rmse']:.4f}\")\n",
        "        print(f\"Correlation: {results['correlation']:.4f}\")\n",
        "        print(f\"Final Train Error: {results['final_train_error']:.4f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"âŒ torchvision not available. Install with: pip install torchvision\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error testing MNIST: {e}\")\n",
        "        return None\n",
        "\n",
        "async def test_cifar10():\n",
        "    \"\"\"Test Aura on CIFAR-10 dataset\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"--- ðŸ§ª BENCHMARK TEST: CIFAR-10 Dataset ---\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    try:\n",
        "        from torchvision import datasets, transforms\n",
        "        from torch.utils.data import DataLoader\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Grayscale()\n",
        "        ])\n",
        "        cifar_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "        cifar_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "        # Convert to numpy (using more data with 22GB VRAM)\n",
        "        X_train = []\n",
        "        y_train = []\n",
        "        for i in range(min(10000, len(cifar_train))):\n",
        "            img, label = cifar_train[i]\n",
        "            X_train.append(img.numpy().flatten())\n",
        "            y_train.append(label)\n",
        "\n",
        "        X_test = []\n",
        "        y_test = []\n",
        "        for i in range(min(2000, len(cifar_test))):\n",
        "            img, label = cifar_test[i]\n",
        "            X_test.append(img.numpy().flatten())\n",
        "            y_test.append(label)\n",
        "\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "        X_test = np.array(X_test)\n",
        "        y_test = np.array(y_test)\n",
        "\n",
        "        print(f\"Loaded CIFAR-10: {len(X_train)} train, {len(X_test)} test samples\")\n",
        "\n",
        "        aura_bench = SimplifiedAuraForBenchmark(\n",
        "            n_experts=15,\n",
        "            hebbian_components=64,\n",
        "            feature_dim=32*32,\n",
        "            num_classes=10\n",
        "        )\n",
        "\n",
        "        results = await aura_bench.train_and_evaluate(\n",
        "            X_train, y_train, X_test, y_test, epochs=5\n",
        "        )\n",
        "\n",
        "        print(\"\\n--- ðŸ“Š CIFAR-10 Results ---\")\n",
        "        print(f\"Test Accuracy: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)\")\n",
        "        print(f\"Test MAE: {results['mae']:.4f}\")\n",
        "        print(f\"Test RMSE: {results['rmse']:.4f}\")\n",
        "        print(f\"Correlation: {results['correlation']:.4f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"âŒ torchvision not available. Install with: pip install torchvision\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error testing CIFAR-10: {e}\")\n",
        "        return None\n",
        "\n",
        "async def run_all_benchmarks():\n",
        "    \"\"\"Run all benchmark tests\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"--- ðŸš€ RUNNING ALL BENCHMARK TESTS ---\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Test MNIST\n",
        "    mnist_results = await test_mnist()\n",
        "    if mnist_results:\n",
        "        results['MNIST'] = mnist_results\n",
        "\n",
        "    # Test CIFAR-10\n",
        "    cifar_results = await test_cifar10()\n",
        "    if cifar_results:\n",
        "        results['CIFAR-10'] = cifar_results\n",
        "\n",
        "    # Summary\n",
        "    if results:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"--- ðŸ“ˆ BENCHMARK SUMMARY ---\")\n",
        "        print(\"=\"*70)\n",
        "        for dataset_name, res in results.items():\n",
        "            print(f\"\\n{dataset_name}:\")\n",
        "            print(f\"  Accuracy: {res['accuracy']*100:.2f}%\")\n",
        "            print(f\"  MAE: {res['mae']:.4f}\")\n",
        "            print(f\"  RMSE: {res['rmse']:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# --- Helper Functions for Running Tests ---\n",
        "async def run_mnist_test_only():\n",
        "    \"\"\"Run only MNIST benchmark test\"\"\"\n",
        "    return await test_mnist()\n",
        "\n",
        "async def run_cifar10_test_only():\n",
        "    \"\"\"Run only CIFAR-10 benchmark test\"\"\"\n",
        "    return await test_cifar10()\n",
        "\n",
        "# --- Run the async main loop ---\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Set RUN_BENCHMARKS=True to run benchmark tests instead of main test loop\n",
        "# Or use: RUN_BENCHMARKS=\"mnist\" for MNIST only, \"cifar10\" for CIFAR-10 only\n",
        "RUN_BENCHMARKS = False\n",
        "\n",
        "if RUN_BENCHMARKS == True:\n",
        "    print(\"=\"*70)\n",
        "    print(\"Running All Benchmark Tests (MNIST, CIFAR-10)\")\n",
        "    print(\"=\"*70)\n",
        "    asyncio.run(run_all_benchmarks())\n",
        "elif RUN_BENCHMARKS == \"mnist\":\n",
        "    print(\"=\"*70)\n",
        "    print(\"Running MNIST Benchmark Test\")\n",
        "    print(\"=\"*70)\n",
        "    asyncio.run(run_mnist_test_only())\n",
        "elif RUN_BENCHMARKS == \"cifar10\":\n",
        "    print(\"=\"*70)\n",
        "    print(\"Running CIFAR-10 Benchmark Test\")\n",
        "    print(\"=\"*70)\n",
        "    asyncio.run(run_cifar10_test_only())\n",
        "else:\n",
        "    asyncio.run(main_test_loop())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkOtqj4ufwtP"
      },
      "source": [
        "# TEST v7.0 (AURA v1)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
